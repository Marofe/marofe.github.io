{"version":3,"sources":["Components/Layout/Layout.js","Components/Pages/HomePage.js","Components/Pages/Publications.js","Components/Latex/Inline.js","Components/Image/Image.js","Content/Tutorials/kf_vision_pt.js","Components/Pages/TutorialList.js","Components/Pages/Tutorials.js","Components/Pages/NotesList.js","Content/Notes/Kalman/ekf_lie.js","Components/Latex/latex.js","Content/Notes/Riccati/RiccatiEq.js","Content/Notes/particleFilter.js","Content/Notes/LASSO/lasso.js","Content/Notes/Kalman/BayesianFiltering.js","Content/Notes/Kalman/IntroKalmanFilter.js","Content/Notes/Kalman/kalmanSmoothing.js","Content/Notes/Kalman/classicEstimation.js","Components/Pages/NotePage.js","Components/Pages/Notes.js","Components/Header/Header.js","Components/Header/Navigation.js","Components/Bottom/Bottom.js","App.js","serviceWorker.js","index.js"],"names":["Layout","props","react_default","a","createElement","className","children","HomePage","Helmet_default","name","content","alt","class","src","href","Papers","inline","dangerouslySetInnerHTML","__html","Katex","renderToString","math","Image","id","label","width","height","legend","Tutorial1","console","log","Components_Image_Image","react_katex","Inline","allowfullscreen","data-thumbnail-src","frameborder","lib_default","DiscussionEmbed","shortname","config","url","identifier","title","TutorialList","prop","Tutorials","react_router","path","exact","render","Pages_TutorialList","kf_vision_pt","NotesList","list","notes","map","note","link","desc","EkfLie","disqusConfig","align","Latex","RiccatiEq","latex","ParticleFilter","Lasso","BayesianFiltering","IntroKalmanFilter","KalmanSmoothing","ClassicEstimation","NotePage","ekf_lie","Riccati_RiccatiEq","particleFilter","lasso","Kalman_BayesianFiltering","Kalman_IntroKalmanFilter","kalmanSmoothing","classicEstimation","Notes","states","routes","_this","Pages_NotePage","_this2","this","Pages_NotesList","Component","Header","Navigation","Bottom","year","Date","getFullYear","App","Components_Layout_Layout","Components_Header_Header","Header_Navigation","react_router_dom","basename","process","component","Publications","Components_Bottom_Bottom","Boolean","window","location","hostname","match","ReactDOM","src_App","document","getElementById","navigator","serviceWorker","ready","then","registration","unregister"],"mappings":"uSAIeA,eAHA,SAACC,GACZ,OAAOC,EAAAC,EAAAC,cAAA,OAAKC,UAAU,UAAUJ,EAAMK,2CCyC3BC,SAxCE,WACb,OAAOL,EAAAC,EAAAC,cAAA,OAAKC,UAAU,WAClBH,EAAAC,EAAAC,cAACI,EAAAL,EAAD,KACAD,EAAAC,EAAAC,cAAA,+DACAF,EAAAC,EAAAC,cAAA,QAAMK,KAAK,cAAcC,QAAQ,iGAEzCR,EAAAC,EAAAC,cAAA,OAAKC,UAAU,gBACNH,EAAAC,EAAAC,cAAA,OAAKO,IAAI,SAASC,MAAM,kBAAkBC,IAAI,+DAC/CX,EAAAC,EAAAC,cAAA,yCACAF,EAAAC,EAAAC,cAAA,+PAMRF,EAAAC,EAAAC,cAAA,eACQF,EAAAC,EAAAC,cAAA,mCACRF,EAAAC,EAAAC,cAAA,UACIF,EAAAC,EAAAC,cAAA,gCACAF,EAAAC,EAAAC,cAAA,8BACAF,EAAAC,EAAAC,cAAA,2CACAF,EAAAC,EAAAC,cAAA,sCACAF,EAAAC,EAAAC,cAAA,qCACAF,EAAAC,EAAAC,cAAA,2DACAF,EAAAC,EAAAC,cAAA,6BACAF,EAAAC,EAAAC,cAAA,8BAGJF,EAAAC,EAAAC,cAAA,OAAKC,UAAU,gBAEfH,EAAAC,EAAAC,cAAA,KAAGU,KAAK,8BAA8BF,MAAM,kBAC5CV,EAAAC,EAAAC,cAAA,KAAGU,KAAK,oCAAoCF,MAAM,oBAClDV,EAAAC,EAAAC,cAAA,KAAGU,KAAK,wDAAwDF,MAAM,mBACtEV,EAAAC,EAAAC,cAAA,KAAGU,KAAK,0DAA0DF,MAAM,uBACxEV,EAAAC,EAAAC,cAAA,KAAGU,KAAK,4BAA4BF,MAAM,iBAC1CV,EAAAC,EAAAC,cAAA,KAAGU,KAAK,gCAAgCF,MAAM,wBCmB/BG,SAtDA,WACX,OAAOb,EAAAC,EAAAC,cAAA,OAAKC,UAAU,0BAClBH,EAAAC,EAAAC,cAACI,EAAAL,EAAD,KACAD,EAAAC,EAAAC,cAAA,2DACAF,EAAAC,EAAAC,cAAA,QAAMK,KAAK,cAAcC,QAAQ,gFAEjCR,EAAAC,EAAAC,cAAA,OAAKC,UAAU,OAChBH,EAAAC,EAAAC,cAAA,6BACAF,EAAAC,EAAAC,cAAA,sEAEAF,EAAAC,EAAAC,cAAA,eACAF,EAAAC,EAAAC,cAAA,uBACAF,EAAAC,EAAAC,cAAA,UACCF,EAAAC,EAAAC,cAAA,UACIF,EAAAC,EAAAC,cAAA,iMAEJF,EAAAC,EAAAC,cAAA,WAFI,IAEEF,EAAAC,EAAAC,cAAA,KAAGU,KAAK,gDAAR,4BAFF,OAKLZ,EAAAC,EAAAC,cAAA,gCACPF,EAAAC,EAAAC,cAAA,UACQF,EAAAC,EAAAC,cAAA,UACIF,EAAAC,EAAAC,cAAA,iSAEJF,EAAAC,EAAAC,cAAA,WAFI,IAEEF,EAAAC,EAAAC,cAAA,KAAGU,KAAK,gDAAR,4BAFF,KAEuFZ,EAAAC,EAAAC,cAAA,KAAGU,KAAK,6DAAR,UAFvF,MAEwKZ,EAAAC,EAAAC,cAAA,KAAGU,KAAK,kCAAR,QAFxK,MAKJZ,EAAAC,EAAAC,cAAA,UAAIF,EAAAC,EAAAC,cAAA,gTAEJF,EAAAC,EAAAC,cAAA,WAFI,IAEEF,EAAAC,EAAAC,cAAA,KAAGU,KAAK,+CAAR,yBAFF,KAEmFZ,EAAAC,EAAAC,cAAA,KAAGU,KAAK,kCAAR,QAFnF,MAKJZ,EAAAC,EAAAC,cAAA,UAAIF,EAAAC,EAAAC,cAAA,yXAEJF,EAAAC,EAAAC,cAAA,WAFI,IAEEF,EAAAC,EAAAC,cAAA,KAAGU,KAAK,gDAAR,4BAFF,MAIJZ,EAAAC,EAAAC,cAAA,UAAIF,EAAAC,EAAAC,cAAA,oXAEJF,EAAAC,EAAAC,cAAA,WAFI,IAEEF,EAAAC,EAAAC,cAAA,KAAGU,KAAK,oDAAR,yBAFF,OAMZZ,EAAAC,EAAAC,cAAA,oCACAF,EAAAC,EAAAC,cAAA,sHAEKF,EAAAC,EAAAC,cAAA,WAFL,IAEWF,EAAAC,EAAAC,cAAA,KAAGU,KAAK,6DAAR,yBAFX,MAE2GZ,EAAAC,EAAAC,cAAA,KAAGU,KAAK,yEAAR,UAF3G,MAEwMZ,EAAAC,EAAAC,cAAA,KAAGU,KAAK,kCAAR,QAFxM,KAIAZ,EAAAC,EAAAC,cAAA,4CACAF,EAAAC,EAAAC,cAAA,6IAEKF,EAAAC,EAAAC,cAAA,WAFL,IAEWF,EAAAC,EAAAC,cAAA,KAAGU,KAAK,uIAAR,yBAFX,wCC9CeE,EAHA,SAACf,GAChB,OAAOC,EAAAC,EAAAC,cAAA,QAAMa,wBAAyB,CAACC,OAAQC,IAAMC,eAAenB,EAAMoB,UCK3DC,eAND,SAACrB,GACX,OAAOC,EAAAC,EAAAC,cAAA,OAAKC,UAAU,YAClBH,EAAAC,EAAAC,cAAA,OAAKC,UAAWJ,EAAMI,UAAWkB,GAAItB,EAAMuB,MAAOb,IAAKV,EAAMU,IAAKE,IAAKZ,EAAMY,IAAKY,MAAOxB,EAAMwB,MAAOC,OAAQzB,EAAMyB,SAASxB,EAAAC,EAAAC,cAAA,WAC7HF,EAAAC,EAAAC,cAAA,YAAOH,EAAM0B,2BCsWNC,EAnWG,WAQd,OADIC,QAAQC,IAA2B,sDAChC5B,EAAAC,EAAAC,cAAA,eACLF,EAAAC,EAAAC,cAACI,EAAAL,EAAD,KACED,EAAAC,EAAAC,cAAA,uHACAF,EAAAC,EAAAC,cAAA,QAAMK,KAAK,cAAcC,QAAQ,iGAErCR,EAAAC,EAAAC,cAAA,sFACAF,EAAAC,EAAAC,cAAC2B,EAAD,CAAOlB,IAAI,4HAA4HF,IAAI,kBAAkBgB,OAAO,4BACxKzB,EAAAC,EAAAC,cAAA,gxBAOIF,EAAAC,EAAAC,cAAA,kEACJF,EAAAC,EAAAC,cAAA,8BACAF,EAAAC,EAAAC,cAAA,6/DAkBKF,EAAAC,EAAAC,cAAA,mBAlBL,4GAoBAF,EAAAC,EAAAC,cAAC2B,EAAD,CAAOlB,IAAI,4HACaF,IAAI,WAAWgB,OAAO,sBAE1CzB,EAAAC,EAAAC,cAAA,iCACAF,EAAAC,EAAAC,cAAA,86BASAF,EAAAC,EAAAC,cAAC4B,EAAA,UAAD,CAAWX,KAAK,oFAjDT,WAoDCnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAcZ,KAAK,2BApDpB,6BAoDmEnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAcZ,KAAK,oCApDtF,6BAoD6InB,EAAAC,EAAAC,cAAC6B,EAAD,CAAcZ,KAAK,oCApDhK,8BAoDwNnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAcZ,KAAK,2BApD3O,6BAoD0RnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAcZ,KAAK,QApD7S,oJAqD0FnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAcZ,KAAK,2BArD7G,yBAqDwJnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAcZ,KAAK,oCArD3K,2BAqDgOnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAcZ,KAAK,QArDnP,qIAsDmFnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAcZ,KAAK,QAtDtG,MAsDgHnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAcZ,KAAK,QAtDnI,kGAyDPnB,EAAAC,EAAAC,cAAC4B,EAAA,UAAD,CAAWX,KAAK,+SAQpBnB,EAAAC,EAAAC,cAAA,gBACIF,EAAAC,EAAAC,cAAC6B,EAAD,CAAcZ,KAAK,oCADvB,oDACqGnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAcZ,KAAK,oCADxH,gCACkLnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAcZ,KAAK,oCADrM,0CAEiCnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAcZ,KAAK,oCAFpD,6CAE2HnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAcZ,KAAK,sCAF9I,2DAE+NnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAcZ,KAAK,eAFlP,wDAGwBnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAcZ,KAAK,MAH3C,sJAI0CnB,EAAAC,EAAAC,cAAA,qBAJ1C,mLAKgGF,EAAAC,EAAAC,cAAA,yBALhG,0FAM6EF,EAAAC,EAAAC,cAAA,qBAN7E,+NAUAF,EAAAC,EAAAC,cAAC2B,EAAD,CAAOlB,IAAI,4HACaF,IAAI,6BAA6BgB,OAAO,gCAChEzB,EAAAC,EAAAC,cAAA,wBAAeF,EAAAC,EAAAC,cAAC6B,EAAD,CAAcZ,KAAK,MAAlC,MAA0CnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAcZ,KAAK,MAA7D,ybAIWnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAcZ,KAAK,SAJ9B,eAIkDnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAcZ,KAAK,SAJrE,WAIqFnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAcZ,KAAK,MAJxG,uDAI2JnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAcZ,KAAK,yBAJ9K,kCAK4BnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAcZ,KAAK,QAL/C,kLAM+EnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAcZ,KAAK,QANlG,8IASAnB,EAAAC,EAAAC,cAAC2B,EAAD,CAAOlB,IAAI,4HACFF,IAAI,yBAAsBgB,OAAO,6CACpCzB,EAAAC,EAAAC,cAAC2B,EAAD,CAAOlB,IAAI,4HACJF,IAAI,yBAAsBgB,OAAO,oDAC9CzB,EAAAC,EAAAC,cAAA,2TAGgGF,EAAAC,EAAAC,cAAA,mBAHhG,wWAQIF,EAAAC,EAAAC,cAAA,yCACJF,EAAAC,EAAAC,cAAA,glBAKiGF,EAAAC,EAAAC,cAAA,uBALjG,iBAMYF,EAAAC,EAAAC,cAAA,mBANZ,yGAOmBF,EAAAC,EAAAC,cAAA,8BAPnB,mkBAWwGF,EAAAC,EAAAC,cAAA,kBAXxG,qCAcAF,EAAAC,EAAAC,cAAC2B,EAAD,CAAOlB,IAAI,uHACWF,IAAI,aAAagB,OAAO,2BAE9CzB,EAAAC,EAAAC,cAAA,+QAEiDF,EAAAC,EAAAC,cAAA,sBAFjD,sBAEoFF,EAAAC,EAAAC,cAAA,mBAFpF,6EAG0DF,EAAAC,EAAAC,cAAA,mBAH1D,oHAMIF,EAAAC,EAAAC,cAAC2B,EAAD,CAAOlB,IAAI,0HACWF,IAAI,qBAAegB,OAAO,mCAChDzB,EAAAC,EAAAC,cAAA,4BAAmBF,EAAAC,EAAAC,cAAC6B,EAAD,CAAcZ,KAAK,MAAtC,4MAGAnB,EAAAC,EAAAC,cAAA,qGAE4CF,EAAAC,EAAAC,cAAA,mBAF5C,2MAKDF,EAAAC,EAAAC,cAAC2B,EAAD,CAAOlB,IAAI,uHACcF,IAAI,YAAYgB,OAAO,gDAC/CzB,EAAAC,EAAAC,cAAA,qDACAF,EAAAC,EAAAC,cAAA,geAMDF,EAAAC,EAAAC,cAAC2B,EAAD,CAAOlB,IAAI,6HACcF,IAAI,sCAAgCgB,OAAO,oDACnEzB,EAAAC,EAAAC,cAAA,2XAGiBF,EAAAC,EAAAC,cAAA,mBAHjB,qHAIsBF,EAAAC,EAAAC,cAAC6B,EAAD,CAAcZ,KAAK,oCAJzC,kBAIwFnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAcZ,KAAK,qBAJ3G,SAImInB,EAAAC,EAAAC,cAAC6B,EAAD,CAAcZ,KAAK,qBAJtJ,MAI2KnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAcZ,KAAK,uBAJ9L,yEAKsEnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAcZ,KAAK,yBALzF,uBAOAnB,EAAAC,EAAAC,cAAC4B,EAAA,UAAD,CAAWX,KAAK,4HAPhB,0CAUiCnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAcZ,KAAK,yBAVpD,SAYAnB,EAAAC,EAAAC,cAAC4B,EAAA,UAAD,CAAWX,KAAK,4HAIhBnB,EAAAC,EAAAC,cAAA,iCACqBF,EAAAC,EAAAC,cAAC6B,EAAD,CAAcZ,KAAK,sBADxC,gFAIAnB,EAAAC,EAAAC,cAAC4B,EAAA,UAAD,CAAWX,KAAK,6EAGhBnB,EAAAC,EAAAC,cAAA,8DACyCF,EAAAC,EAAAC,cAAA,mBADzC,8IAGAF,EAAAC,EAAAC,cAAA,mBAHA,eAIDF,EAAAC,EAAAC,cAAC2B,EAAD,CAAOlB,IAAI,8HACaF,IAAI,mBAAagB,OAAO,gCACnDzB,EAAAC,EAAAC,cAAA,mPAEIF,EAAAC,EAAAC,cAAC6B,EAAD,CAAcZ,KAAK,sBAFvB,8CAEoFnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAcZ,KAAK,kBAFvG,0HAKInB,EAAAC,EAAAC,cAAC4B,EAAA,UAAD,CAAWX,KAAK,6MAKhBnB,EAAAC,EAAAC,cAAA,uCACAF,EAAAC,EAAAC,cAAA,kwBAQAF,EAAAC,EAAAC,cAAC4B,EAAA,UAAD,CAAWX,KAAK,2+BAuCjBnB,EAAAC,EAAAC,cAAA,sBACWF,EAAAC,EAAAC,cAAC6B,EAAD,CAAcZ,KAAK,0BAD9B,gDAEwBnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAcZ,KAAK,0BAF3C,8CAE0GnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAcZ,KAAK,0BAF7H,mDAGyCnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAcZ,KAAK,0BAH5D,iDAG8HnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAcZ,KAAK,YAHjJ,yCAI2BnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAcZ,KAAK,YAJ9C,+QAQFnB,EAAAC,EAAAC,cAAA,+BAAsBF,EAAAC,EAAAC,cAAC6B,EAAD,CAAcZ,KAAK,QAAzC,MAAmDnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAcZ,KAAK,QAAtE,qHAEenB,EAAAC,EAAAC,cAAA,6iBAOhBF,EAAAC,EAAAC,cAAC2B,EAAD,CAAOlB,IAAI,2HACgBF,IAAI,YAAYgB,OAAO,2BAClDzB,EAAAC,EAAAC,cAAA,4CAAgCF,EAAAC,EAAAC,cAAC6B,EAAD,CAAcZ,KAAK,QAAnD,MAA6DnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAcZ,KAAK,QAAhF,+iBAOInB,EAAAC,EAAAC,cAAA,uBAhQO,8LAkQRF,EAAAC,EAAAC,cAAC2B,EAAD,CAAOlB,IAAI,4HACcF,IAAI,iBAAcgB,OAAO,gCAnQ1C,qFAqQPzB,EAAAC,EAAAC,cAAC2B,EAAD,CAAOlB,IAAI,4HACYF,IAAI,iBAAcgB,OAAO,+BAtQzC,sUA4QPzB,EAAAC,EAAAC,cAAC2B,EAAD,CAAOlB,IAAI,8HACaF,IAAI,gBAAagB,OAAO,+BA7QzC,wUAkRPzB,EAAAC,EAAAC,cAAC2B,EAAD,CAAOlB,IAAI,2HACYF,IAAI,gBAAagB,OAAO,2CAC/CzB,EAAAC,EAAAC,cAAA,yCACJF,EAAAC,EAAAC,cAAA,cACGF,EAAAC,EAAAC,cAAA,UAAQ8B,gBAAgB,GACftB,MAAM,uBAAuBuB,qBAAmB,2CAA2CC,YAAY,IACvGV,OAAO,MAAMb,IAAI,oEAAoEY,MAAM,SAEnGvB,EAAAC,EAAAC,cAAA,6BACAF,EAAAC,EAAAC,cAAA,cACJF,EAAAC,EAAAC,cAAA,KAAGU,KAAK,uEAAR,wEAEAZ,EAAAC,EAAAC,cAAA,0BACIF,EAAAC,EAAAC,cAAA,szBASAF,EAAAC,EAAAC,cAAA,4BACAF,EAAAC,EAAAC,cAAA,SACAF,EAAAC,EAAAC,cAAA,iDADA,kHAIJF,EAAAC,EAAAC,cAAA,SACIF,EAAAC,EAAAC,cAAA,yCADJ,wEAIIF,EAAAC,EAAAC,cAAA,SACAF,EAAAC,EAAAC,cAAA,4BADA,+GAIAF,EAAAC,EAAAC,cAAA,SACAF,EAAAC,EAAAC,cAAA,0CADA,2MAKAF,EAAAC,EAAAC,cAAA,SACAF,EAAAC,EAAAC,cAAA,wCADA,iHAIAF,EAAAC,EAAAC,cAAA,SACAF,EAAAC,EAAAC,cAAA,gFADA,iFAIAF,EAAAC,EAAAC,cAAA,SACAF,EAAAC,EAAAC,cAAA,6BADA,2JAKAF,EAAAC,EAAAC,cAAA,SACAF,EAAAC,EAAAC,cAAA,sDADA,iKAKAF,EAAAC,EAAAC,cAAA,SACAF,EAAAC,EAAAC,cAAA,4CADA,uHAIAF,EAAAC,EAAAC,cAAA,SACAF,EAAAC,EAAAC,cAAA,4CADA,2CAIAF,EAAAC,EAAAC,cAAA,SACAF,EAAAC,EAAAC,cAAA,yDADA,wIAIAF,EAAAC,EAAAC,cAACiC,EAAAlC,EAAOmC,gBAAR,CAAwBC,UA/VA,mBA+V4BC,OA9V3B,CACjBC,IAAK,gFACLC,WAAY,0CACZC,MAAO,gFCIJC,EAfM,SAACC,GAClB,OAAO3C,EAAAC,EAAAC,cAAA,OAAKC,UAAU,WACtBH,EAAAC,EAAAC,cAAA,OAAKQ,MAAM,YACXV,EAAAC,EAAAC,cAAA,UAAIF,EAAAC,EAAAC,cAAA,KAAGU,KAAK,sDAAR,6EACJZ,EAAAC,EAAAC,cAAA,gxBAOJF,EAAAC,EAAAC,cAAA,qECMe0C,EAbG,WACd,OAAO5C,EAAAC,EAAAC,cAAA,OAAKC,UAAU,WACtBH,EAAAC,EAAAC,cAACI,EAAAL,EAAD,KACID,EAAAC,EAAAC,cAAA,wDACAF,EAAAC,EAAAC,cAAA,QAAMK,KAAK,cAAcC,QAAQ,gEAErCR,EAAAC,EAAAC,cAAA,OAAKC,UAAU,OACZH,EAAAC,EAAAC,cAAA,wBAEFF,EAAAC,EAAAC,cAAC2C,EAAA,EAAD,CAAOC,KAAK,aAAaC,OAAK,EAACC,OAAQ,SAACjD,GAAD,OAAWC,EAAAC,EAAAC,cAAC+C,EAAD,SAClDjD,EAAAC,EAAAC,cAAC2C,EAAA,EAAD,CAAOC,KAAK,qDAAqDC,OAAK,EAACC,OAAQ,SAACjD,GAAD,OAAWC,EAAAC,EAAAC,cAACgD,EAAD,mDCMhFC,SAnBG,SAACpD,GACf,IAAIqD,EAAMrD,EAAMsD,MAAMC,IAAI,SAACC,GAAD,OACtBvD,EAAAC,EAAAC,cAAA,OAAKC,UAAU,YACXH,EAAAC,EAAAC,cAAA,UAAIF,EAAAC,EAAAC,cAAA,KAAGU,KAAM,UAAU2C,EAAKC,MAAOD,EAAKd,QACxCzC,EAAAC,EAAAC,cAAA,SAAIqD,EAAKE,SAGjB,OAASzD,EAAAC,EAAAC,cAAA,WACXF,EAAAC,EAAAC,cAACI,EAAAL,EAAD,KACED,EAAAC,EAAAC,cAAA,oDACAF,EAAAC,EAAAC,cAAA,QAAMK,KAAK,cAAcC,QAAQ,2CAErCR,EAAAC,EAAAC,cAAA,OAAKC,UAAU,OACZH,EAAAC,EAAAC,cAAA,sBACAF,EAAAC,EAAAC,cAAA,kHAEFkD,KCiDcM,EA5DA,SAAC3D,GACZ,IACU4D,EAAe,CACjBpB,IAAK,+BAA+BxC,EAAMwD,KAAKC,KAC/ChB,WAAY,QAAQzC,EAAMwD,KAAKC,KAC/Bf,MAAO1C,EAAM0C,OAGrB,OAAOzC,EAAAC,EAAAC,cAAA,eACLF,EAAAC,EAAAC,cAACI,EAAAL,EAAD,KACED,EAAAC,EAAAC,cAAA,aAAQH,EAAMwD,KAAKd,MAAnB,YACAzC,EAAAC,EAAAC,cAAA,QAAMK,KAAK,cAAcC,QAAST,EAAMwD,KAAKE,QAEjDzD,EAAAC,EAAAC,cAAA,UAAKH,EAAM0C,OACfzC,EAAAC,EAAAC,cAAA,SAAIH,EAAM0D,MACNzD,EAAAC,EAAAC,cAAA,KAAG0D,MAAM,SAAT,oCACJ5D,EAAAC,EAAAC,cAAA,+FACiFF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,MAD9F,iBACiHnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,MAD9H,kDACkLnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,uBAD/L,WAC4NnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,OADzO,uCACmRnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,MADhS,iBAEAnB,EAAAC,EAAAC,cAAC4B,EAAA,UAAD,CAAWX,KAAK,+KAFhB,SAMMnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,4BANnB,qBAM8DnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,+BAN3E,wBAM4HnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,SANzI,qBAMmKnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,SANhL,oEAOAnB,EAAAC,EAAAC,cAAC4B,EAAA,UAAD,CAAWX,KAAK,wHAPhB,OAWInB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,iCAXjB,QAWoDnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,oCAXjE,IAYAnB,EAAAC,EAAAC,cAAA,cAAQF,EAAAC,EAAAC,cAAA,wBACRF,EAAAC,EAAAC,cAAA,wBACAF,EAAAC,EAAAC,cAAC4B,EAAA,UAAD,CAAWX,KAAK,wPAdhB,QAoBAnB,EAAAC,EAAAC,cAAC4B,EAAA,UAAD,CAAWX,KAAK,uZAOhBnB,EAAAC,EAAAC,cAAA,oBACAF,EAAAC,EAAAC,cAAC4B,EAAA,UAAD,CAAWX,KAAK,+VA5BhB,QAoCAnB,EAAAC,EAAAC,cAAC4B,EAAA,UAAD,CAAWX,KAAK,mPAKZnB,EAAAC,EAAAC,cAACiC,EAAAlC,EAAOmC,gBAAR,CAAwBC,UAxDA,mBAwD4BC,OAAQqB,MC1DjDE,EALD,SAAC9D,GACf,OAAOC,EAAAC,EAAAC,cAAA,OAAKmB,GAAItB,EAAMuB,OAClBtB,EAAAC,EAAAC,cAAC4B,EAAA,UAAD,CAAWX,KAAMpB,EAAMoB,SC4WQ2C,EAvWjB,SAAC/D,GACnB,IACM4D,EAAe,CACbpB,IAAK,+BAA+BxC,EAAMwD,KAAKC,KAC/ChB,WAAY,QAAQzC,EAAMwD,KAAKC,KAC/Bf,MAAO1C,EAAM0C,OAErB,OAAOzC,EAAAC,EAAAC,cAAA,eACDF,EAAAC,EAAAC,cAACI,EAAAL,EAAD,KACED,EAAAC,EAAAC,cAAA,aAAQH,EAAMwD,KAAKd,MAAnB,aACAzC,EAAAC,EAAAC,cAAA,QAAMK,KAAK,cAAcC,QAAST,EAAMwD,KAAKE,QAEjDzD,EAAAC,EAAAC,cAAA,UAAKH,EAAM0C,OACfzC,EAAAC,EAAAC,cAAA,SAAIH,EAAM0D,MACNzD,EAAAC,EAAAC,cAAA,KAAG0D,MAAM,SAAT,qCACJ5D,EAAAC,EAAAC,cAAA,WACAF,EAAAC,EAAAC,cAAA,+CADA,0NAIAF,EAAAC,EAAAC,cAAA,UAJA,mKAMAF,EAAAC,EAAAC,cAAA,UACAF,EAAAC,EAAAC,cAAA,OAAKQ,MAAM,WAAUV,EAAAC,EAAAC,cAAA,UACpBF,EAAAC,EAAAC,cAAA,yCAAgCF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,gBAA7C,KACAnB,EAAAC,EAAAC,cAAA,yCAAgCF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,4BAA7C,KACAnB,EAAAC,EAAAC,cAAA,qCAA4BF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,gBAAzC,KACAnB,EAAAC,EAAAC,cAAA,oCAA2BF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,4BAAxC,OAEDnB,EAAAC,EAAAC,cAAA,UAbA,oIAciIF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,QAd9I,kCAcoLnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,cAdjM,gGAeAnB,EAAAC,EAAAC,cAAA,UACAF,EAAAC,EAAAC,cAAC2B,EAAD,CAAOlB,IAAI,uBAAuBW,MAAM,eAAeG,OAAO,2EAA2EF,MAAM,QAC/IvB,EAAAC,EAAAC,cAAA,UAjBA,+CAkB4CF,EAAAC,EAAAC,cAAA,KAAGU,KAAK,sBAAR,gBAlB5C,2FAkBiLZ,EAAAC,EAAAC,cAAA,sBAlBjL,8DAkB4PF,EAAAC,EAAAC,cAAA,mBAlB5P,8DAmBAF,EAAAC,EAAAC,cAAA,oDAnBA,kDAqB+CF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,eArB5D,eAsBAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,wGAEGG,MAAM,oBAxBrB,iCA0BAtB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,uHAKZnB,EAAAC,EAAAC,cAAA,UA/BA,mBAgCgBF,EAAAC,EAAAC,cAAA,KAAGU,KAAK,oBAAR,mBAhChB,2BAgCsFZ,EAAAC,EAAAC,cAAA,mBAhCtF,yBAiCAF,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,kcA2BGG,MAAM,oBACrBtB,EAAAC,EAAAC,cAAA,OAAKQ,MAAM,SAAQV,EAAAC,EAAAC,cAAA,mBAAaF,EAAAC,EAAAC,cAAA,WAAhC,sBACoBF,EAAAC,EAAAC,cAAA,KAAGU,KAAK,oBAAR,mBADpB,cAC6EZ,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,YAD1F,yBAC2HnB,EAAAC,EAAAC,cAAA,KAAGU,KAAK,oBAAR,mBAD3H,0BACgMZ,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,cAD7M,cAEAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,8DAIZnB,EAAAC,EAAAC,cAAA,OAAKQ,MAAM,SAAQV,EAAAC,EAAAC,cAAA,mBAAaF,EAAAC,EAAAC,cAAA,WAAhC,UACQF,EAAAC,EAAAC,cAAA,yBADR,QACgCF,EAAAC,EAAAC,cAAA,yBADhC,gCAEAF,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,+HAFZ,oBAKkBnB,EAAAC,EAAAC,cAAA,KAAGU,KAAK,oBAAR,mBALlB,WAMAZ,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,gIAGGG,MAAM,YATrB,QAWAtB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,6RAXZ,0CAiBwCnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,8CAjBrD,QAiBuGnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,WAjBpH,kCAkBAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,6EAlBZ,iDAqB8CnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,oBArB3D,mBAqB6FnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,yBArB1G,SAqBsInB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,SArBnJ,yEAqBiOnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,SArB9O,gCAqBmRnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,cArBhS,IAsBAnB,EAAAC,EAAAC,cAAA,UAtBA,OAuBIF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,yBAvBjB,WAuB8CnB,EAAAC,EAAAC,cAAA,8BAvB9C,8BAwBAF,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,sFAxBZ,cA2BWnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,SA3BxB,eA2B4CnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,cA3BzD,SA2B2EnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,yBA3BxF,6DA2BuKnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,QA3BpL,kBA4BAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,uFAEGG,MAAM,aA9BrB,oCA+BiCtB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,cA/B9C,kBA+B0EnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,mCA/BvF,sBAgCAnB,EAAAC,EAAAC,cAAA,UAhCA,uBAiCoBF,EAAAC,EAAAC,cAAA,KAAGU,KAAK,aAAR,YAjCpB,YAkCAZ,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,4GAGGG,MAAM,cArCrB,MAuCAtB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,2LAvCZ,yCA4CsCnB,EAAAC,EAAAC,cAAA,KAAGU,KAAK,aAAR,YA5CtC,YA4C+EZ,EAAAC,EAAAC,cAAA,KAAGU,KAAK,YAAR,WA5C/E,QA4CkHZ,EAAAC,EAAAC,cAAA,KAAGU,KAAK,YAAR,WA5ClH,IA6CAZ,EAAAC,EAAAC,cAAA,KAAG0D,MAAM,SAAQ5D,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,oBAC9BnB,EAAAC,EAAAC,cAAA,UACAF,EAAAC,EAAAC,cAAA,OAAKQ,MAAM,UAASV,EAAAC,EAAAC,cAAA,oBAAcF,EAAAC,EAAAC,cAAA,WAAlC,6CAC0CF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,4BADvD,sFACmKnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,cADhL,yCACkOnB,EAAAC,EAAAC,cAAA,KAAGU,KAAK,oBAAR,mBADlO,uDACoUZ,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,QADjV,+CACoYnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,QADjZ,kBAGAnB,EAAAC,EAAAC,cAAA,8CAAqCF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,gBAAlD,KArHA,8BAwHAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,uFAEGG,MAAM,yBA1HrB,SA2HMtB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,UA3HnB,QA2HiCnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,MA3H9C,mFA4HAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,0cA2BGG,MAAM,0BAvJrB,wEAyJAtB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,8TAzJZ,WA4KAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,uSA5KZ,4CA2LAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,kKAGZnB,EAAAC,EAAAC,cAAA,iCAAwBF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,6BA9LrC,QAgMKnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,6BAhMlB,yDAgMkGnB,EAAAC,EAAAC,cAAA,uCAClGF,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,sGAEGG,MAAM,qBACrBtB,EAAAC,EAAAC,cAAC2B,EAAD,CAAOlB,IAAI,2BAA2BW,MAAM,iBAAiBG,OAAO,wCAAwCF,MAAM,QApMlH,6BAqM0BvB,EAAAC,EAAAC,cAAA,kCArM1B,uTAsMAF,EAAAC,EAAAC,cAAA,UAtMA,qDAuMkDF,EAAAC,EAAAC,cAAA,KAAGU,KAAK,qBAAR,oBAvMlD,uGAwMAZ,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,qIAQZnB,EAAAC,EAAAC,cAAA,UAhNA,QAiNKF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,MAjNlB,8EAiNkGnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,aAjN/G,yBAiNgJnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,MAjN7J,WAiN0KnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,cAjNvL,gCAiNgOnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,MAC7OnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,gJAlNZ,YA2NAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,4IA3NZ,wCAoOAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,sEAGZnB,EAAAC,EAAAC,cAAA,OAAKQ,MAAM,SAAQV,EAAAC,EAAAC,cAAA,mBAAaF,EAAAC,EAAAC,cAAA,WAAhC,4CAEAF,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,uIAFZ,kBAWAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,iIAIZnB,EAAAC,EAAAC,cAAA,UAfA,kBAgBeF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,gBAhB5B,+CAgBuFnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,sBAhBpG,8BAiBAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,sIAjBZ,MAqBAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,8FArBZ,aAyBAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,8IAGZnB,EAAAC,EAAAC,cAAA,KAAG0D,MAAM,SAAQ5D,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,oBAC9BnB,EAAAC,EAAAC,cAAA,UACAF,EAAAC,EAAAC,cAAA,UAAIF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,SAAjB,aAAmCnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,eArQhD,mBAuQgBnB,EAAAC,EAAAC,cAAA,KAAGU,KAAK,sBAAR,gBAvQhB,wMAuQkQZ,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,SAvQ/Q,OAwQAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,8EAxQZ,WA2QQnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,cA3QrB,aA4QAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,wGAGZnB,EAAAC,EAAAC,cAAA,UA/QA,6BAiRAF,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,kFAjRZ,SAoRMnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,SApRnB,uBAqRAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,6HArRZ,cAwRWnB,EAAAC,EAAAC,cAAA,2CAxRX,sBAwRmEF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,SAxRhF,MAyRAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,0GAzRZ,QA6RAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,wKA7RZ,sFAmSAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,0IAGZnB,EAAAC,EAAAC,cAAA,UACAF,EAAAC,EAAAC,cAAA,UACAF,EAAAC,EAAAC,cAAA,uEAxSA,0DA2SAF,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,qFAEGG,MAAM,kBACrBtB,EAAAC,EAAAC,cAAA,OAAKQ,MAAM,SAAQV,EAAAC,EAAAC,cAAA,mBAAaF,EAAAC,EAAAC,cAAA,WAAhC,2CACyCF,EAAAC,EAAAC,cAAA,KAAGU,KAAK,kBAAR,iBADzC,eAEAZ,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,qFAEGG,MAAM,sBAJrB,SAKOtB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,aALpB,oBAMAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,mEAEGG,MAAM,oCAErBtB,EAAAC,EAAAC,cAAA,OAAKQ,MAAM,SAAQV,EAAAC,EAAAC,cAAA,mBAAaF,EAAAC,EAAAC,cAAA,WAAhC,gCAC8BF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,MAD3C,2CACwFnB,EAAAC,EAAAC,cAAA,KAAGU,KAAK,mCAAR,kCADxF,8CAC+MZ,EAAAC,EAAAC,cAAA,KAAGU,KAAK,kBAAR,iBAD/M,OAEAZ,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,4GAFZ,aAMAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,uFAGZnB,EAAAC,EAAAC,cAAA,KAAG0D,MAAM,SAAQ5D,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,oBAC9BnB,EAAAC,EAAAC,cAAA,OAAKQ,MAAM,UAASV,EAAAC,EAAAC,cAAA,oBAAcF,EAAAC,EAAAC,cAAA,WAAlC,mBACiBF,EAAAC,EAAAC,cAAA,KAAGU,KAAK,mCAAR,kCADjB,mDAEAZ,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,+FAIZnB,EAAAC,EAAAC,cAAA,MAAImB,GAAG,YAAP,YAEArB,EAAAC,EAAAC,cAAA,qBAEAF,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,2DA5UZ,wBAgVAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,mEAKQnB,EAAAC,EAAAC,cAACiC,EAAAlC,EAAOmC,gBAAR,CAAwBC,UAnWpB,mBAmWgDC,OAAQqB,MCtHjEK,EA/OQ,SAACjE,GACxB,IACM4D,EAAe,CACbpB,IAAK,+BAA+BxC,EAAMwD,KAAKC,KAC/ChB,WAAY,QAAQzC,EAAMwD,KAAKC,KAC/Bf,MAAO1C,EAAM0C,OAErB,OAAOzC,EAAAC,EAAAC,cAAA,eACDF,EAAAC,EAAAC,cAACI,EAAAL,EAAD,KACED,EAAAC,EAAAC,cAAA,aAAQH,EAAMwD,KAAKd,MAAnB,aACAzC,EAAAC,EAAAC,cAAA,QAAMK,KAAK,cAAcC,QAAST,EAAMwD,KAAKE,QAEjDzD,EAAAC,EAAAC,cAAA,UAAKH,EAAM0C,OACfzC,EAAAC,EAAAC,cAAA,SAAIH,EAAM0D,MACNzD,EAAAC,EAAAC,cAAA,KAAG0D,MAAM,SAAT,gCACJ5D,EAAAC,EAAAC,cAAA,WACCF,EAAAC,EAAAC,cAAA,oCACuBF,EAAAC,EAAAC,cAAA,mCADvB,mIACoLF,EAAAC,EAAAC,cAAA,2CADpL,sJAC4WF,EAAAC,EAAAC,cAAA,4BAD5W,6HAGAF,EAAAC,EAAAC,cAAA,uDAA8CF,EAAAC,EAAAC,cAAA,KAAGU,KAAK,WAAR,oBAA9C,KACDZ,EAAAC,EAAAC,cAAA,qCALA,sEAQAF,EAAAC,EAAAC,cAAC4B,EAAA,UAAD,CAAWX,KAAK,yDARhB,SAWMnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,gDAXnB,6GAWyKnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,qBAXtL,uBAW6NnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,gDAX1O,sDAYAnB,EAAAC,EAAAC,cAAC4B,EAAA,UAAD,CAAWX,KAAK,+GAZhB,4CAeyCnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,SAftD,YAeuEnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,sBAfpF,6BAeiInB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,YAf9I,4CAeiMnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,MAf9M,YAgBAnB,EAAAC,EAAAC,cAAC4B,EAAA,UAAD,CAAWX,KAAK,yFAhBhB,oBAmBiBnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,cAnB9B,kDAmBwFnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,eAnBrG,UAmByHnB,EAAAC,EAAAC,cAAA,qBAnBzH,gBAmBqJF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,MAClKnB,EAAAC,EAAAC,cAAC4B,EAAA,UAAD,CAAWX,KAAK,yFApBhB,wBAuBqBnB,EAAAC,EAAAC,cAAA,iCAvBrB,KAuBkDF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,eAvB/D,mCAuB4GnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,MAvBzH,OAuBkInB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,0BAvB/I,gDAuBmNnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,2BAvBhO,0EAuBgUnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,MAvB7U,0FAwBqFnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,QAxBlG,iBAwBuHnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,YAxBpI,uGAyBAnB,EAAAC,EAAAC,cAAA,UAzBA,+CA0B4CF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,YA1BzD,mBA0BmFnB,EAAAC,EAAAC,cAAA,sBA1BnF,mMA0BmSF,EAAAC,EAAAC,cAAA,uCA1BnS,IA2BAF,EAAAC,EAAAC,cAAA,wCA3BA,gEA6B6DF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,SA7B1E,yBA6BwGnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,YA7BrH,mGA6B+NnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,SA7B5O,0BA6B2QnB,EAAAC,EAAAC,cAAA,uBA7B3Q,OA6BgSF,EAAAC,EAAAC,cAAA,qBA7BhS,mCA6B+UF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,YA7B5V,+CA8BAnB,EAAAC,EAAAC,cAAC4B,EAAA,UAAD,CAAWX,KAAK,8GA9BhB,oBAiCiBnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,YAjC9B,QAiC6CnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,SAjC1D,2DAkCAnB,EAAAC,EAAAC,cAAC4B,EAAA,UAAD,CAAWX,KAAK,wGAlChB,iBAqCcnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,0BArC3B,OAqCsDnB,EAAAC,EAAAC,cAAA,0BArCtD,sBAqC6FF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,MArC1G,8BAqC0InB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,SArCvJ,yBAqCqLnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,cArClM,6BAqCuOnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,SArCpP,gCAsCAnB,EAAAC,EAAAC,cAAC4B,EAAA,UAAD,CAAWX,KAAK,qGAtChB,QA0CAnB,EAAAC,EAAAC,cAAC4B,EAAA,UAAD,CAAWX,KAAK,oFA1ChB,2EA6CwEnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,YA7CrF,mFA8CAnB,EAAAC,EAAAC,cAAC4B,EAAA,UAAD,CAAWX,KAAK,mLA9ChB,QAkDAnB,EAAAC,EAAAC,cAAC4B,EAAA,UAAD,CAAWX,KAAK,uGAGhBnB,EAAAC,EAAAC,cAAA,kDArDA,gFAuD6EF,EAAAC,EAAAC,cAAA,2CAvD7E,iHAwDAF,EAAAC,EAAAC,cAAA,UAxDA,qDAyDkDF,EAAAC,EAAAC,cAAA,gJAzDlD,0WA4DAF,EAAAC,EAAAC,cAAA,UA5DA,uCA6DoCF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,MA7DjD,kCA8DAnB,EAAAC,EAAAC,cAAC4B,EAAA,UAAD,CAAWX,KAAK,oGA9DhB,SAiEMnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,kCAjEnB,QAiEsDnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,kCAjEnE,6EAiE2KnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,UAjExL,0CAiEwOnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,eAjErP,QAkEAnB,EAAAC,EAAAC,cAAC4B,EAAA,UAAD,CAAWX,KAAK,4FAlEhB,2EAsEAnB,EAAAC,EAAAC,cAAC4B,EAAA,UAAD,CAAWX,KAAK,0FAtEhB,8BAyE2BnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,2BAzExC,+CAyE6GnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,sCAzE1H,uBAyEkLnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,mCAzE/L,IA0EAnB,EAAAC,EAAAC,cAAA,UA1EA,iDA2E8CF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,eA3E3D,0BA4EAnB,EAAAC,EAAAC,cAAC4B,EAAA,UAAD,CAAWX,KAAK,maA5EhB,QAoFAnB,EAAAC,EAAAC,cAAC4B,EAAA,UAAD,CAAWX,KAAK,wGApFhB,mBAuFgBnB,EAAAC,EAAAC,cAAA,KAAGU,KAAK,KAAR,oBAvFhB,YAwFAZ,EAAAC,EAAAC,cAAC4B,EAAA,UAAD,CAAWX,KAAK,0KAxFhB,8BA4FAnB,EAAAC,EAAAC,cAAC4B,EAAA,UAAD,CAAWX,KAAK,gIA5FhB,WAgGQnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,4CAhGrB,QAiGAnB,EAAAC,EAAAC,cAAC4B,EAAA,UAAD,CAAWX,KAAK,iIAjGhB,gDAoG6CnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,eApG1D,0BAqGAnB,EAAAC,EAAAC,cAAC4B,EAAA,UAAD,CAAWX,KAAK,oGArGhB,cAwGWnB,EAAAC,EAAAC,cAAA,KAAGU,KAAK,KAAR,WAxGX,uDAyGAZ,EAAAC,EAAAC,cAAC2B,EAAD,CAAOlB,IAAI,kBAAkBY,MAAM,QAzGnC,kFA2G+EvB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,UA3G5F,uBA2GyHnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,UA3GtI,4KA2GwTnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,SA3GrU,8DA6GAnB,EAAAC,EAAAC,cAAA,4CA7GA,oCA+GiCF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,uBA/G9C,uLA+GwPnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,YA/GrQ,QA+GqRnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,QA/GlS,wBAgHAnB,EAAAC,EAAAC,cAAC4B,EAAA,UAAD,CAAWX,KAAK,gFAhHhB,mBAmHgBnB,EAAAC,EAAAC,cAAA,KAAGU,KAAK,KAAR,YAnHhB,SAmH8CZ,EAAAC,EAAAC,cAAA,KAAGU,KAAK,KAAR,qBAnH9C,UAoHAZ,EAAAC,EAAAC,cAAC4B,EAAA,UAAD,CAAWX,KAAK,yRApHhB,gDAyH6CnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,MAzH1D,qFAyHiJnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,MAzH9J,4FAyH4PnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,yBAzHzQ,qBA0HAnB,EAAAC,EAAAC,cAAC4B,EAAA,UAAD,CAAWX,KAAK,uIA1HhB,gMA+HAnB,EAAAC,EAAAC,cAAA,UA/HA,0BAgIuBF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,QAhIpC,kHAgI0JnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,yBAhIvK,gBAiIAnB,EAAAC,EAAAC,cAAA,iDAjIA,gKAmIAF,EAAAC,EAAAC,cAAC4B,EAAA,UAAD,CAAWX,KAAK,qMAnIhB,yCAyIAnB,EAAAC,EAAAC,cAAC4B,EAAA,UAAD,CAAWX,KAAK,6FAzIhB,sEA4ImEnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,uBA5IhF,sHA6IAnB,EAAAC,EAAAC,cAAC4B,EAAA,UAAD,CAAWX,KAAK,qGA7IhB,wCAiJAnB,EAAAC,EAAAC,cAAC4B,EAAA,UAAD,CAAWX,KAAK,iJAjJhB,OAsJAnB,EAAAC,EAAAC,cAAC4B,EAAA,UAAD,CAAWX,KAAK,4PAMhBnB,EAAAC,EAAAC,cAAA,+CA5JA,mFA8JgFF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,eA9J7F,6HA8JqOnB,EAAAC,EAAAC,cAAA,kCA9JrO,IA+JAF,EAAAC,EAAAC,cAAA,UA/JA,yYAgKsYF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,eAhKnZ,mBAkKAnB,EAAAC,EAAAC,cAAA,UAlKA,uDAoKAF,EAAAC,EAAAC,cAAC4B,EAAA,UAAD,CAAWX,KAAK,oFApKhB,wCAwKqCnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,wBAxKlD,2EAwK+InB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,uBAxK5J,UAwKwLnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,cAxKrM,iBAwKgOnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,qCAxK7O,cAwKuRnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,YAxKpS,QAwKoTnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,YAxKjU,YAwKqVnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,aAxKlW,UAwKoXnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,cAxKjY,sBAwKianB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,YAxK9a,iDAyKAnB,EAAAC,EAAAC,cAAA,UAzKA,4HA0KyHF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,YA1KtI,8BA0K4KnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,YA1KzL,iGA2KAnB,EAAAC,EAAAC,cAAA,UA3KA,4CA4KyCF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,8BA5KtD,kBA4KgGnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,8CA5K7G,iDA6KuBnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,iCA7KpC,kDA6KgHnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,MA7K7H,0DA6KyLnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,eA7KtM,aA6K8NnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,sCA7K3O,sFA8KAnB,EAAAC,EAAAC,cAAA,UA9KA,sDA+KmDF,EAAAC,EAAAC,cAAA,+CA/KnD,qDA+K8IF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,MA/K3J,kDA+K+MnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,sBA/K5N,kHA+K+VnB,EAAAC,EAAAC,cAAA,KAAGU,KAAK,KAAR,WA/K/V,8BAgLAZ,EAAAC,EAAAC,cAAC2B,EAAD,CAAOlB,IAAI,kBAAkBY,MAAM,QACnCvB,EAAAC,EAAAC,cAAA,wCAjLA,eAmLYF,EAAAC,EAAAC,cAAA,KAAGU,KAAK,WAAR,mBAnLZ,SAmLuDZ,EAAAC,EAAAC,cAAA,6CAnLvD,gGAmL2LF,EAAAC,EAAAC,cAAA,+BAnL3L,8CAoLAF,EAAAC,EAAAC,cAAC4B,EAAA,UAAD,CAAWX,KAAK,4EApLhB,YAwLSnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,gCAxLtB,6DAwL8GnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,gCAxL3H,gBAwLoKnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,oCAxLjL,2EAyLAnB,EAAAC,EAAAC,cAAC4B,EAAA,UAAD,CAAWX,KAAK,8EAzLhB,yEA4LuEnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,2BA5LpF,YA4LsHnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,kBA5LnI,0CA6LAnB,EAAAC,EAAAC,cAAC4B,EAAA,UAAD,CAAWX,KAAK,sEAIhBnB,EAAAC,EAAAC,cAAA,kBAjMA,4DAmMyDF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,QAnMtE,6MAmMuRnB,EAAAC,EAAAC,cAAA,8BAnMvR,iBAoMAF,EAAAC,EAAAC,cAAA,kBApMA,sIAuMAF,EAAAC,EAAAC,cAAA,yDAvMA,oGAyMiGF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,QAzM9G,yLA0MAnB,EAAAC,EAAAC,cAAC4B,EAAA,UAAD,CAAWX,KAAK,yGA1MhB,SA6MMnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,iBA7MnB,QA6MuCnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,iBA7MpD,4EA6M4InB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,MA7MzJ,sBA6MiLnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,QA7M9L,0DA6M4PnB,EAAAC,EAAAC,cAAA,gDA7M5P,WA8MAF,EAAAC,EAAAC,cAAA,UA9MA,8XAiNAF,EAAAC,EAAAC,cAAA,OAAKC,UAAU,UACdH,EAAAC,EAAAC,cAAA,qBADD,sMAIAF,EAAAC,EAAAC,cAAA,yBACAF,EAAAC,EAAAC,cAAA,SAAGF,EAAAC,EAAAC,cAAA,KAAGK,KAAK,WAAX,wNAGAP,EAAAC,EAAAC,cAAA,SAAGF,EAAAC,EAAAC,cAAA,KAAGK,KAAK,WAAX,kKAGAP,EAAAC,EAAAC,cAACiC,EAAAlC,EAAOmC,gBAAR,CAAwBC,UA1OA,mBA0O4BC,OAAQqB,MC4EzBM,EAtTrB,SAAClE,GACf,IACM4D,EAAe,CACbpB,IAAK,+BAA+BxC,EAAMwD,KAAKC,KAC/ChB,WAAY,QAAQzC,EAAMwD,KAAKC,KAC/Bf,MAAO1C,EAAM0C,OAErB,OAAOzC,EAAAC,EAAAC,cAAA,eACDF,EAAAC,EAAAC,cAACI,EAAAL,EAAD,KACED,EAAAC,EAAAC,cAAA,aAAQH,EAAMwD,KAAKd,MAAnB,aACAzC,EAAAC,EAAAC,cAAA,QAAMK,KAAK,cAAcC,QAAST,EAAMwD,KAAKE,QAEjDzD,EAAAC,EAAAC,cAAA,UAAKH,EAAM0C,OACfzC,EAAAC,EAAAC,cAAA,SAAIH,EAAM0D,MACNzD,EAAAC,EAAAC,cAAA,KAAG0D,MAAM,SAAT,qCACJ5D,EAAAC,EAAAC,cAAA,WACAF,EAAAC,EAAAC,cAAA,0BADA,sCAGmCF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,MAHhD,+BAGiFnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,4BAH9F,eAGmInB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,yCAHhJ,6DAGiPnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,yBAH9P,wKAIAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,yGAJZ,8DAO2DnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,gDAPxE,iFASAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,yFATZ,SAYMnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,4BAZnB,OAaAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,6RAbZ,kGAuB+FnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,iCAvB5G,4BAuBmKnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,kCAvBhL,yHAuBqUnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,4BAvBlV,iBAuByXnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,sDAvBtY,iCAwBAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,2FAxBZ,iDA2B8CnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,aA3B3D,kFA4B8DnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,QA5B3E,cA4B6FnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,8BA5B1G,KA6BAnB,EAAAC,EAAAC,cAAA,UA7BA,iIA8B8HF,EAAAC,EAAAC,cAAA,qBA9B9H,qVA+BAF,EAAAC,EAAAC,cAAA,UA/BA,wBAgCqBF,EAAAC,EAAAC,cAAA,2BAhCrB,qKAiCAF,EAAAC,EAAAC,cAAA,UAjCA,0IAkCuIF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,QAlCpJ,yDAmCAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,qIAGGG,MAAM,aAtCrB,aAuCUtB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,MAvCvB,yEAuCkGnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,MAvC/G,gIAwCAnB,EAAAC,EAAAC,cAAA,UAxCA,eAyCYF,EAAAC,EAAAC,cAAA,KAAGU,KAAK,aAAR,YAzCZ,qDAyC8FZ,EAAAC,EAAAC,cAAA,4BAC9FF,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,iHAEGG,MAAM,aA5CrB,oFA6CiFtB,EAAAC,EAAAC,cAAA,KAAGU,KAAK,aAAR,YA7CjF,QA6CsHZ,EAAAC,EAAAC,cAAA,KAAGU,KAAK,aAAR,YA7CtH,cA6CiKZ,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,MA7C9K,oBA6CoMnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,yBA7CjN,OA6CyOnB,EAAAC,EAAAC,cAAA,KAAGU,KAAK,aAAR,YA7CzO,sCA6C4SZ,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,aA7CzT,QA6CyUnB,EAAAC,EAAAC,cAAA,KAAGU,KAAK,aAAR,YA7CzU,4DA6CkaZ,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,aA7C/a,kBA6CycnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,2BA7Ctd,8CA6CwhBnB,EAAAC,EAAAC,cAAA,KAAGU,KAAK,aAAR,YA7CxhB,SA6C8jBZ,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,qCA7C3kB,IA8CAnB,EAAAC,EAAAC,cAAA,OAAKQ,MAAM,UAASV,EAAAC,EAAAC,cAAA,oBAAcF,EAAAC,EAAAC,cAAA,WAAlC,yDACuDF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,SADpE,yBACkGnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,QAD/G,OAC0HnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,MADvI,kCAC2KnB,EAAAC,EAAAC,cAAA,KAAGU,KAAK,aAAR,YAD3K,sCAC8OZ,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,aAD3P,OAC0QnB,EAAAC,EAAAC,cAAA,KAAGU,KAAK,aAAR,YAD1Q,iDACwVZ,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,aADrW,gFAGAnB,EAAAC,EAAAC,cAAA,4BAjDA,gHAmD6GF,EAAAC,EAAAC,cAAA,KAAGU,KAAK,aAAR,YAnD7G,iBAoDAZ,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,gFAEGG,MAAM,mBAtDrB,SAuDMtB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,4BAvDnB,0DAuDoGnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,uBAvDjH,OAuD0InB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,oBAvDvJ,OAuD4KnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,oBAvDzL,8CAuDsPnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,kBAvDnQ,eAuD8RnB,EAAAC,EAAAC,cAAA,KAAGU,KAAK,aAAR,YAvD9R,oBAuD+UZ,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,6BAvD5V,OAuDyXnB,EAAAC,EAAAC,cAAA,KAAGU,KAAK,mBAAR,kBAvDzX,+GAwDAZ,EAAAC,EAAAC,cAAA,UAxDA,iHAyD8GF,EAAAC,EAAAC,cAAA,+BAzD9G,IA0DAF,EAAAC,EAAAC,cAAA,2CA1DA,uCA6DAF,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,sHAEGG,MAAM,mBA/DrB,SAgEMtB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,4BAhEnB,uCAiEAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,oVAjEZ,QA0EKnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,4BA1ElB,IA2EAnB,EAAAC,EAAAC,cAAA,OAAKQ,MAAM,SAAQV,EAAAC,EAAAC,cAAA,mBAAaF,EAAAC,EAAAC,cAAA,WAAhC,QACMF,EAAAC,EAAAC,cAAA,KAAGU,KAAK,mBAAR,kBADN,aAEAZ,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,4NAFZ,6BAOAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,qIAPZ,MAUGnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,gBAVhB,SAUoCnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,4CAVjD,2BAUkHnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,eAV/H,SAUkJnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,4CAV/J,eAUoNnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,eAVjO,YAUuPnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,iDAVpQ,kBAUgUnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,2BAV7U,sBAWCnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,iEAXd,IAYAnB,EAAAC,EAAAC,cAAA,KAAG0D,MAAM,SAAQ5D,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,oBAC9BnB,EAAAC,EAAAC,cAAA,UAxFA,oDAyFiDF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,gCAzF9D,QAyFgGnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,gCAzF7G,wCA0FAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,4UASZnB,EAAAC,EAAAC,cAAA,UAnGA,sDAqGAF,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,4GArGZ,SAwGMnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,0BAxGnB,WAwGkDnB,EAAAC,EAAAC,cAAA,wCAClDF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,qDAzGb,gCAyG2FnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,MAzGxG,+BAyGyInB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,aAzGtJ,2BAyGyLnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,qBAzGtM,QAyG6NnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,qBAzG1O,iCAyG2RnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,MAzGxS,cAyGwTnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,MAzGrU,OAyG8UnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,QAzG3V,uBA0GAnB,EAAAC,EAAAC,cAAA,UA1GA,8EA4GAF,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,iHAGZnB,EAAAC,EAAAC,cAAA,oDA/GA,oLAiHiLF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,WAjH9L,oCAiHyOnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,aAjHtP,gDAiH8SnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,sBAjH3T,KAkHAnB,EAAAC,EAAAC,cAAA,UAlHA,oCAoHAF,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,kMApHZ,qCAuHkCnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,aAvH/C,gDAuHuGnB,EAAAC,EAAAC,cAAA,6BACvGF,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,+FAxHZ,oDA4HAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,2eA5HZ,SAgIMnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,uCAhInB,QAgI6DnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,oDAhI1E,iCAiI4BnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,MAjIzC,mBAkIAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,yJAlIZ,gDAqI6CnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,WArI1D,6BAsIAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,gIAtIZ,oCAyIiCnB,EAAAC,EAAAC,cAAA,0BAzIjC,IAyIsDF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,oDAzInE,YA0IAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,0OAGZnB,EAAAC,EAAAC,cAAA,UA7IA,6DA8I0DF,EAAAC,EAAAC,cAAA,wCA9I1D,2EA+IAF,EAAAC,EAAAC,cAAA,UA/IA,+SAiJiHF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,aAjJ9H,sEAiJ4MnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,aAjJzN,WAkJAnB,EAAAC,EAAAC,cAAA,UAlJA,gEAmJ6DF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,aAnJ1E,wGAmJ0LnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,mDAnJvM,sBAmJyQnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,aAnJtR,+EAmJ6WnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,aAnJ1X,mLAmJqjBnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,aAnJlkB,uCAmJinBnB,EAAAC,EAAAC,cAAA,wCAnJjnB,IAoJAF,EAAAC,EAAAC,cAAA,OAAKQ,MAAM,UAASV,EAAAC,EAAAC,cAAA,oBAAcF,EAAAC,EAAAC,cAAA,WAAlC,oMACkMF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,aAD/M,yGACgUnB,EAAAC,EAAAC,cAAA,mCADhU,2FAGAF,EAAAC,EAAAC,cAAA,iDAvJA,oHA0JAF,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,sGA1JZ,2CA8JAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,yFA9JZ,qIAkKAnB,EAAAC,EAAAC,cAAA,UAlKA,iCAmK8BF,EAAAC,EAAAC,cAAA,8BAnK9B,oGAoKAF,EAAAC,EAAAC,cAAA,8BApKA,yCAuKAF,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,wHAEGG,MAAM,mBAzKrB,6BA0K0BtB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,iBA1KvC,kBA2KAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,6KAGZnB,EAAAC,EAAAC,cAAA,OAAKQ,MAAM,WAAUV,EAAAC,EAAAC,cAAA,qBAAeF,EAAAC,EAAAC,cAAA,WAApC,oBACkBF,EAAAC,EAAAC,cAAA,KAAGU,KAAK,mBAAR,kBADlB,oBAEAZ,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,uGAIZnB,EAAAC,EAAAC,cAAA,OAAKQ,MAAM,SAAQV,EAAAC,EAAAC,cAAA,mBAAaF,EAAAC,EAAAC,cAAA,WAAhC,eACaF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,WAD1B,yBAEAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,oUAMZnB,EAAAC,EAAAC,cAAA,UARA,yBASuBF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,oFATpC,6DAUyDnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,cAVtE,YAWAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,2ZAXZ,yBA2BAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,8RAKZnB,EAAAC,EAAAC,cAAA,KAAG0D,MAAM,SAAQ5D,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,oBAC9BnB,EAAAC,EAAAC,cAAA,qCArNA,sFAuNmFF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,WAvNhG,6LAwNAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,uGAxNZ,qBA4NAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,yMA5NZ,kMA+N+LnB,EAAAC,EAAAC,cAAA,KAAGU,KAAK,2BAAR,0BAC/LZ,EAAAC,EAAAC,cAAC2B,EAAD,CAAOlB,IAAI,iCAAiCW,MAAM,yBAAyBG,OAAO,8DAA8DF,MAAM,QACtJvB,EAAAC,EAAAC,cAAA,UAjOA,yGAmOAF,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,wFAnOZ,uCAuOAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,yFAGZnB,EAAAC,EAAAC,cAAA,OAAKQ,MAAM,UAASV,EAAAC,EAAAC,cAAA,oBAAcF,EAAAC,EAAAC,cAAA,WAAlC,2RAGAF,EAAAC,EAAAC,cAAA,kCA7OA,uLA+OoLF,EAAAC,EAAAC,cAAA,sBA/OpL,mKAgPAF,EAAAC,EAAAC,cAAA,UAhPA,2FAkPAF,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,iMAlPZ,gFAsPAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,mIAtPZ,SAyPMnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,UAzPnB,8BAyPsDnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,6CAzPnE,OAyP+GnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,qCAzP5H,uBA0PAnB,EAAAC,EAAAC,cAAA,UA1PA,qEA4PAF,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,2JA5PZ,MAgQAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,0MAGZnB,EAAAC,EAAAC,cAAA,iCAEAF,EAAAC,EAAAC,cAAA,4BAEAF,EAAAC,EAAAC,cAAA,UACAF,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,wFAGZnB,EAAAC,EAAAC,cAAA,UACAF,EAAAC,EAAAC,cAAA,yBAEAF,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,6HAGZnB,EAAAC,EAAAC,cAAA,yBAEAF,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,2IAGZnB,EAAAC,EAAAC,cAAA,2BAtRA,aAyRAF,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,uFAGZnB,EAAAC,EAAAC,cAAA,UA5RA,YA8RAF,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,sGA9RZ,uDAiSoDnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,QAjSjE,KAiS0EnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,QAjSvF,QAiSmGnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,8BAjShH,KAoSoBnB,EAAAC,EAAAC,cAACiC,EAAAlC,EAAOmC,gBAAR,CAAwBC,UAlTpB,mBAkTgDC,OAAQqB,MC3HjEO,EAzLW,SAACnE,GAC3B,IACM4D,EAAe,CACbpB,IAAK,+BAA+BxC,EAAMwD,KAAKC,KAC/ChB,WAAY,QAAQzC,EAAMwD,KAAKC,KAC/Bf,MAAO1C,EAAM0C,OAErB,OAAOzC,EAAAC,EAAAC,cAAA,eACDF,EAAAC,EAAAC,cAACI,EAAAL,EAAD,KACED,EAAAC,EAAAC,cAAA,aAAQH,EAAMwD,KAAKd,MAAnB,aACAzC,EAAAC,EAAAC,cAAA,QAAMK,KAAK,cAAcC,QAAST,EAAMwD,KAAKE,QAEjDzD,EAAAC,EAAAC,cAAA,UAAKH,EAAM0C,OACfzC,EAAAC,EAAAC,cAAA,SAAIH,EAAM0D,MACNzD,EAAAC,EAAAC,cAAA,KAAG0D,MAAM,SAAT,kCACJ5D,EAAAC,EAAAC,cAAA,WACIF,EAAAC,EAAAC,cAAA,uDAC+CF,EAAAC,EAAAC,cAAA,KAAGU,KAAK,WAAR,gBAD/C,KAGJZ,EAAAC,EAAAC,cAAA,6BAJA,gQAM6PF,EAAAC,EAAAC,cAAA,UAN7P,wVAQqVF,EAAAC,EAAAC,cAAA,UARrV,gLAWAF,EAAAC,EAAAC,cAAA,UAXA,4nBAYynBF,EAAAC,EAAAC,cAAA,UAZznB,4UAcyUF,EAAAC,EAAAC,cAAA,UAdzU,+TAgB4TF,EAAAC,EAAAC,cAAA,UAC5TF,EAAAC,EAAAC,cAAA,UAjBA,+NAmBAF,EAAAC,EAAAC,cAAA,UAnBA,yXAqBAF,EAAAC,EAAAC,cAAA,UArBA,4NAuBAF,EAAAC,EAAAC,cAAA,UAvBA,kNAyBAF,EAAAC,EAAAC,cAAA,UAzBA,iZA2BAF,EAAAC,EAAAC,cAAA,UA3BA,ydA6BAF,EAAAC,EAAAC,cAAA,UA7BA,4YA+BAF,EAAAC,EAAAC,cAAA,UA/BA,wKAgCqKF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,0BAhClL,0DAgC+PnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,0BAhC5Q,uFAiCkFnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,sCAjC/F,uCAiCqKnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,sCAjClL,0NAkCAnB,EAAAC,EAAAC,cAAC4B,EAAA,UAAD,CAAWX,KAAK,8GAlChB,SAqCMnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,eArCnB,4DAqC0FnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,uBArCvG,qDAqC+KnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,eArC5L,+CAqCsPnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,yCArCnQ,iEAsCAnB,EAAAC,EAAAC,cAAC4B,EAAA,UAAD,CAAWX,KAAK,gGAtChB,ioBA2CAnB,EAAAC,EAAAC,cAAA,UA3CA,qSA6CAF,EAAAC,EAAAC,cAAA,UA7CA,8CA+CAF,EAAAC,EAAAC,cAAA,UACCF,EAAAC,EAAAC,cAAA,kFACsEF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,WADnF,wBACkHnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,QAD/H,6BACgKnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,QAD7K,KAGAnB,EAAAC,EAAAC,cAAA,oKAA2JF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,mBAAxK,KAEAnB,EAAAC,EAAAC,cAAA,+DAAsDF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,QAAnE,iCAAwGnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,QAArH,+IAAwQnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,eAArR,MArDD,iQA0DAnB,EAAAC,EAAAC,cAAA,UACCF,EAAAC,EAAAC,cAAA,UAAIF,EAAAC,EAAAC,cAAA,oCAAJ,wFAAuHF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,QAApI,+CAAuLnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,kCAApM,IACDnB,EAAAC,EAAAC,cAAC4B,EAAA,UAAD,CAAWX,KAAK,iFAIhBnB,EAAAC,EAAAC,cAAA,UAAIF,EAAAC,EAAAC,cAAA,qCAAJ,6HAA6JF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,YAA1K,KAAuLnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,MAApM,sCACAnB,EAAAC,EAAAC,cAAC4B,EAAA,UAAD,CAAWX,KAAK,6GAIhBnB,EAAAC,EAAAC,cAAA,UAAIF,EAAAC,EAAAC,cAAA,oCAAJ,kFAAiHF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,QAA9H,6BAA+JnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,kCAA5K,yBAAgOnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,QAA7O,IACAnB,EAAAC,EAAAC,cAAC4B,EAAA,UAAD,CAAWX,KAAK,qFAtEhB,4MA6EAnB,EAAAC,EAAAC,cAAA,UA7EA,kBA8EeF,EAAAC,EAAAC,cAAA,0BA9Ef,kFA8EkHF,EAAAC,EAAAC,cAAA,gCA9ElH,qGA8E8OF,EAAAC,EAAAC,cAAA,yBA9E9O,QA8EsQF,EAAAC,EAAAC,cAAA,2BA9EtQ,4DA+EAF,EAAAC,EAAAC,cAAA,UA/EA,iMAiFAF,EAAAC,EAAAC,cAAA,UACCF,EAAAC,EAAAC,cAAA,UAAIF,EAAAC,EAAAC,cAAA,uCAAJ,yNACAF,EAAAC,EAAAC,cAAA,UAAOF,EAAAC,EAAAC,cAAA,cAAKF,EAAAC,EAAAC,cAAA,sDAAL,4EACPF,EAAAC,EAAAC,cAAA,UAAOF,EAAAC,EAAAC,cAAA,cAAKF,EAAAC,EAAAC,cAAA,yCAAL,6HAAkKF,EAAAC,EAAAC,cAAA,gCAAlK,oDACPF,EAAAC,EAAAC,cAAA,UAAOF,EAAAC,EAAAC,cAAA,cAAKF,EAAAC,EAAAC,cAAA,uDAAL,4EACPF,EAAAC,EAAAC,cAAA,UAAOF,EAAAC,EAAAC,cAAA,cAAKF,EAAAC,EAAAC,cAAA,2CAAL,OAA8CF,EAAAC,EAAAC,cAAA,gDAA9C,mFACPF,EAAAC,EAAAC,cAAA,UAAOF,EAAAC,EAAAC,cAAA,cAAKF,EAAAC,EAAAC,cAAA,0CAAL,aAAmDF,EAAAC,EAAAC,cAAA,sDAAnD,qJACPF,EAAAC,EAAAC,cAAA,UAAOF,EAAAC,EAAAC,cAAA,cAAKF,EAAAC,EAAAC,cAAA,6DAAL,iJAxFR,qEA2FAF,EAAAC,EAAAC,cAAA,8DA3FA,mIA8FAF,EAAAC,EAAAC,cAAC4B,EAAA,UAAD,CAAWX,KAAK,oHA9FhB,SAmGMnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,2BAnGnB,4CAmGoFnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,MAnGjG,KAmGwGnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,2BAnGrH,oCAmG8KnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,MAnG3L,KAmGkMnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,mBAnG/M,mFAmGiTnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,eAnG9T,+KAsGAnB,EAAAC,EAAAC,cAAC4B,EAAA,UAAD,CAAWX,KAAK,uIAtGhB,0CA0GuCnB,EAAAC,EAAAC,cAAA,qDA1GvC,cA2GAF,EAAAC,EAAAC,cAAC4B,EAAA,UAAD,CAAWX,KAAK,8EA3GhB,mFA+GgFnB,EAAAC,EAAAC,cAAA,qCA/GhF,0BA+GsIF,EAAAC,EAAAC,cAAA,6BA/GtI,yCAgHAF,EAAAC,EAAAC,cAAC4B,EAAA,UAAD,CAAWX,KAAK,oIAhHhB,6BAoH0BnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,MApHvC,yEAoHkHnB,EAAAC,EAAAC,cAAA,wBApHlH,8eAsHAF,EAAAC,EAAAC,cAAA,gCAtHA,8HAwH2HF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,QAxHxI,sBAwHkKnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,MAxH/K,0DAwH2OnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,MAxHxP,IAyHAnB,EAAAC,EAAAC,cAAC4B,EAAA,UAAD,CAAWX,KAAK,wDAIhBnB,EAAAC,EAAAC,cAAA,OAAKC,UAAU,SACXH,EAAAC,EAAAC,cAAA,mBAAaF,EAAAC,EAAAC,cAAA,WADjB,uFAGAF,EAAAC,EAAAC,cAAA,UACCF,EAAAC,EAAAC,cAAA,UAAIF,EAAAC,EAAAC,cAAA,4BAAJ,qDAA4EF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,WAAzF,KACAnB,EAAAC,EAAAC,cAAA,UAAIF,EAAAC,EAAAC,cAAA,6BAAJ,6CAAqEF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,QAAlF,qBAA2GnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,MAAxH,qDAA+KnB,EAAAC,EAAAC,cAAA,wCAChLF,EAAAC,EAAAC,cAAC4B,EAAA,UAAD,CAAWX,KAAK,+GAIfnB,EAAAC,EAAAC,cAAA,cAAKF,EAAAC,EAAAC,cAAA,yBAAL,0BAA+CF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,QAA5D,iBAAiFnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,MAA9F,4CAA4InB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,QAAzJ,uBAAoLnB,EAAAC,EAAAC,cAAA,wBACrLF,EAAAC,EAAAC,cAAC4B,EAAA,UAAD,CAAWX,KAAK,kGADf,sBAImBnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,MAJhC,wCAKDnB,EAAAC,EAAAC,cAAC4B,EAAA,UAAD,CAAWX,KAAK,sFAMhBnB,EAAAC,EAAAC,cAAA,OAAKC,UAAU,SAAQH,EAAAC,EAAAC,cAAA,mBAAaF,EAAAC,EAAAC,cAAA,WAApC,0FAEAF,EAAAC,EAAAC,cAAC4B,EAAA,UAAD,CAAWX,KAAK,sXAFhB,aASAnB,EAAAC,EAAAC,cAAC4B,EAAA,UAAD,CAAWX,KAAK,0ZAOhBnB,EAAAC,EAAAC,cAAA,KAAG0D,MAAM,SAAQ5D,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,oBAE9BnB,EAAAC,EAAAC,cAAA,yBACAF,EAAAC,EAAAC,cAAA,SAAGF,EAAAC,EAAAC,cAAA,KAAGK,KAAK,WAAX,0FAEAP,EAAAC,EAAAC,cAACiC,EAAAlC,EAAOmC,gBAAR,CAAwBC,UArLA,mBAqL4BC,OAAQqB,MC0PzBQ,EA/aT,SAACpE,GAC3B,IACM4D,EAAe,CACbpB,IAAK,+BAA+BxC,EAAMwD,KAAKC,KAC/ChB,WAAY,QAAQzC,EAAMwD,KAAKC,KAC/Bf,MAAO1C,EAAM0C,OAErB,OAAOzC,EAAAC,EAAAC,cAAA,eACDF,EAAAC,EAAAC,cAACI,EAAAL,EAAD,KACED,EAAAC,EAAAC,cAAA,aAAQH,EAAMwD,KAAKd,MAAnB,aACAzC,EAAAC,EAAAC,cAAA,QAAMK,KAAK,cAAcC,QAAST,EAAMwD,KAAKE,QAEjDzD,EAAAC,EAAAC,cAAA,UAAKH,EAAM0C,OACfzC,EAAAC,EAAAC,cAAA,SAAIH,EAAM0D,MACNzD,EAAAC,EAAAC,cAAA,KAAG0D,MAAM,SAAT,qCACJ5D,EAAAC,EAAAC,cAAA,WACAF,EAAAC,EAAAC,cAAA,0BADA,mdAKAF,EAAAC,EAAAC,cAAA,UALA,soBAOAF,EAAAC,EAAAC,cAAA,UAPA,8TASAF,EAAAC,EAAAC,cAAA,UATA,0QAWAF,EAAAC,EAAAC,cAAA,UAXA,sHAYmHF,EAAAC,EAAAC,cAAA,KAAGU,KAAK,oBAAR,cAZnH,yKAaAZ,EAAAC,EAAAC,cAAA,UAbA,mEAcgEF,EAAAC,EAAAC,cAAA,8CAdhE,yNAc8TF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,mBAd3U,UAcoWnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,yBAdjX,4BAcganB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,YAd7a,2DAcgfnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,MAd7f,IAeAnB,EAAAC,EAAAC,cAAA,UAfA,+JAgB4JF,EAAAC,EAAAC,cAAA,uCAhB5J,IAiBAF,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,wGAEGG,MAAM,yBAnBrB,+DAoB4DtB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,mBApBzE,sKAoB8PnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,mBApB3Q,6EAqBAnB,EAAAC,EAAAC,cAAA,UArBA,sCAsBmCF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,YAtBhD,4HAsBoLnB,EAAAC,EAAAC,cAAA,wBAtBpL,IAuBAF,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,8HAEGG,MAAM,kBAzBrB,SA0BMtB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,uBA1BnB,mEA0ByGnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,uBA1BtH,qCA2BAnB,EAAAC,EAAAC,cAAA,UA3BA,0HA4BuHF,EAAAC,EAAAC,cAAA,KAAGU,KAAK,yBAAR,wBA5BvH,yCA4BqNZ,EAAAC,EAAAC,cAAA,KAAGU,KAAK,kBAAR,iBA5BrN,wHA6BAZ,EAAAC,EAAAC,cAAA,UA7BA,qEA8BkEF,EAAAC,EAAAC,cAAA,KAAGU,KAAK,yBAAR,wBA9BlE,IA8B2HZ,EAAAC,EAAAC,cAAA,KAAGU,KAAK,kBAAR,iBA9B3H,8EA+BAZ,EAAAC,EAAAC,cAAA,UACAF,EAAAC,EAAAC,cAAA,yCAhCA,uDAmCAF,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,8DAEGG,MAAM,mBArCrB,SAsCMtB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,kCAtCnB,2BAsCyEnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,kCAtCtF,yBAsC0InB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,yBAtCvJ,yBAsCmMnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,kCAtChN,mFAsC8TnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,gCAtC3U,6DAsCkanB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,oDAtC/a,mBAsC8enB,EAAAC,EAAAC,cAAA,8BAtC9e,IAuCAF,EAAAC,EAAAC,cAAA,UACAF,EAAAC,EAAAC,cAAA,OAAKQ,MAAM,UAASV,EAAAC,EAAAC,cAAA,oBAAcF,EAAAC,EAAAC,cAAA,WAAlC,mJAGAF,EAAAC,EAAAC,cAAA,UA3CA,QA4CKF,EAAAC,EAAAC,cAAA,KAAGU,KAAK,mBAAR,kBA5CL,4CA4C0FZ,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,QA5CvG,kBA4C6HnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,QA5C1I,sCA4CoLnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,SA5CjM,gBA4CsNnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,YA5CnO,mCA4C8QnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,gBA5C3R,mBA4C0TnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,YA5CvU,6GA6CAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,iGAGZnB,EAAAC,EAAAC,cAAA,UAhDA,qEAiDkEF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,qDAjD/E,yEAkDAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,6GAlDZ,QAsDAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,yHAtDZ,sCA0DmCnB,EAAAC,EAAAC,cAAA,KAAGU,KAAK,uBAAR,sBA1DnC,IA2DAZ,EAAAC,EAAAC,cAAA,UA3DA,0DA6DAF,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,4EAEGG,MAAM,gBA/DrB,SAgEMtB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,kCAhEnB,6BAgE2EnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,+CAhExF,kNAgEkVnB,EAAAC,EAAAC,cAAA,KAAGU,KAAK,gBAAR,eAhElV,qBAgE0YZ,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,YAhEvZ,wFAiEAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,qGAjEZ,6GAqEAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,oHArEZ,QAyEAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,mMAzEZ,sCA8EmCnB,EAAAC,EAAAC,cAAA,KAAGU,KAAK,uBAAR,sBACnCZ,EAAAC,EAAAC,cAAA,UA/EA,mDAgFgDF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,qDAhF7D,8DAgFyKnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,sBAhFtL,gCAiFAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,wRAOZnB,EAAAC,EAAAC,cAAA,UAxFA,mNAyFgNF,EAAAC,EAAAC,cAAA,KAAGU,KAAK,0BAAR,yBAzFhN,0DA0FAZ,EAAAC,EAAAC,cAAA,UACAF,EAAAC,EAAAC,cAAC2B,EAAD,CAAOlB,IAAI,gCAAgCW,MAAM,wBAAwBG,OAAO,4CAA4CF,MAAM,QAClIvB,EAAAC,EAAAC,cAAA,UA5FA,sHA6FmHF,EAAAC,EAAAC,cAAA,wBA7FnH,IA8FAF,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,2FA9FZ,uFAkGAnB,EAAAC,EAAAC,cAAA,UACAF,EAAAC,EAAAC,cAAA,kCAnGA,iJAqG8IF,EAAAC,EAAAC,cAAA,KAAGU,KAAK,4BAAR,2BArG9I,IAsGAZ,EAAAC,EAAAC,cAAC2B,EAAD,CAAOlB,IAAI,mCAAmCW,MAAM,0BAA0BG,OAAO,uBAAuBF,MAAM,QAtGlH,gCAuG6BvB,EAAAC,EAAAC,cAAA,0CAvG7B,uEAuGqIF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,oBAvGlJ,oCAwGAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,4QAxGZ,gJAuH6InB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,iCAvH1J,uGAwHAnB,EAAAC,EAAAC,cAAA,UAxHA,mIA0HAF,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,sEA1HZ,SA6HMnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,2CA7HnB,2DA6HkHnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,OA7H/H,8DA6HgMnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,MA7H7M,2HA6H0UnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,iDA7HvV,UA6H2YnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,6BA7HxZ,6BA6H6cnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,kCA7H1d,8BA6HshBnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,UA7HniB,8CA6HslBnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,gBA7HnmB,qBA6HmoBnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,eA7HhpB,KA6H+pBnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,aA7H5qB,8EA6HkwBnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,OA7H/wB,6DA6H+0BnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,WA7H51B,WA6H82BnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,aA7H33B,KA6Hy4BnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,iBA7Ht5B,WA6H86BnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,mBA7H37B,QA6Hi9BnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,2BA7H99B,SA6H6/BnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,UA7H1gC,2DA8HAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,qiBA9HZ,kEAkJ+DnB,EAAAC,EAAAC,cAAA,KAAGU,KAAK,oBAAR,mBAlJ/D,IAmJAZ,EAAAC,EAAAC,cAAA,UACAF,EAAAC,EAAAC,cAAC2B,EAAD,CAAOlB,IAAI,0BAA0BW,MAAM,kBAAkBG,OAAO,gDAAgDF,MAAM,QAC1HvB,EAAAC,EAAAC,cAAA,MAAImB,GAAG,YAAP,YAEArB,EAAAC,EAAAC,cAAA,yBAEAF,EAAAC,EAAAC,cAAA,KAAGQ,MAAM,QAAQW,GAAG,uBACpBrB,EAAAC,EAAAC,cAAA,OAAKQ,MAAM,SAAQV,EAAAC,EAAAC,cAAA,mBAAaF,EAAAC,EAAAC,cAAA,WAChCF,EAAAC,EAAAC,cAAA,KAAGQ,MAAM,QAAQW,GAAG,yBADpB,uDAGArB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,2DAHZ,QAMKnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,gCANlB,qDAMiGnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,MAN9G,gBAMgInB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,qDAN7I,KAMgMnB,EAAAC,EAAAC,cAAA,uDANhM,eAOAF,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,+OAPZ,OAYAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,sEAIZnB,EAAAC,EAAAC,cAAA,OAAKQ,MAAM,SAAQV,EAAAC,EAAAC,cAAA,mBAAaF,EAAAC,EAAAC,cAAA,WAChCF,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,wdADZ,QAQAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,6HAIZnB,EAAAC,EAAAC,cAAA,UAZA,cAcAF,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,uRAdZ,aAkBAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,gnBAlBZ,OAuBInB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,gCAvBjB,SAwBAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,iNAxBZ,MA4BAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,uMA5BZ,SAiCMnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,kDAjCnB,iBAkCAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,mMAlCZ,eAsCYnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,8BAtCzB,YAuCAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,wQAvCZ,yCA6CAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,gMA7CZ,YAiDAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,0aAjDZ,yBA6DAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,iPAIZnB,EAAAC,EAAAC,cAAA,KAAG0D,MAAM,SAAQ5D,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,oBAC9BnB,EAAAC,EAAAC,cAAA,gCAEAF,EAAAC,EAAAC,cAAA,KAAGQ,MAAM,QAAQW,GAAG,uBA9OpB,kDAgPArB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,6EAhPZ,QAmPKnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,mDAnPlB,mBAoPcnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,iEApP3B,sBAoP2GnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,YApPxH,QAoPwInB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,YApPrJ,iDAqPAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,gkBArPZ,SA4PMnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,+BA5PnB,KA4PmDnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,sDA5PhE,OA6PAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,6IA7PZ,WAoQAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,iHApQZ,UAyQAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,qlBAzQZ,iFA+QAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,oJA/QZ,OAsRAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,8PAtRZ,sDA6RAnB,EAAAC,EAAAC,cAAA,UACAF,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,4GA9RZ,MAkSAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,kHAlSZ,gDAqS6CnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,yBArS1D,oDAsSAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,sPAtSZ,sBA4SAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,0JA5SZ,kCAiTAnB,EAAAC,EAAAC,cAAA,iCAEAF,EAAAC,EAAAC,cAAA,OAAKQ,MAAM,WAAUV,EAAAC,EAAAC,cAAA,UACjBF,EAAAC,EAAAC,cAAA,cAAKF,EAAAC,EAAAC,cAAA,sBACTF,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,yHAFS,QAMrBnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,6FAIZnB,EAAAC,EAAAC,cAAA,UAVqB,MAYrBF,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,6PAMZnB,EAAAC,EAAAC,cAAA,UACAF,EAAAC,EAAAC,cAAA,cAAKF,EAAAC,EAAAC,cAAA,sBACLF,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,6RApBS,MA2BrBnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,6RAMZnB,EAAAC,EAAAC,cAAA,cAAKF,EAAAC,EAAAC,cAAA,yBACLF,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,kLAGZnB,EAAAC,EAAAC,cAAA,cAAKF,EAAAC,EAAAC,cAAA,wBACLF,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,iIAGZnB,EAAAC,EAAAC,cAAA,cAAKF,EAAAC,EAAAC,cAAA,8CACLF,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,gKAGZnB,EAAAC,EAAAC,cAAA,cAAKF,EAAAC,EAAAC,cAAA,iDACLF,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,yLAGZnB,EAAAC,EAAAC,cAAA,UACAF,EAAAC,EAAAC,cAAA,cAAKF,EAAAC,EAAAC,cAAA,kBAAL,KACAF,EAAAC,EAAAC,cAAA,UAnDqB,WAqDrBF,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,6GArDS,QA0DrBnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,oPAOZnB,EAAAC,EAAAC,cAAA,sCAEAF,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,kGAGZnB,EAAAC,EAAAC,cAAA,UACAF,EAAAC,EAAAC,cAAA,iCAEAF,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,sgBA5XZ,sDAgZAnB,EAAAC,EAAAC,cAAA,UACAF,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,4JAjZZ,MAsZAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,6QAOQnB,EAAAC,EAAAC,cAACiC,EAAAlC,EAAOmC,gBAAR,CAAwBC,UA3apB,mBA2agDC,OAAQqB,MC5Q7CS,EAhKX,SAACrE,GACzB,IACM4D,EAAe,CACbpB,IAAK,+BAA+BxC,EAAMwD,KAAKC,KAC/ChB,WAAY,QAAQzC,EAAMwD,KAAKC,KAC/Bf,MAAO1C,EAAM0C,OAErB,OAAOzC,EAAAC,EAAAC,cAAA,eACDF,EAAAC,EAAAC,cAACI,EAAAL,EAAD,KACED,EAAAC,EAAAC,cAAA,aAAQH,EAAMwD,KAAKd,MAAnB,aACAzC,EAAAC,EAAAC,cAAA,QAAMK,KAAK,cAAcC,QAAST,EAAMwD,KAAKE,QAEjDzD,EAAAC,EAAAC,cAAA,UAAKH,EAAM0C,OACfzC,EAAAC,EAAAC,cAAA,SAAIH,EAAM0D,MACNzD,EAAAC,EAAAC,cAAA,KAAG0D,MAAM,SAAT,qCACJ5D,EAAAC,EAAAC,cAAA,WACAF,EAAAC,EAAAC,cAAA,0BADA,4XAIAF,EAAAC,EAAAC,cAAA,sBAJA,oGAMiGF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,QAN9G,qBAMuInB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,MANpJ,4DAMkNnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,MAN/N,WAM4OnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,SANzP,4BAM0RnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,mBANvS,IAOAnB,EAAAC,EAAAC,cAAA,UAPA,mKAQgKF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,MAR7K,6FAQ4QnB,EAAAC,EAAAC,cAAA,KAAGU,KAAK,oBAAR,cAR5Q,IASAZ,EAAAC,EAAAC,cAAA,OAAKQ,MAAM,WAAUV,EAAAC,EAAAC,cAAA,qBAAeF,EAAAC,EAAAC,cAAA,WAApC,6EAC0EF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,mBADvF,YACkHnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,QAD/H,OAEAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,uJAFZ,SAKMnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,mBALnB,sCAKwEnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,uBALrF,2FAMAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,qGAIZnB,EAAAC,EAAAC,cAAA,OAAKQ,MAAM,SAAQV,EAAAC,EAAAC,cAAA,mBAAaF,EAAAC,EAAAC,cAAA,WAAhC,YAEAF,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,yGAFZ,6CAK0CnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,QALvD,aAKwEnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,kDALrF,QAK2InB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,0CALxJ,UAMAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,2LANZ,MAUGnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,wDAVhB,kBAWAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,gPAIZnB,EAAAC,EAAAC,cAAA,KAAG0D,MAAM,SAAQ5D,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,oBAlC9B,4BAmCyBnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,UAnCtC,YAoCAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,iJApCZ,oBAuCiBnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,mBAvC9B,+EAuC4HnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,wBAvCzI,6BAwCAnB,EAAAC,EAAAC,cAAA,iBAxCA,kLA2CAF,EAAAC,EAAAC,cAAA,OAAKQ,MAAM,WAAUV,EAAAC,EAAAC,cAAA,qBAAeF,EAAAC,EAAAC,cAAA,WAApC,wIAEAF,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,gRAFZ,SASMnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,iCATnB,+DAWAnB,EAAAC,EAAAC,cAAA,OAAKQ,MAAM,SAAQV,EAAAC,EAAAC,cAAA,mBAAaF,EAAAC,EAAAC,cAAA,WAAhC,iDAEAF,EAAAC,EAAAC,cAAA,OAAKQ,MAAM,SAAQV,EAAAC,EAAAC,cAAA,mBAAaF,EAAAC,EAAAC,cAAA,WAChCF,EAAAC,EAAAC,cAAA,KAAGQ,MAAM,QAAQW,GAAG,eADpB,2BAEwBrB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,uBAFrC,QAE8DnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,uBAF3E,2CAGAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,kHAHZ,mCAOgCnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,MAP7C,QAOuDnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,MAPpE,eAQAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,2NAYZnB,EAAAC,EAAAC,cAAA,OAAKQ,MAAM,SAAQV,EAAAC,EAAAC,cAAA,mBAAaF,EAAAC,EAAAC,cAAA,WAAhC,OACIF,EAAAC,EAAAC,cAAA,KAAGU,KAAK,oBAAR,cADJ,IAEAZ,EAAAC,EAAAC,cAAA,KAAG0D,MAAM,SAAQ5D,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,oBAxB9B,8BA0BAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,kJA1BZ,YA8BSnB,EAAAC,EAAAC,cAAA,KAAGU,KAAK,cAAR,cA9BT,WA+BAZ,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,qQAUGG,MAAM,6BAzCrB,0CA2CAtB,EAAAC,EAAAC,cAAA,OAAKQ,MAAM,SAAQV,EAAAC,EAAAC,cAAA,mBAAaF,EAAAC,EAAAC,cAAA,WAChCF,EAAAC,EAAAC,cAAA,KAAGQ,MAAM,QAAQW,GAAG,eADpB,uEAGArB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,8MAHZ,QAeAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,8MA1DZ,mBA+DgBnB,EAAAC,EAAAC,cAAA,KAAGU,KAAK,4BAAR,4BA/DhB,YAgEAZ,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,qJAhEZ,oBAoEAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,2NApEZ,0BAwEuBnB,EAAAC,EAAAC,cAAA,KAAGU,KAAK,cAAR,cAxEvB,aAyEAZ,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,uQAzEZ,mBAoFgBnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,wDApF7B,sBAoFsGnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,oDApFnH,UAoF2KnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,uEApFxL,QAoF+PnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,kDApF5Q,IAqFAnB,EAAAC,EAAAC,cAAA,KAAG0D,MAAM,SAAQ5D,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,qBAGVnB,EAAAC,EAAAC,cAACiC,EAAAlC,EAAOmC,gBAAR,CAAwBC,UA5JpB,mBA4JgDC,OAAQqB,MC+3B7CU,EA5hCT,SAACtE,GAC3B,IACM4D,EAAe,CACbpB,IAAK,+BAA+BxC,EAAMwD,KAAKC,KAC/ChB,WAAY,QAAQzC,EAAMwD,KAAKC,KAC/Bf,MAAO1C,EAAM0C,OAErB,OAAOzC,EAAAC,EAAAC,cAAA,eACDF,EAAAC,EAAAC,cAACI,EAAAL,EAAD,KACED,EAAAC,EAAAC,cAAA,aAAQH,EAAMwD,KAAKd,MAAnB,aACAzC,EAAAC,EAAAC,cAAA,QAAMK,KAAK,cAAcC,QAAST,EAAMwD,KAAKE,QAEjDzD,EAAAC,EAAAC,cAAA,UAAKH,EAAM0C,OACfzC,EAAAC,EAAAC,cAAA,SAAIH,EAAM0D,MACNzD,EAAAC,EAAAC,cAAA,KAAG0D,MAAM,SAAT,qCACJ5D,EAAAC,EAAAC,cAAA,WACAF,EAAAC,EAAAC,cAAA,0BADA,mMAGgMF,EAAAC,EAAAC,cAAA,2CAHhM,yCAG2QF,EAAAC,EAAAC,cAAA,KAAGU,KAAK,wBAAR,kBAC3QZ,EAAAC,EAAAC,cAAA,gCAJA,iPAOAF,EAAAC,EAAAC,cAAA,UAPA,6PASAF,EAAAC,EAAAC,cAAA,UATA,oPAWAF,EAAAC,EAAAC,cAAA,UAXA,oLAaAF,EAAAC,EAAAC,cAAA,UAbA,wGAcqGF,EAAAC,EAAAC,cAAA,sBAdrG,2BAc6IF,EAAAC,EAAAC,cAAA,yBAd7I,0EAcuOF,EAAAC,EAAAC,cAAA,iCAdvO,QAcuQF,EAAAC,EAAAC,cAAA,6BAdvQ,IAeAF,EAAAC,EAAAC,cAAA,UAfA,mIAiBAF,EAAAC,EAAAC,cAAA,OAAKQ,MAAM,WAAUV,EAAAC,EAAAC,cAAA,UACpBF,EAAAC,EAAAC,cAAA,6LAEAF,EAAAC,EAAAC,cAAA,mHAEAF,EAAAC,EAAAC,cAAA,0LAEAF,EAAAC,EAAAC,cAAA,sLAEDF,EAAAC,EAAAC,cAAA,UACAF,EAAAC,EAAAC,cAAA,kCA3BA,qDA6BkDF,EAAAC,EAAAC,cAAA,sCA7BlD,cA6B6FF,EAAAC,EAAAC,cAAA,sBA7B7F,oFA6B8LF,EAAAC,EAAAC,cAAA,2BA7B9L,0DA6B0QF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,MA7BvR,4CA8BAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,2FA9BZ,iDAiC8CnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,oBAjC3D,4BAiCsGnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,MAjCnH,gBAkCAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,2EAEGG,MAAM,iBApCrB,qDAqCkDtB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,2BArC/D,gCAqCoHnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,MArCjI,gCAqCmKnB,EAAAC,EAAAC,cAAA,KAAGU,KAAK,iBAAR,gBArCnK,kBAqC0NZ,EAAAC,EAAAC,cAAA,sBArC1N,uCAqC8QF,EAAAC,EAAAC,cAAA,qBArC9Q,IAsCAF,EAAAC,EAAAC,cAAA,UAtCA,OAuCIF,EAAAC,EAAAC,cAAA,6BAvCJ,kCAuC0DF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,aAvCvE,MAwCAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,+DAGZnB,EAAAC,EAAAC,cAAA,UA3CA,6FA4C0FF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,MA5CvG,+GA4CwNnB,EAAAC,EAAAC,cAAA,uBA5CxN,YA6CAF,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,mEA7CZ,uKAiDAnB,EAAAC,EAAAC,cAAA,UAjDA,8BAkD2BF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,MAlDxC,iCAkD2EnB,EAAAC,EAAAC,cAAA,kBAlD3E,iBAkDqGF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,SAlDlH,kDAkDyKnB,EAAAC,EAAAC,cAAA,uBAlDzK,mDAmDAF,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,uEAnDZ,2DAuDAnB,EAAAC,EAAAC,cAAA,UAvDA,sNAyDAF,EAAAC,EAAAC,cAAA,UACAF,EAAAC,EAAAC,cAAA,8CA1DA,gLA6DAF,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,sFA7DZ,oBAgEiBnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,MAhE9B,uCAgEuEnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,qBAhEpF,4FAiEAnB,EAAAC,EAAAC,cAAA,UACAF,EAAAC,EAAAC,cAAA,gDAlEA,oJAqEAF,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,gFArEZ,sIAwEmInB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,MAxEhJ,0CAyEAnB,EAAAC,EAAAC,cAAA,OAAKQ,MAAM,UAASV,EAAAC,EAAAC,cAAA,oBAAcF,EAAAC,EAAAC,cAAA,WAAlC,kIACgIF,EAAAC,EAAAC,cAAA,iCAChIF,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,mHAFZ,+GAMAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,mLANZ,yCASwCnB,EAAAC,EAAAC,cAAA,gCATxC,oKAWAF,EAAAC,EAAAC,cAAA,uCApFA,uEAsFoEF,EAAAC,EAAAC,cAAA,0BAtFpE,uCAuFAF,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,2FAvFZ,OA0FInB,EAAAC,EAAAC,cAAA,oCA1FJ,aA0F4CF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,MA1FzD,MA2FAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,uHAEGG,MAAM,oBA7FrB,6CA8F0CtB,EAAAC,EAAAC,cAAA,KAAGU,KAAK,oBAAR,mBA9F1C,mEA8FwJZ,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,oBA9FrK,iHA8FqSnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,mDA9FlT,8HA+FAnB,EAAAC,EAAAC,cAAA,UACAF,EAAAC,EAAAC,cAAA,gCAhGA,wGAmGAF,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,qHAnGZ,qFAuGAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,kGAvGZ,gEA0G6DnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,WA1G1E,mEA2GAnB,EAAAC,EAAAC,cAAA,iCAEAF,EAAAC,EAAAC,cAAA,6BA7GA,8BA+G2BF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,MA/GxC,gCA+G0EnB,EAAAC,EAAAC,cAAA,qBA/G1E,MAgHAF,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,8EAhHZ,SAmHMnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,QAnHnB,gMAmHuNnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,iBAnHpO,IAoHAnB,EAAAC,EAAAC,cAAA,yBApHA,MAsHGF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,MAtHhB,kCAsHoDnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,SAtHjE,iDAuHAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,8FAvHZ,4EA0HyEnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,aA1HtF,gDA0H+InB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,SA1H5J,IA2HAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,0FAGZnB,EAAAC,EAAAC,cAAA,0BA9HA,sFAgImFF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,oCAhIhG,yBAiIAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,4GAEGG,MAAM,oBAnIrB,2EAoIwEtB,EAAAC,EAAAC,cAAA,mCApIxE,6HAoI+NF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,yBApI5O,sBAoIsRnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,uCApInS,IAqIAnB,EAAAC,EAAAC,cAAA,UArIA,qEAsIkEF,EAAAC,EAAAC,cAAA,qCAtIlE,MAuIAF,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,gGAGZnB,EAAAC,EAAAC,cAAA,UACAF,EAAAC,EAAAC,cAAA,UA3IA,mDA4IgDF,EAAAC,EAAAC,cAAA,KAAGU,KAAK,oBAAR,mBA5IhD,kBA4I6GZ,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,MA5I1H,sBA4IkJnB,EAAAC,EAAAC,cAAA,oCA5IlJ,gCA4I6MF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,0BA5I1N,IA6IAnB,EAAAC,EAAAC,cAAA,8BAEAF,EAAAC,EAAAC,cAAA,6BA/IA,8BAiJ2BF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,MAjJxC,4BAiJsEnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,gBAjJnF,2BAkJAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,wGAlJZ,SAqJMnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,QArJnB,qFAqJ4GnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,MArJzH,IAsJAnB,EAAAC,EAAAC,cAAA,UAtJA,wCAuJqCF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,uCAvJlD,UAwJAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,iSAxJZ,SA8JMnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,2DA9JnB,qBA8JyFnB,EAAAC,EAAAC,cAAA,+BA9JzF,qEA+JAF,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,kFAGZnB,EAAAC,EAAAC,cAAA,OAAKQ,MAAM,UAASV,EAAAC,EAAAC,cAAA,oBAAcF,EAAAC,EAAAC,cAAA,WAAlC,OACIF,EAAAC,EAAAC,cAAA,2BADJ,sBAEAF,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,8HAFZ,uCAKoCnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,kCALjD,SAMAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,sGANZ,aAUAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,gJAVZ,kBAaenB,EAAAC,EAAAC,cAAA,2BAbf,8BAa+DF,EAAAC,EAAAC,cAAA,+BAb/D,KAeAF,EAAAC,EAAAC,cAAA,yBAjLA,0BAmLuBF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,MAnLpC,gCAmLsEnB,EAAAC,EAAAC,cAAA,8BAnLtE,YAoLAF,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,oGApLZ,8CAuL2CnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,WAvLxD,uDAwLAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,qJAxLZ,SA2LMnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,uBA3LnB,WA2LgDnB,EAAAC,EAAAC,cAAA,4BA3LhD,mDA2LsHF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,MA3LnI,yCA4LAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,mIA5LZ,gBA+LanB,EAAAC,EAAAC,cAAA,iCA/Lb,OA+L4CF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,MA/LzD,UA+LqEnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,MA/LlF,IAgMAnB,EAAAC,EAAAC,cAAA,OAAKQ,MAAM,UAASV,EAAAC,EAAAC,cAAA,oBAAcF,EAAAC,EAAAC,cAAA,WAAlC,8CAC4CF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,yBADzD,qBACgGnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,6DAD7G,KAGAnB,EAAAC,EAAAC,cAAA,UACAF,EAAAC,EAAAC,cAAA,uCAEAF,EAAAC,EAAAC,cAAA,2BAtMA,sEAwMmEF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,MAxMhF,2CAwM6HnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,gBAxM1I,kDAyMAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,0FAzMZ,kCA4M+BnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,MA5M5C,QA4MsDnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,MA5MnE,WA4MgFnB,EAAAC,EAAAC,cAAA,+BA5MhF,cA6MAF,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,mRA7MZ,SAgNMnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,uBAhNnB,iKAiNAnB,EAAAC,EAAAC,cAAA,UAjNA,2JAmNAF,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,6GAnNZ,2CAsNwCnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,MAtNrD,QAsN+DnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,MAtN5E,cAsN4FnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,MAtNzG,WAsNsHnB,EAAAC,EAAAC,cAAA,sCAtNtH,YAuNAF,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,0NAvNZ,OA0NInB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,QA1NjB,+CA0NoEnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,MA1NjF,wKA2NAnB,EAAAC,EAAAC,cAAA,UA3NA,oJA4NiJF,EAAAC,EAAAC,cAAA,sCA5NjJ,oGA6NAF,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,4DAGZnB,EAAAC,EAAAC,cAAA,UACAF,EAAAC,EAAAC,cAAA,OAAKQ,MAAM,SAAQV,EAAAC,EAAAC,cAAA,mBAAaF,EAAAC,EAAAC,cAAA,WAAhC,OACKF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,gBADlB,UACuCnB,EAAAC,EAAAC,cAAA,gDADvC,0BACwGF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,MADrH,qEAC4LnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,MADzM,gCAC2OnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,MADxP,YACsQnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,uBADnR,gGACqYnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,MADlZ,YACganB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,oCAD7a,oFAGiDnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,gBAH9D,YAIAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,8HAJZ,qCAOmCnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,MAPhD,eAOiEnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,QAP9E,gDAOkInB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,MAP/I,cAQAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,oUARZ,+BAcAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,kHAEGG,MAAM,oBAhBrB,qBAiBmBtB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,2CAjBhC,eAkBAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,yIAlBZ,oCAsBAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,qMAtBZ,eAyBanB,EAAAC,EAAAC,cAAA,qCAzBb,gDA0BAF,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,2IA1BZ,QA8BAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,wGA9BZ,WAkCAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,8YAlCZ,cAuCAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,oOAvCZ,MA0CInB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,2CA1CjB,qFA2CAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,mLA3CZ,+DA8C6DnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,MA9C1E,+FAiDAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,8GAjDZ,wCAoDsCnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,0CApDnD,2BAoDiHnB,EAAAC,EAAAC,cAAA,KAAGU,KAAK,oBAAR,mBApDjH,kDAoD8MZ,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,MApD3N,YAqDAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,ykBArDZ,QA4DAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,+MAGZnB,EAAAC,EAAAC,cAAA,KAAG0D,MAAM,SAAQ5D,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,oBAC9BnB,EAAAC,EAAAC,cAAA,OAAKQ,MAAM,UAASV,EAAAC,EAAAC,cAAA,oBAAcF,EAAAC,EAAAC,cAAA,WAAlC,+IAC6IF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,MAD1J,iDAC6MnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,MAD1N,yJACqXnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,MADlY,mCAGAnB,EAAAC,EAAAC,cAAA,yBApSA,yCAsSsCF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,MAtSnD,2EAuSAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,wFAvSZ,OA2SAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,2NAGZnB,EAAAC,EAAAC,cAAA,UA9SA,kFAgTAF,EAAAC,EAAAC,cAAA,OAAKQ,MAAM,SAAQV,EAAAC,EAAAC,cAAA,mBAAaF,EAAAC,EAAAC,cAAA,WAChCF,EAAAC,EAAAC,cAAA,UADA,mEAGAF,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,kGAHZ,+BAM4BnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,MANzC,cAOAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,0aAPZ,+BAYAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,mJAEGG,MAAM,0BAdrB,qBAemBtB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,uEAfhC,eAgBAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,qKAhBZ,oCAoBAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,iOApBZ,eAuBanB,EAAAC,EAAAC,cAAA,qCAvBb,gDAwBAF,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,qIAxBZ,QA4BAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,iGA5BZ,WAgCAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,geAhCZ,cAqCAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,4RArCZ,mFAyCAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,+KAzCZ,0EA4CwEnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,MA5CrF,+FA+CAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,0IA/CZ,wCAkDsCnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,sEAlDnD,2BAkD0InB,EAAAC,EAAAC,cAAA,KAAGU,KAAK,0BAAR,yBAlD1I,kDAkDmPZ,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,MAlDhQ,YAmDAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,+rBAnDZ,QA0DAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,+MAGZnB,EAAAC,EAAAC,cAAA,KAAG0D,MAAM,SAAQ5D,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,oBAC9BnB,EAAAC,EAAAC,cAAA,UACAF,EAAAC,EAAAC,cAAA,yBA/WA,2BAiXwBF,EAAAC,EAAAC,cAAA,mBAjXxB,yEAiX2GF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,gBAjXxH,QAiX2InB,EAAAC,EAAAC,cAAA,0BAjX3I,IAiXgKF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,SAC7KnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,6EAlXZ,uBAqXoBnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,6BArXjC,uEAsXAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,sNAGZnB,EAAAC,EAAAC,cAAA,wCAEAF,EAAAC,EAAAC,cAAA,yBA3XA,gCA6X6BF,EAAAC,EAAAC,cAAA,uBA7X7B,uFA8XAF,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,+GA9XZ,wBAiYqBnB,EAAAC,EAAAC,cAAA,iDAjYrB,wEAiYqIF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,QAjYlJ,+FAkYAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,4GAlYZ,iCAqY8BnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,QArY3C,QAqYuDnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,MArYpE,gIAsYAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,2FAtYZ,6LA0YAnB,EAAAC,EAAAC,cAAA,OAAKQ,MAAM,UAASV,EAAAC,EAAAC,cAAA,oBAAcF,EAAAC,EAAAC,cAAA,WAAlC,8QAC4QF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,0BADzR,wCACqVnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,0BADlW,qDA1YA,6GA8YAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,kHAGZnB,EAAAC,EAAAC,cAAA,wBAjZA,oBAmZiBF,EAAAC,EAAAC,cAAA,mCAnZjB,uJAoZuCF,EAAAC,EAAAC,cAAA,kBApZvC,8CAoZ8FF,EAAAC,EAAAC,cAAA,sBApZ9F,IAqZAF,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,2EAGZnB,EAAAC,EAAAC,cAAA,UAxZA,0JA0ZAF,EAAAC,EAAAC,cAAA,UACAF,EAAAC,EAAAC,cAAA,UACAF,EAAAC,EAAAC,cAAA,UACAF,EAAAC,EAAAC,cAAA,oDA7ZA,uBA+ZoBF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,yCA/ZjC,sCA+ZyGnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,yCA/ZtH,2EA+ZmOnB,EAAAC,EAAAC,cAAA,2BACnOF,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,+GAhaZ,gBAuaanB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,yCAva1B,gCAua4FnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,MAvazG,OAuakHnB,EAAAC,EAAAC,cAAA,iCAvalH,QAwaAF,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,4OAxaZ,uEAqboEnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,MArbjF,UAqb6FnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,MArb1G,2BAsbAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,2FAtbZ,iBAybcnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,MAzb3B,QAybqCnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,MAzblD,gDA0bAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,8TA1bZ,YA8bSnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,sBA9btB,QA8b8CnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,sBA9b3D,YA+bAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,soBA/bZ,iFAqcAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,sgBAmBZnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,6KAIZnB,EAAAC,EAAAC,cAAA,UACAF,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,2JA7dZ,MAkeAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,2QAleZ,kCAue+BnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,WAve5C,+CAweAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,8JAIZnB,EAAAC,EAAAC,cAAA,UA5eA,YA6eSF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,+BA7etB,cA6e4DnB,EAAAC,EAAAC,cAAA,iCA7e5D,qBA8eAF,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,4EAGZnB,EAAAC,EAAAC,cAAA,UAjfA,0DAkfuDF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,MAlfpE,gBAkfsFnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,MAlfnG,4BAkfiInB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,MAlf9I,mHAkfmQnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,aAlfhR,sFAkf+WnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,MAlf5X,mFAmfAnB,EAAAC,EAAAC,cAAA,OAAKQ,MAAM,UAASV,EAAAC,EAAAC,cAAA,oBAAcF,EAAAC,EAAAC,cAAA,WAAlC,wDACsDF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,MADnE,QAC6EnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,MAD1F,qCACiInB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,WAD9I,QAC6JnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,SAD1K,wBACuMnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,sBADpN,KAGAnB,EAAAC,EAAAC,cAAA,wCAtfA,OAwfIF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,sBAxfjB,SAwf2CnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,oCAxfxD,QAwf6FnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,uCAxf1G,gBAwf0JnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,+BAxfvK,oDAwfoPnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,mCAxfjQ,SAyfAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,0LAzfZ,QAmgBAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,oIAngBZ,SAugBMnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,oGAvgBnB,IAwgBAnB,EAAAC,EAAAC,cAAA,UACAF,EAAAC,EAAAC,cAAA,8DAzgBA,4DA2gByDF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,MA3gBtE,wCA2gBgHnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,MA3gB7H,4BA2gB2JnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,yBA3gBxK,4CA2gBsOnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,WA3gBnP,yGA4gBAnB,EAAAC,EAAAC,cAAA,UA5gBA,6IA6gB0IF,EAAAC,EAAAC,cAAA,2CA7gB1I,iEA8gBAF,EAAAC,EAAAC,cAAA,UA9gBA,gEAghBAF,EAAAC,EAAAC,cAAA,OAAKQ,MAAM,WAAUV,EAAAC,EAAAC,cAAA,UACpBF,EAAAC,EAAAC,cAAA,6CAEAF,EAAAC,EAAAC,cAAA,iFAEDF,EAAAC,EAAAC,cAAA,UACAF,EAAAC,EAAAC,cAAA,qCAthBA,ySA0hBAF,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,qHAGZnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,iBA7hBb,SA6hBkCnB,EAAAC,EAAAC,cAAA,yBA7hBlC,wEA8hBAF,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,6NA9hBZ,2BAsiBwBnB,EAAAC,EAAAC,cAAA,0BAtiBxB,MAuiBAF,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,sGAviBZ,iBA0iBcnB,EAAAC,EAAAC,cAAA,iBA1iBd,sBA2iBAF,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,mGA3iBZ,2DA8iBwDnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,kBA9iBrE,OA+iBAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,kGA/iBZ,4EAmjBAnB,EAAAC,EAAAC,cAAA,UAnjBA,4EAojByEF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,MApjBtF,oCAojB4HnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,QApjBzI,KAojBkJnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,mBApjB/J,0CAqjBAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,gFArjBZ,wBAwjBqBnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,8CAxjBlC,oEAyjBAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,iNAGZnB,EAAAC,EAAAC,cAAA,UA5jBA,yCA6jBsCF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,aA7jBnD,qCA8jBAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,8OA9jBZ,SAkkBMnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,6BAlkBnB,gFAmkBAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,4FAnkBZ,uIAukBAnB,EAAAC,EAAAC,cAAA,UAvkBA,mDAwkBgDF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,aAxkB7D,2CAwkBgHnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,MAxkB7H,mNAwkBiVnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,aAxkB9V,8BAwkBoYnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,MAxkBjZ,yDAykBAnB,EAAAC,EAAAC,cAAC2B,EAAD,CAAOlB,IAAI,4BAA4BW,MAAM,oBAAoBG,OAAO,2BAA2BF,MAAM,QACzGvB,EAAAC,EAAAC,cAAA,UA1kBA,8JA4kBAF,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,qGA5kBZ,gDAglBAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,yGAhlBZ,SAmlBMnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,mBAnlBnB,mDAolBAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,uNAplBZ,MAulBGnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,sCAvlBhB,QAwlBAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,iGAGZnB,EAAAC,EAAAC,cAAA,sDA3lBA,+CA6lB4CF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,wBA7lBzD,QA6lBmFnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,wBA7lBhG,kEA6lBoLnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,MA7lBjM,gBA6lBmNnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,MA7lBhO,8CA8lBAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,0DA9lBZ,0CAkmBAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,mIAlmBZ,6FAqmB0FnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,0BArmBvG,qBAqmBgJnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,aArmB7J,+CAqmBoNnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,MArmBjO,oEAqmBuSnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,eArmBpT,eAsmBAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,wIAtmBZ,oCAymBiCnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,wCAzmB9C,yCA0mBAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,gKA1mBZ,iCA+mBAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,6FA/mBZ,uFAknBoFnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,gBAlnBjG,uPAmnBAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,kPAnnBZ,yDAwnBsDnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,aAxnBnE,qFAwnBiKnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,gBAxnB9K,QAwnBiMnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,QAxnB9M,kEAynBAnB,EAAAC,EAAAC,cAAA,OAAKQ,MAAM,UAASV,EAAAC,EAAAC,cAAA,oBAAcF,EAAAC,EAAAC,cAAA,WAAlC,kmBAKAF,EAAAC,EAAAC,cAAA,gDA9nBA,yCAgoBsCF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,2BAhoBnD,8BAgoBsGnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,wBAhoBnH,uBAioBAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,iEAGZnB,EAAAC,EAAAC,cAAA,wBApoBA,iBAsoBcF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,aAtoB3B,wEAuoBAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,4FAvoBZ,yDA2oBAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,0EA3oBZ,QA+oBAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,yRA/oBZ,iHAiqBAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,yGAjqBZ,QAqqBAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,uGArqBZ,+HAwqB4HnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,MAxqBzI,kDAwqB6LnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,YAxqB1M,8CAyqBAnB,EAAAC,EAAAC,cAAA,wBAzqBA,4BA2qByBF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,mBA3qBtC,iEA2qBqHnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,QA3qBlI,UA2qBgJnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,gBA3qB7J,gBA4qBAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,uQA5qBZ,0BAkrBAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,uNAlrBZ,6CAurB0CnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,gBAvrBvD,MAwrBAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,sYAxrBZ,wCA+rBAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,yHAIZnB,EAAAC,EAAAC,cAAA,OAAKQ,MAAM,UAASV,EAAAC,EAAAC,cAAA,oBAAcF,EAAAC,EAAAC,cAAA,WAAlC,oBACkBF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,iCAD/B,0MAGsBnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,4BAHnC,8MAKAnB,EAAAC,EAAAC,cAAA,gCAxsBA,sMA0sBmMF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,YA1sBhN,6DA2sBAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,qPA3sBZ,+BAytBAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,qbAztBZ,wFA8uBqFnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,QA9uBlG,iDA8uBuJnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,MA9uBpK,kCA8uBwMnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,MA9uBrN,kBA8uByOnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,YA9uBtP,IA+uBAnB,EAAAC,EAAAC,cAAA,UA/uBA,0IAgvBuIF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,4CAhvBpJ,IAivBAnB,EAAAC,EAAAC,cAAA,UAjvBA,aAkvBUF,EAAAC,EAAAC,cAAA,mCAlvBV,YAmvBAF,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,+QAnvBZ,SAyvBMnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,0DAzvBnB,WAyvBoFnB,EAAAC,EAAAC,cAAA,2BAzvBpF,4CA0vBAF,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,0EA1vBZ,kEA8vBAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,+lBA9vBZ,8NAsxBAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,mNAKZnB,EAAAC,EAAAC,cAAA,OAAKQ,MAAM,UAASV,EAAAC,EAAAC,cAAA,oBAAcF,EAAAC,EAAAC,cAAA,WAAlC,2MAGAF,EAAAC,EAAAC,cAAA,sCA9xBA,uCAiyBAF,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,iHAjyBZ,kCAoyB+BnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,YApyB5C,QAoyB4DnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,aApyBzE,UAqyBAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,mFAryBZ,kBAyyBAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,0FAzyBZ,sDA4yBmDnB,EAAAC,EAAAC,cAAA,yCA5yBnD,mDA4yBsIF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,kDA5yBnJ,iBA4yB+MnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,wDA5yB5N,QA4yBsRnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,qDA5yBnS,IA6yBAnB,EAAAC,EAAAC,cAAA,4BA7yBA,OA+yBIF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,wEA/yBjB,+BA+yBmHnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,0BA/yBhI,sEAgzBAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,8IAhzBZ,aAmzBUnB,EAAAC,EAAAC,cAAA,mCAnzBV,YAozBAF,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,+QApzBZ,SA0zBMnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,0DA1zBnB,WA0zBoFnB,EAAAC,EAAAC,cAAA,2BA1zBpF,4CA2zBAF,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,0EA3zBZ,kEA+zBAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,mlBA/zBZ,iSAu1BwHnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,mBAv1BrI,QAu1B2JnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,aAv1BxK,IAw1BAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,mNAKZnB,EAAAC,EAAAC,cAAA,0BA71BA,+EA+1B4EF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,gDA/1BzF,uBAg2BAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,iEAGZnB,EAAAC,EAAAC,cAAA,wBAn2BA,iBAq2BcF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,MAr2B3B,wEAs2BAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,+HAt2BZ,QA02BAnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,0EA12Bb,QA02BqFnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,eA12BlG,6BA02ByInB,EAAAC,EAAAC,cAAA,mBA12BzI,gBA02BmKF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,MA12BhL,kFA02BoQnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,eA12BjR,gBA22BAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,+EA32BZ,qDA82BkDnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,sBA92B/D,oCA82BoHnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,iBA92BjI,IA+2BAnB,EAAAC,EAAAC,cAAA,UA/2BA,yCAg3BsCF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,wBAh3BnD,2QAg3BiVnB,EAAAC,EAAAC,cAAA,kCAh3BjV,mBAi3BAF,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,gKAj3BZ,OAs3BAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,8aAiBZnB,EAAAC,EAAAC,cAAA,OAAKQ,MAAM,UAASV,EAAAC,EAAAC,cAAA,oBAAcF,EAAAC,EAAAC,cAAA,WAAlC,uJACqJF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,SADlK,qDAGAnB,EAAAC,EAAAC,cAAA,gCA14BA,+KA44B4KF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,YA54BzL,6DA64BAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,yRA74BZ,uBA25BAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,oEA35BZ,8DA85B2DnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,+CA95BxE,+CA+5BAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,stBA/5BZ,eAq7BYnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,2CAr7BzB,2BAq7ByFnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,MAr7BtG,kFAq7B0LnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,kBAr7BvM,QAq7B4NnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,WAr7BzO,6HAq7B6WnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,kCAr7B1X,IAs7BAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,6GAt7BZ,4JA07BAnB,EAAAC,EAAAC,cAAA,UA17BA,yDA47BAF,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,8OAKZnB,EAAAC,EAAAC,cAAA,OAAKQ,MAAM,UAASV,EAAAC,EAAAC,cAAA,oBAAcF,EAAAC,EAAAC,cAAA,WAAlC,8IAGAF,EAAAC,EAAAC,cAAA,kCAp8BA,YAs8BSF,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,oBAt8BtB,UAs8B+CnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,wCAt8B5D,SAu8BAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,uIAv8BZ,qDA28BAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,2HA38BZ,mDA+8BgDnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,MA/8B7D,QA+8BuEnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,SA/8BpF,0DA+8BmJnB,EAAAC,EAAAC,cAAC6B,EAAD,CAAQZ,KAAK,iBA/8BhK,gBAg9BAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,kJAh9BZ,QAy9BAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,0IAz9BZ,MAk+BAnB,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,ymBA+BZnB,EAAAC,EAAAC,cAAA,MAAImB,GAAG,YAAP,YAEArB,EAAAC,EAAAC,cAAA,sCAEAF,EAAAC,EAAAC,cAAC6D,EAAD,CAAO5C,KAAK,mGAKQnB,EAAAC,EAAAC,cAACiC,EAAAlC,EAAOmC,gBAAR,CAAwBC,UAxhCpB,mBAwhCgDC,OAAQqB,MCj/BjEW,EArCE,SAACvE,GACd,IAAIS,EACJ,OAAQT,EAAMwD,KAAK7C,OACf,IAAK,SACDF,EAAUR,EAAAC,EAAAC,cAACqE,EAAD,CAAQhB,KAAMxD,EAAMwD,OAC9B,MACJ,IAAK,YACD/C,EAAUR,EAAAC,EAAAC,cAACsE,EAAD,CAAWjB,KAAMxD,EAAMwD,OACjC,MACJ,IAAK,iBACD/C,EAAUR,EAAAC,EAAAC,cAACuE,EAAD,CAAgBlB,KAAMxD,EAAMwD,OACtC,MACJ,IAAK,QACD/C,EAAUR,EAAAC,EAAAC,cAACwE,EAAD,CAAOnB,KAAMxD,EAAMwD,OAC7B,MACJ,IAAK,oBACD/C,EAAUR,EAAAC,EAAAC,cAACyE,EAAD,CAAmBpB,KAAMxD,EAAMwD,OACzC,MAEJ,IAAK,oBACD/C,EAAUR,EAAAC,EAAAC,cAAC0E,EAAD,CAAmBrB,KAAMxD,EAAMwD,OACzC,MACJ,IAAK,kBACG/C,EAAUR,EAAAC,EAAAC,cAAC2E,EAAD,CAAiBtB,KAAMxD,EAAMwD,OAC3C,MACJ,IAAK,oBACG/C,EAAUR,EAAAC,EAAAC,cAAC4E,EAAD,CAAmBvB,KAAMxD,EAAMwD,OAGrD,OAAOvD,EAAAC,EAAAC,cAAA,OAAKC,UAAU,WAC1BH,EAAAC,EAAAC,cAAA,OAAKC,UAAU,OACZH,EAAAC,EAAAC,cAAA,UAAKH,EAAMwD,KAAKd,OAChBzC,EAAAC,EAAAC,cAAA,SAAIH,EAAMwD,KAAKE,OAEjBjD,IC+BcuE,6MAtEXC,OAAS,CACL3B,MAAO,CACP,CACIhC,GAAG,EACHoB,MAAM,oCACNgB,KAAK,6EACLD,KAAM,sBACN9C,MAAO,qBAEX,CACIW,GAAG,EACHoB,MAAM,kBACNgB,KAAK,wEACLD,KAAM,kBACN9C,MAAO,mBAEX,CACIW,GAAG,EACHoB,MAAM,qBACNgB,KAAK,2HACLD,KAAM,qBACN9C,MAAO,qBAEX,CACIW,GAAG,EACHoB,MAAM,qCACNgB,KAAK,8FACLD,KAAM,iBACN9C,MAAO,UAEX,CACIW,GAAG,EACHoB,MAAM,2CACNgB,KAAK,wMACLD,KAAM,mBACN9C,MAAO,aAEX,CACIW,GAAG,EACHoB,MAAM,8CACNgB,KAAK,0TACLD,KAAM,kBACN9C,MAAO,kBAEX,CACIW,GAAG,EACHoB,MAAM,mBACNgB,KAAK,ymBACLD,KAAM,QACN9C,MAAO,SAEX,CACIW,GAAG,EACHoB,MAAM,qBACNgB,KAAK,qgBACLD,KAAM,qBACN9C,MAAO,yBAIfuE,OAAOC,EAAKF,OAAO3B,MAAMC,IAAI,SAACC,GAC1B,OAAOvD,EAAAC,EAAAC,cAAC2C,EAAA,EAAD,CAAOC,KAAM,UAAUS,EAAKC,KAAMR,OAAQ,SAACjD,GAAD,OAAWC,EAAAC,EAAAC,cAACiF,EAAD,CAAU5B,KAAMA,iFAExE,IAAA6B,EAAAC,KACR,OAAOrF,EAAAC,EAAAC,cAAA,OAAKC,UAAU,WACrBH,EAAAC,EAAAC,cAAC2C,EAAA,EAAD,CAAOC,KAAK,SAASC,OAAK,EAACC,OAAQ,SAACjD,GAAD,OAAWC,EAAAC,EAAAC,cAACoF,EAAD,CAAUjC,MAAO+B,EAAKJ,OAAO3B,WAC3EgC,KAAKJ,eAnEUM,aCALC,EALA,SAACzF,GACZ,OAAOC,EAAAC,EAAAC,cAAA,UAAQC,UAAU,OACpBJ,EAAMK,WCWAqF,EAbI,WACf,OAAOzF,EAAAC,EAAAC,cAAA,OAAKC,UAAU,UACtBH,EAAAC,EAAAC,cAAA,WACMF,EAAAC,EAAAC,cAAA,UACEF,EAAAC,EAAAC,cAAA,UAAIF,EAAAC,EAAAC,cAAA,KAAGU,KAAK,KAAR,SACJZ,EAAAC,EAAAC,cAAA,UAAIF,EAAAC,EAAAC,cAAA,KAAGU,KAAK,cAAR,cACJZ,EAAAC,EAAAC,cAAA,UAAIF,EAAAC,EAAAC,cAAA,KAAGU,KAAK,UAAR,UACJZ,EAAAC,EAAAC,cAAA,UAAIF,EAAAC,EAAAC,cAAA,KAAGU,KAAK,iBAAR,iBACJZ,EAAAC,EAAAC,cAAA,UAAIF,EAAAC,EAAAC,cAAA,OAAKC,UAAU,aAAaQ,IAAI,6GAA6GF,IAAI,uBCDlJiF,EAPA,SAAC3F,GACZ,IACI4F,GADE,IAAIC,MACCC,cACf,OAAO7F,EAAAC,EAAAC,cAAA,OAAKC,UAAU,UAChBwF,EADC,6CC0BQG,MAnBf,WAEE,OACE9F,EAAAC,EAAAC,cAAC6F,EAAD,KACE/F,EAAAC,EAAAC,cAAC8F,EAAD,KACEhG,EAAAC,EAAAC,cAAA,OAAKC,UAAU,aAAYH,EAAAC,EAAAC,cAAA,kCAC5BF,EAAAC,EAAAC,cAAC+F,EAAD,OAEDjG,EAAAC,EAAAC,cAACgG,EAAA,EAAD,CAAQC,SAAUC,IAClBpG,EAAAC,EAAAC,cAAC2C,EAAA,EAAD,CAAOC,KAAK,IAAIC,OAAK,EAACsD,UAAWhG,IACjCL,EAAAC,EAAAC,cAAC2C,EAAA,EAAD,CAAOC,KAAK,gBAAgBuD,UAAWC,IACvCtG,EAAAC,EAAAC,cAAC2C,EAAA,EAAD,CAAOC,KAAK,aAAauD,UAAWzD,IACpC5C,EAAAC,EAAAC,cAAC2C,EAAA,EAAD,CAAOC,KAAK,SAASuD,UAAWtB,KAEhC/E,EAAAC,EAAAC,cAACqG,EAAD,QCbcC,QACW,cAA7BC,OAAOC,SAASC,UAEe,UAA7BF,OAAOC,SAASC,UAEhBF,OAAOC,SAASC,SAASC,MACvB,2DCZNC,IAAS7D,OAAOhD,EAAAC,EAAAC,cAAC4G,EAAD,MAASC,SAASC,eAAe,SD2H3C,kBAAmBC,WACrBA,UAAUC,cAAcC,MAAMC,KAAK,SAAAC,GACjCA,EAAaC","file":"static/js/main.fe3356e1.chunk.js","sourcesContent":["import React from 'react';\r\nconst Layout = (props) => {\r\n    return <div className=\"layout\">{props.children}</div>\r\n}\r\nexport default Layout;","import React from 'react';\r\nimport Helmet from 'react-helmet';\r\nimport './HomePage.css';\r\nconst HomePage = () => {\r\n    return <div className=\"divPage\">\r\n        <Helmet>\r\n        <title>Marcos Rogério Fernandes | Personal Website</title>\r\n        <meta name=\"description\" content=\"Welcome to my personal website. Here you will find my reserach interest and contributions. \" />\r\n    </Helmet>\r\n<div className=\"homepage_top\">\r\n         <img alt=\"perfil\" class=\"homepage_myfoto\" src=\"https://avatars1.githubusercontent.com/u/4412144?s=460&v=4\"/>\r\n        <h1>Marcos Rogério Fernandes</h1>\r\n        <p>\r\n        I'm a Control Engineer, programmer and a researcher.\r\nI work on ideas and tools related to Electrical Engineer, Automation and Computer Science.\r\nI'm a PhD Candidate at School of Electrical and Computer Engineering from Unicamp (FEEC/Unicamp). \r\n        </p>\r\n</div>\r\n<article>\r\n        <h2>My Research Interest:</h2>\r\n<ul>\r\n    <li>Statistic Learning</li>\r\n    <li>Kalman Filtering</li>\r\n    <li>Navigation & Tracking Systems</li>\r\n    <li>Sensor Fusion Algorithms</li>\r\n    <li>GNSS Processing Methods</li>\r\n    <li>Optimal and Robust Stochastic Control Systems</li>\r\n    <li>Mobile Robotics</li>\r\n    <li>Computer Vision</li>\r\n\r\n</ul>\r\n<div className=\"social_media\">\r\n{/*<a href=\"https://www.facebook.com/eng.marofe\" class=\"fa fa-facebook\"></a>*/}\r\n<a href=\"https://twitter.com/_marofe\" class=\"fa fa-twitter\"></a>\r\n<a href=\"https://www.instagram.com/_marofe\" class=\"fa fa-instagram\"></a>\r\n<a href=\"https://www.linkedin.com/in/marcos-rogerio-fernandes/\" class=\"fa fa-linkedin\"></a>\r\n<a href=\"https://www.researchgate.net/profile/Marcos_Fernandes10\" class=\"fa fa-researchgate\"></a>\r\n<a href=\"https://github.com/Marofe\" class=\"fa fa-github\"></a>\r\n<a href=\"mailto:eng.marofe@hotmail.com\" class=\"fa fa-envelope\"></a> \r\n</div>\r\n</article>\r\n    </div>\r\n}\r\nexport default HomePage;","import React from 'react';\r\nimport './Publications.css';\r\nimport Helmet from 'react-helmet';\r\nconst Papers = () => {\r\n    return <div className=\"divPages pgPublication\">\r\n        <Helmet>\r\n        <title>Publications | Marcos Rogério Fernandes</title>\r\n        <meta name=\"description\" content=\"Welcome to my personal website. Here you will find my main contributions. \" />\r\n       </Helmet>\r\n        <div className=\"top\">\r\n       <h1>My Publications</h1>\r\n       <p>Here is an overview of my latest works and publications.</p>\r\n       </div>\r\n       <article>\r\n       <h2>Journals:</h2>\r\n       <ul>\r\n        <li>\r\n            <p>\r\n        M. R. Fernandes, J. B. R. do Val and R. F. Souto, \"Robust Estimation and Filtering for Poorly Known Models,\" in IEEE Control Systems Letters, vol. 4, no. 2, pp. 474-479, April 2020.\r\n        <br/>[<a href=\"https://ieeexplore.ieee.org/document/8891731\">Download (IEEE Explorer)</a>]\r\n    </p>\r\n    </li></ul>\r\n       <h2>Conference Papers:</h2>\r\n<ul>\r\n        <li>\r\n            <p>\r\n        FERNANDES, MARCOS R.; DO VAL, JOAO B. R. ; SOUTO, RAFAEL F. . Filtering of Poorly Known Systems: Estimation Variations as Source of Uncertainty. In: 2018 IEEE Conference on Decision and Control (CDC), 2018, FL. 2018 IEEE Conference on Decision and Control (CDC), 2018. p. 3074. \r\n        <br/>[<a href=\"https://ieeexplore.ieee.org/document/8619306\">Download (IEEE Explorer)</a>][<a href=\"https://www.researchgate.net/publication/329895979_Slides\">Slides</a>] [<a href=\"https://github.com/Marofe/EVIU\">Code</a>]\r\n    </p>\r\n    </li>\r\n        <li><p>\r\n        FERNANDES, M. R.; SOUTO, R. F. ; DO VAL, J. B. R. . FILTRAGEM DE SISTEMAS NÃO-LINEARES: CONSIDERANDO A VARIAÇÃO DA ESTIMATIVA COMO FONTE DE INCERTEZA. In: Congresso Brasileiro de Automática, 2018, João Pessoa. Anais do XXII Congresso Brasileiro de Automática, 2018. \r\n        <br/>[<a href=\"http://dx.doi.org/10.20906/CPS/CBA2018-1140\">Download (Portuguese)</a>][<a href=\"https://github.com/Marofe/EVIU\">Code</a>]\r\n    </p>\r\n    </li>\r\n        <li><p>\r\n        DE OLIVEIRA, MARIO. O. F. ; FERNANDES, M. R. ; SOUTO, RAFAEL F. . Implementation of a Low-cost Prototype of Twin Rotor for academic studies in identification, optimal control and stochastic filtering. In: 2017 6th International Conference on Systems and Control (ICSC), 2017, Batna. 2017 6th International Conference on Systems and Control (ICSC), 2017. p. 193-198. \r\n        <br/>[<a href=\"https://ieeexplore.ieee.org/document/7958718\">Download (IEEE Explorer)</a>]</p>\r\n    </li>\r\n        <li><p>\r\n        FERNANDES, MARCOS. R.; DE OLIVEIRA, MARIO. O. F. ; SOUTO, R. F. . CONSTRUÇÃO DE UM PROTÓTIPO DE HELICÓPTERO DE BAIXO CUSTO PARA ESTUDOS EM IDENTIFICAÇÃO DE SISTEMAS. In: Simpósio Brasileiro de Automação Inteligente, 2017, Porto Alegre. Anais do XIII Simpósio Brasileiro de Automação Inteligente, 2017. p. 1177-1183. \r\n        <br/>[<a href=\"https://www.ufrgs.br/sbai17/papers/paper_332.pdf\">Download (Portuguese)</a>]\r\n    </p>\r\n    </li>\r\n</ul>\r\n<h2>Master's Dissertation:</h2>\r\n<p>\r\n     FERNANDES, M. R.; Stochastic Filtering: Estimation Variation as Source of Uncertainty. FEEC/UNICAMP, 2019.\r\n     <br/>[<a href=\"http://repositorio.unicamp.br/jspui/handle/REPOSIP/334481\">Download (Portuguese)</a>] [<a href=\"https://www.researchgate.net/publication/334710395_mestrado-slidespdf\">Slides</a>] [<a href=\"https://github.com/Marofe/EVIU\">Code</a>]\r\n</p>\r\n<h2>Undergraduate's Final Project:</h2>\r\n<p>\r\n     FERNANDES, M. R.; DE OLIVEIRA, M. O. F. ; Study and Development of Optimal Control Systems and Stochastic Filtering. UTFPR, 2016. \r\n     <br/>[<a href=\"https://www.researchgate.net/publication/313426875_Estudo_e_Desenvolvimento_de_Sistemas_de_Controle_Otimo_com_Filtragem_Estocastica\">Download (Portuguese)</a>]\r\n</p></article>\r\n</div>\r\n}\r\nexport default Papers;","import React from 'react';\r\nimport Katex from 'katex';\r\nconst inline = (props)=> {\r\nreturn <span dangerouslySetInnerHTML={{__html: Katex.renderToString(props.math)}}></span>;\r\n}\r\nexport default inline;","import React from 'react';\r\nimport './Image.css';\r\nconst Image = (props) => {\r\n    return <div className=\"divImage\">\r\n        <img className={props.className} id={props.label} alt={props.alt} src={props.src} width={props.width} height={props.height}/><br/>\r\n        <span>{props.legend}</span>\r\n    </div>\r\n}\r\nexport default Image;","import React from 'react';\r\nimport Helmet from 'react-helmet';\r\nimport '../../Components/Pages/Tutorials.css';\r\nimport { BlockMath } from 'react-katex';\r\nimport Latex_inline from '../../Components/Latex/Inline';\r\nimport '../../../node_modules/katex/dist/katex.css';\r\nimport Image from '../../Components/Image/Image';\r\nimport Disqus from 'disqus-react';\r\nconst Tutorial1 = () => {\r\n    const disqusShortname = 'marofe-github-io';\r\n        const disqusConfig = {\r\n            url: 'https://marofe.github.io/?p=tutorials/rastreamento_usando_visao_filtro_kalman',\r\n            identifier: 'rastreamento_usando_visao_filtro_kalman',\r\n            title: 'Rastreamento de Objetos usando Visão Computacional e Filtro de Kalman'\r\n        };\r\n        console.log(process.env.PUBLIC_URL+'/tutorials/rastreamento_usando_visao_filtro_kalman');\r\n    return <article>\r\n      <Helmet>\r\n        <title>Rastreamento de Objetos usando Visão Computacional e Filtro de Kalman | Marcos Rogério Fernandes</title>\r\n        <meta name=\"description\" content=\"Welcome to my personal website. Here you will find my reserach interest and contributions. \" />\r\n    </Helmet>\r\n    <h1>Rastreamento de Objetos usando Visão Computacional e Filtro de Kalman</h1>\r\n    <Image src=\"https://4.bp.blogspot.com/-J-tkGAP5-DA/WV7cvNDr5mI/AAAAAAAAAV4/hHQS3uj5H-gK040plU-Ikg6MSpQjtSmDwCLcBGAs/s400/Untitled.jpg\" alt=\"Computer Vision\" legend=\"Rastreamento de Objetos\" />\r\n<p>Este trabalho apresenta um algoritmo em tempo real para rastreamento de objetos\r\n    em visão computacional, usando o Filtro de Kalman como mecanismo de predição para situações de oclusão e ou\r\n    contaminação da cena por ruído. O principal objetivo deste trabalho é de apresentar de forma didática o\r\n    desenvolvimento de um algoritmo de rastreamento de objetos baseado em cor. O algoritmo apresentado faz o\r\n    rastreamento do maior objeto simétrico de uma cor pré-definida presente na cena. É apresentado em detalhes a\r\n    implementação da etapa de segmentação da imagem, e posteriormente é apresentado uma estratégia para tratar situações\r\n    com dois objetos da mesma cor. Por fim é demonstrado o uso do Filtro de Kalmam.</p>\r\n    <p>Última atualização:  13 de Dezembro de 2015.</p>\r\n<h3>INTRODUÇÃO</h3>\r\n<p>\r\nO rastreamento de objetos é uma das mais importantes áreas da visão computacional, com\r\n    extensas aplicações tanto para indústria pesada como automobilismo, assim como para a indústria do entretenimento,\r\n    além de ser uma poderosa ferramenta na área médica (Pinho et al., 2004). Visão computacional consiste em técnicas\r\n    computacionais no qual possibilita interpretar imagens (WANGENHEIM et al., 2001). Segundo (Freitas et\r\n    al.,2010), as principais aplicações do rastreamento de objetos em imagens são para diagnósticos médicos, interfaces\r\n    Homem-Computador para controle de jogos eletrônicos e na área de segurança, para o monitoramento de ambientes com\r\n    grandes fluxos de pessoas, tais como aeroportos, plataformas de trens e estacionamentos. O objetivo principal na\r\n    área de segurança é detectar através dos sistemas de rastreamento de objetos atividades indesejadas, contribuindo\r\n    para a tomada de decisões dos profissionais de segurança (Relli, 2014).Um algoritmo de rastreamento de\r\n    objetos busca a partir de cenas provindas de um sensor óptico, como uma câmera, identificar a trajetória que um ou\r\n    mais objetos descrevem. No entanto, existem diversos fatores que dificultam a identificação da trajetória descrita\r\n    por um objeto no mundo real. Seja por variações de iluminação, como o ascender ou apagar de luzes, ruídos de fundo e\r\n    principalmente oclusões que eventualmente o objeto sofra (Weng et al., 2006). Para contornar as dificuldades do\r\n    mundo real para o rastreamento de objetos, é feito o uso de diversas estratégias de predição como o Filtro de\r\n    Partículas e o Filtro de Kalman (Iraei and Faez, 2015).Os sistemas de rastreamento de objetos usando\r\n    visão computacional podem ser divido em três estágios, conforme ilustrado na Figura 1. O primeiro estágio é onde\r\n    ocorre a segmentação da imagem, o segundo estágio é onde faz-se o rastreamento ao longo do tempo do objeto ou alvo\r\n    (<i>target</i>) e no ultimo estágio, faz-se a classificação dos objetos quanto a suas ações executadas.\r\n</p>\r\n<Image src=\"https://3.bp.blogspot.com/-Mad91z12UTo/WV7e5j1RkRI/AAAAAAAAAV8/1uTcrkXLTxodkvw2r_DDTnEBA3smrcfAQCLcBGAs/s320/sys_rast.png\"\r\n                        alt=\"Workflow\" legend=\"Figura 1 - Etapas\" />\r\n\r\n    <h3>O Filtro de Kalman </h3>\r\n    <p>\r\n    O Filtro de Kalman consiste em um conjunto de equações que possibilitam a\r\n    implementação recursiva de um estimador, gerando predição ótima dos estados futuros de um sistema linear a partir de\r\n    uma observação presente (Welch and Bishop, 1995). Foi desenvolvido em meados de 1960 por Rudolf Emil Kalman (Kalman\r\n    et al., 1960), inicialmente para aplicações aeroespaciais. No entanto, logo vislumbraram-se diversas aplicações em\r\n    outras áreas, como robótica móvel, rastreamento de alvos, identificação de sistemas, controle de processos, análise\r\n    e processamento de sinais entre outros (Funk, 2003). Existem hoje variações para sistemas não-lineares, como o\r\n    Filtro de Kalman Estendido (EKF) e o Filtro de Kalman Unscented (UKF). Neste trabalho será feito o uso do Filtro de\r\n    Kalman linear (KF) que busca gerar estimativas ótimas dos estados de um sistema descrito por</p>\r\n    <BlockMath math=\"\\begin{aligned}\r\n    x_{k+1}&=Ax_k+Bu_k+w_k\\\\\r\n    y_k &= Cx_k + v_k\\end{aligned}\"/>\r\n    No qual <Latex_inline math=\"x_k \\in \\mathbb{R}^n\"/> é o vetor de estados, <Latex_inline math=\"A \\in \\mathbb{R}^{n\\times n}\"/> é a matriz de estado, <Latex_inline math=\"B \\in \\mathbb{R}^{n\\times m}\"/> é a matriz de entrada, <Latex_inline math=\"u_k \\in \\mathbb{R}^m\"/> é o vetor de entrada, <Latex_inline math=\"w_k\"/> representa a incerteza associada a\r\n    modelagem do processo, no qual é assumido como sendo uma distribuição gaussiana, com média nula, <Latex_inline math=\"y_k \\in \\mathbb{R}^p\"/> o vetor de saída, <Latex_inline math=\"C \\in \\mathbb{R}^{p\\times n}\"/> a matriz de saída e <Latex_inline math=\"v_k\"/> a incerteza associada a\r\n    medição da saída. Da mesma forma, $v_k$ é assumido como sendo gaussiano, com média nula e <Latex_inline math=\"w_k\"/> e <Latex_inline math=\"v_k\"/> não possuem\r\n    correlação. Para este caso, o filtro de Kalman pode ser implementado\r\n    por:\r\n    <BlockMath math=\"\r\n    \\begin{aligned}\r\n    \\hat{x}_{k+1|k} &= A\\hat{x}_{k|k}+Bu_{k}\\\\\r\n    P_{k+1|k}&=AP_{k|k} A^T+Q\\\\\r\n    K_k&=P_{k+1|k} C^T(R +CP_{k+1|k} C^T)^{-1} \\\\\r\n    \\hat{x}_{k+1|k+1} &=\\hat{x}_{k+1|k}+K_k(y_{k+1}-C\\hat{x}_{k+1|k}) \\\\\r\n    P_{k+1|k+1}&= (I-K_kC)P_{k+1|k}(I-K_kC)^T+K_kRK_k^T \r\n    \\end{aligned}\"/>\r\n<p>    \r\nCom <Latex_inline math=\"P \\in \\mathbb{R}^{n\\times n}\"/> sendo a matriz de covariância da estimativa, <Latex_inline math=\"K \\in \\mathbb{R}^{m\\times n}\"/> o ganho ótimo de Kalman, <Latex_inline math=\"Q \\in \\mathbb{R}^{n\\times n}\"/> a\r\nmatriz de covariância do modelo, <Latex_inline math=\"R \\in \\mathbb{R}^{m\\times m}\"/> a matriz de covariância das entradas, <Latex_inline math=\"I \\in  \\mathbb{R}^{n \\times n}\"/> é a matriz identidade de dimensão comptível e <Latex_inline math=\"\\hat{x}_k\"/> é o vetor de estimativas dos\r\n    estados no instante <Latex_inline math=\"k\"/>. O Filtro de Kalman funciona em duas etapas, chamadas de predição e correção. Na etapa de\r\n    predição o filtro gera uma estimativa <i>a priori</i> do vetor de estados, e na etapa de correção, caso disponível,\r\n    o filtro toma uma medição provinda de um sensor e faz a atualização, gerando uma estimativa <i>a posteriori</i>.\r\n    Note que nas equações do filtro, a notação k+1|k indica o instante $k+1$ <i>a priori</i>, ou seja, não possuindo\r\n    ainda uma medição, enquanto a notação k+1|k+1 indica o instante k+1 dado que já é conhecido uma medição. O ciclo\r\n    de funcionamento do filtro é ilustrado na Figura 2.\r\n</p>\r\n<Image src=\"https://2.bp.blogspot.com/-gF3dW3XMZLE/WV7fa-0sBLI/AAAAAAAAAWA/y8jpvSb5ngYka6SS4QW00z_dlTPvBvAXQCLcBGAs/s320/predicao.png\"\r\n                        alt=\"Etapas do Filtro de Kalman\" legend=\"Figura 2 - Filtro de Kalman\" />\r\n<p>As matrizes <Latex_inline math=\"Q\"/> e <Latex_inline math=\"R\"/> são parâmetros de sintonia do filtro de Kalman, no qual\r\n    possibilitam fazer com que ele passe a \"confiar\" mais na modelagem, conforme ilustrado na Figura 3, ou na medição,\r\n    conforme ilustrado na Figura 4. As respectivas figuras apresentam as Funções de Densidade de Probabilidade (FDP) da\r\n    saída do modelo, das medições e da saída do Filtro de Kalman. Para ilustrar o comportamento do filtro, suponha a\r\n    matriz <Latex_inline math=\"Q=qI\"/> e a matriz <Latex_inline math=\"R=rI\"/>, sendo <Latex_inline math=\"I\"/> a matriz identidade de dimensão compátivel e <Latex_inline math=\"q,r \\in \\mathbb{R}\"/>. Note\r\n    que para o caso no qual <Latex_inline math=\"q<r\"/>, a FDP do Filtro de Kalman está mais próxima da FDP do modelo. Ou seja, nesse caso,\r\n    o filtro está tendendo a gerar saídas próximas as do modelo. E no caso que <Latex_inline math=\"q>r\"/>, o filtro apresenta uma FDP mais\r\n    próxima da FDP das medidas. Assim a saída do filtro tende a gerar valores próximos aos medidos.\r\n</p>\r\n<Image src=\"https://2.bp.blogspot.com/--KLJOSzaIhI/WV7gPsqjMKI/AAAAAAAAAWE/UjdyAw1ToOgbsD2osrlHaYFLU1maoV0YwCLcBGAs/s320/kalman_q.jpg\"\r\n         alt=\"Confiança do filtro\" legend=\"Figura 3 - Maior confiança no modelo.\" />\r\n      <Image src=\"https://2.bp.blogspot.com/-xBBvXPJZYPs/WV7gPuUxFqI/AAAAAAAAAWI/id0-JAHpvuIofQ2b3s527-EMv4vBoFFIQCLcBGAs/s320/kalman_r.jpg\"\r\n             alt=\"Confiança do filtro\" legend=\"Figura 4 - Maior confiança na medição.\" />\r\n<p>\r\n    O objetivo principal deste trabalho é apresentar de forma didática as principais\r\n    etapas de implementação de um sistema de rastreamento de objetos em tempo real. Fazendo uso de abordagens\r\n    encontradas na literatura. Para aquisição da imagem, é utilizado uma câmera de baixo custo (<i>webcam</i>) e a\r\n    plataforma de programação Matlab®, no qual já conta com diversas ferramentas para processamento de imagens. O\r\n    sistema de rastreamento apresentado visa rastrear o maior objeto na cor vermelha presente na cena. E ainda lidar\r\n    também com situações de rápidas oclusões, parciais ou totais, através do uso do Filtro de Kalman.\r\n</p>\r\n    <h3>SEGMENTAÇÃO DA IMAGEM</h3>\r\n<p>\r\n    Conforme mencionado anteriormente para todo algoritmo de rastreamento de objetos\r\n    em visão computacional, existe um estágio de segmentação, de forma a identificar em cada quadro, provindo da câmera,\r\n    a posição do objeto. Uma das estratégias mais simples para a identificação de objetos numa cena é através de um\r\n    processo de limiarização. A limiarização é uma das abordagens mais importantes da segmentação de imagens. O\r\n    princípio da limiarização consiste em separar as regiões da imagem em duas classes, o fundo (<i>background</i>) e o\r\n    objeto (<i>target</i>) (ARTERO and TOMMASELLI, 2000).Neste trabalho foi optado por trabalhar com imagens\r\n    no espaço RGB (<i>Red, Green e Blue</i>). Por ser este trabalho voltado para aplicações em tempo real, o espaço de\r\n    cores RGB demonstra-se computacionalmente menos custoso, pois em geral, os dispositivos de aquisição de imagens já\r\n    trabalham neste padrão, não sendo necessário uma etapa de transformação de espaço de cores. Assim as imagens obtidas\r\n    pelo dispositivo de captura são em geral formadas por três canais de cores, representadas por matrizes. Sendo que as\r\n    entradas das matrizes são respectivamente a informação relativa ao vermelho, verde e azul para cada <i>pixel</i>,\r\n    conforme ilustrado na Figura 5.\r\n</p>    \r\n<Image src=\"https://2.bp.blogspot.com/--w3ugv-udTs/WV7hd-7ZFNI/AAAAAAAAAWQ/M4cYdEph-yIwHy2ko6LT4kmAJkOFx7nUACLcBGAs/s320/rgb.png\"\r\n                      alt=\"imagem rgb\" legend=\"Figura 5 - Imagem RGB.\"/>\r\n\r\n<p>A estratégia de limiarização adotada neste trabalho foi a subtração dos canais de\r\n    cores verde e azul do canal de cor vermelho, uma vez que busca-se rastrear os objetos na cor vermelha presente na\r\n    cena. E então considerou-se um valor limiar (<i>threshold</i>), de forma que os <i>pixels</i> resultantes com\r\n    valores inferiores a este limiar são descartados e os <i>pixels</i> com valores maiores são considerados como parte\r\n    do objeto a ser rastreado, conforme apresentado na Figura 6.\r\n</p>\r\n    <Image src=\"https://4.bp.blogspot.com/-pnYFUlaJSms/WV7ibAa9MBI/AAAAAAAAAWY/nizRhmsKjTUn6y0rjASWBKx82LuQLNbfACLcBGAs/s320/limiar.png\"\r\n                          alt=\"Limiarização\" legend=\"Figura 6 - Limiarização.\" />\r\n    <i>Obs: O valor de <Latex_inline math=\"L\"/> foi obtido empiricamente,\r\n                através de vários testes. Até chegar no valor ideal para as condições de iluminação no qual a câmera se\r\n                encontrava no momento da implementação.</i>\r\n    <p>\r\n    Como resultado da limiarização é\r\n    obtido uma imagem binária, ou seja, cujo os <i>pixels</i> possuem valores de 0 ou 1, resultando em uma imagem do\r\n    tipo preto e branca, no qual a região branca representa o objeto vermelho presente na cena. Na Figura 7 é\r\n    apresentado o resultado obtido.</p>\r\n   <Image src=\"https://3.bp.blogspot.com/-hO9_WqmaZUg/WV7itsUjNGI/AAAAAAAAAWc/34FZnxTwtXEZ4eJnJUeWSkv4daxUOPEeACLcBGAs/s320/bin.png\"\r\n                            alt=\"Resultado\" legend=\"Figura 7 - Resultado da Limiarização.\" />\r\n    <h4>Tratando dois objetos vermelhos na cena</h4>\r\n    <p>\r\n    Uma situação possível no qual é desejado que o algoritmo\r\n    apresente robustez, é no caso de existirem dois objetos na cor vermelha presente na imagem, ou mesmo a presença de\r\n    pequenos detalhes vermelhos no fundo da imagem. O resultado da limiarização para este caso, possui duas ou mais\r\n    regiões brancas conforme a Figura 8, no qual apresenta o resultado da limiarização quando é posicionado dois objetos\r\n    vermelhos diante da câmera.</p>\r\n   <Image src=\"https://1.bp.blogspot.com/-HugKp3SFnYo/WV7jDSoUkTI/AAAAAAAAAWg/NGsh3PWAebo0XRJC5SFmx6LYn27jLCdpgCLcBGAs/s320/bin_multo.png\"\r\n                            alt=\"Limiarização com dois objetos\" legend=\"Figura 8 - Limiarização com dois objetos.\"/>\r\n    <p>O objetivo deste trabalho é rastrear o maior objeto vermelho presente na cena. Portanto, faz-se\r\n    necessário a implementação de um mecanismo para buscar a posição do maior objeto vermelho. Visando o mínimo de\r\n    consumo computacional, de forma a garantir um bom funcionamento em tempo real, foi implementado o algoritmo que faz\r\n    a acumulação dos <i>pixels</i> da imagem binária, tanto na horizontal, como na vertical. Define-se a imagem binária\r\n    como sendo uma matriz <Latex_inline math=\"O \\in \\mathbb{N}^{N\\times M}\"/> definida como <Latex_inline math=\"O = \\{o_{ij}\\}\"/>, com <Latex_inline math=\"1\\leq i \\leq N\"/> e <Latex_inline math=\"1\\leq j\r\n    \\leq M\"/>, cuja entradas são 0 ou 1. O vetor de acumulação horizontal <Latex_inline math=\"H \\in \\mathbb{N}^N\"/> é definido\r\n    como:\r\n    <BlockMath math=\"\r\n    \\begin{aligned}H=[h_1~h_2~\\cdots~ h_N]^T ,\\quad h_i=\\sum_{j=1}^{M}o_{ij}, \\quad\r\n    i=1,2,\\ldots,N\\end{aligned}\"/>\r\n    E o vetor de acumulação vertical <Latex_inline math=\"V \\in \\mathbb{N}^M\"/>\r\n    como:</p>\r\n    <BlockMath math=\"\r\n    \\begin{aligned}V=[v_1~v_2~\\cdots~ v_M]^T ,\\quad v_j=\\sum_{i=1}^{N}o_{ij}, \\quad\r\n    j=1,2,\\ldots,M\\end{aligned}\"/>\r\n    \r\n    <p>\r\n    Dessa forma, o ponto <Latex_inline math=\"(x_{max},y_{max})\"/> com a maior\r\n    concentração de pixels vermelhos na imagem é dado por:\r\n    </p>\r\n    <BlockMath math=\"\r\n    \\begin{aligned}x_{max}=max(V), \\quad\r\n    y_{max}=max(H)\\end{aligned}\"/>\r\n    <p>\r\n    Na Figura 9 é ilustrado a acumulação dos <i>pixels</i> da imagem binária e\r\n    os respectivos pontos de máximo, que coincidem com o ponto na imagem que contém a maior concentração de\r\n    <i>pixels</i> vermelhos.</p>\r\n   <Image src=\"https://1.bp.blogspot.com/-btt2yn24EY4/WV7jXqyCaPI/AAAAAAAAAWk/o_w3fjIhM2wIqeWjF-LIFgLZtPm12ULswCLcBGAs/s320/acumulacao.png\"\r\n                           alt=\"Acumulação\" legend=\"Figura 9 - Acumulação\" />\r\n<p> Após a identificação da região onde possui o maior objeto vermelho na cena, define-se uma região de\r\n    interesse, formada considerando-se o intervalo de $10\\%$, para cima, para baixo e para os lados, em torno do ponto\r\n    <Latex_inline math=\"(x_{max},y_{max})\"/>. Em seguida é determinado a coordenada <Latex_inline math=\"(x_{c},y_{c})\"/> do objeto aplicando-se o cálculo do centro\r\n    geométrico na região de interesse, através das equações:\r\n    </p>   \r\n    <BlockMath math=\"      \r\n    \\begin{aligned}\r\n    x_c &=\\frac{\\sum_{i=1}^{N}o_{ij}i}{\\sum_{i=1}^{N}\\sum_{j=1}^{M}o_{ij}}\\\\\r\n    y_c &=\\frac{\\sum_{i=1}^{M}o_{ij}j}{\\sum_{i=1}^{N}\\sum_{j=1}^{M}o_{ij}}\r\n    \\end{aligned}\"/>\r\n    <h3>TRATAMENTO DE OCLUSÕES</h3>\r\n    <p>\r\n    Note que para o caso no qual é possível visualizar o objeto na cena, o\r\n    procedimento apresentado na seção anterior é suficiente para fazer o rastreamento. Porém, caso este objeto sofra uma\r\n    oclusão, o procedimento descrito falha em buscar as coordenadas do objeto. Para contornar este problema, foi tomado\r\n    como ferramenta o Filtro de Kalman e então, nas situações de oclusão, não mais é feito o processamento da imagem,\r\n    mas é gerado estimativas da posição do objeto baseando-se no ultimo instante no qual foi possível visualizar o\r\n    objeto.Para implementar o Filtro de Kalman deve-se considerar um modelo para a dinâmica do movimento do\r\n    objeto, neste trabalho optou-se por utilizar o modelo linear dado por:</p>\r\n    <BlockMath math=\"\r\n    \\begin{aligned}\r\n    \\left[\r\n    \\begin{array}{cccc}\r\n    \\hat{x}_1(k+1) \\\\ \r\n    \\hat{x}_2(k+1) \\\\ \r\n    \\hat{x}_3(k+1) \\\\ \r\n    \\hat{x}_4(k+1)\r\n    \\end{array} \\right] =\\left[ \\begin{array}{cccc}\r\n        1 & 0 & \\Delta t & 0 \\\\\r\n        0 & 1 & 0 & \\Delta t \\\\\r\n        0 & 0 & 1 & 0\\\\\r\n        0 & 0 & 0 & 1\r\n        \\end{array} \\right] \\left[ \\begin{array}{cccc}\r\n            \\hat{x}_1(k) \\\\\r\n            \\hat{x}_2(k) \\\\\r\n            \\hat{x}_3(k) \\\\\r\n            \\hat{x}_4(k)\\end{array} \\right]+\\left[ \\begin{array}{cccc}\r\n                \\frac{1}{2}\\Delta t^2 & 0 \\\\\r\n                0 & \\frac{1}{2}\\Delta t^2\\\\\r\n                \\Delta t & 0 \\\\\r\n                0 & \\Delta t \\\\\r\n                \\end{array} \\right]\\left[\r\n    \\begin{array}{cccc}\r\n    u_1(k) \\\\\r\n    u_2(k) \\end{array} \\right],\\\\\r\n    \\left[\r\n    \\begin{array}{cccc}\r\n    z_1(k) \\\\\r\n    z_2(k)\\end{array} \\right]=\\left[\r\n    \\begin{array}{cccc}\r\n    1 & 0 & 0 & 0 \\\\\r\n    0 & 1 & 0 & 0\\end{array} \\right]\\left[ \\begin{array}{cccc}\r\n        \\hat{x}_1(k) \\\\\r\n        \\hat{x}_2(k) \\\\\r\n        \\hat{x}_3(k) \\\\\r\n        \\hat{x}_4(k) \\end{array}\r\n    \\right]\\end{aligned}\"/>\r\n   \r\n   <p>\r\n    Sendo que <Latex_inline math=\"\\hat{x}_1=\\hat{x}_c\"/> é a estimativa da\r\n    coordenada horizontal, <Latex_inline math=\"\\hat{x}_2=\\hat{y}_c\"/> é a estimativa da coordenada vertical, <Latex_inline math=\"\\hat{x}_3=\\hat{v}_x\"/> é a\r\n    estimativa da velocidade na horizontal, <Latex_inline math=\"\\hat{x}_4=\\hat{v}_y\"/> é a estimativa da velocidade na vertical, <Latex_inline math=\"u_1=a_x\"/> é\r\n    a aceleração horizontal e <Latex_inline math=\"u_2=a_y\"/> é a aceleração vertical. Note que o modelo descreve um movimento retilíneo\r\n    uniformemente variado (MURV) e o $\\Delta t$ presente, indica o tempo de amostragem, que para este caso, é o tempo no\r\n    qual o Matlab® leva para processar cada quadro da cena.\r\n    </p>\r\n <i>Obs: Os valores de <Latex_inline math=\"a_x\"/> e <Latex_inline math=\"a_y\"/> são obtidos\r\n                através dos frames anteriores, fazendo aproximação da derivada segunda da posição.</i>\r\n                <p>\r\n   Com o modelo definido, pode-se aplicar as equações do Filtro de Kalman apresentadas na introdução\r\n    e então gerar estimativas para a posição do objeto vermelho. Porém, como é desejado o tratamento de oclusões, foi\r\n    optado por utilizar não apenas um, mas dois Filtros de Kalman, sendo que o primeiro é sintonizado para ter\r\n    \"confiança\" na medição. E o segundo \"confiança\" no modelo. Assim obtêm-se um algoritmo com maior robustez. A Figura\r\n    10 apresenta o diagrama conceitual da estrutura utilizada.\r\n    </p>\r\n<Image src=\"https://1.bp.blogspot.com/-XpoyRu0bpdc/WV7jsc2OIlI/AAAAAAAAAWo/pZh80J0V2LQqaG3vI_MHqad1PTcIiyIAwCLcBGAs/s320/diagram.png\"\r\n                           alt=\"estrutura\" legend=\"Figura 10 - Estrutura.\" />\r\n<p>Note que a saída passa a ser <Latex_inline math=\"Y_1\"/> e <Latex_inline math=\"Y_2\"/>, que são selecionadas conforme a\r\n    detecção ou não de oclusões. Nos instantes em que não existe oclusão, a saída é aquela provinda do Filtro de\r\n    Kalman que \"confia\" mais na medição. E quando verifica-se uma oclusão, é selecionado a saída do Filtro de Kalman que\r\n    \"confia\" mais no modelo. Esta estratégia foi necessária pois, o filtro sintonizado para confiar no modelo apresenta\r\n    bons resultados nas situações de oclusão, porém uma baixa eficiência na situações sem oclusão e\r\n    vice-versa.\r\n    </p>\r\n    <h3>RESULTADO</h3>O resultado obtido pelo algoritmo de rastreamento desenvolvido é apresentado nesta seção.\r\n    Para situações sem oclusão, o resultado é conforme apresentado na Figura 11.\r\n   <Image src=\"https://4.bp.blogspot.com/-yAXdYw8HpeI/WV7j6jeVzHI/AAAAAAAAAWs/cgOV-Jz_lqYWKwdVxT8POMYlABE7guPJQCLcBGAs/s320/frame_so.png\"\r\n                            alt=\"sem oclusão\" legend=\"Figura 11 - Sem oclusão.\" />\r\n    Para as situações com oclusão, o resultado é apresentado na Figura 12.\r\n    <Image src=\"https://1.bp.blogspot.com/-DESUcQuAcL0/WV7kHCAeJzI/AAAAAAAAAWw/QNZ-F05mHA0QI_gjyHi_Ao0_g0v-Ti5qACLcBGAs/s320/frame_co.png\"\r\n                           alt=\"Com oclusão\" legend=\"Figura 12 - Com oclusão\"/>\r\n\r\nNos instantes em que não é possível visualizar o objeto, é tomado os valores\r\n    obtidos pelo Filtro de Kalman sintonizado para \"confiar\" no modelo, então baseando-se no ultimo instante que foi\r\n    possível visualizar o objeto, é gerado estimativas da trajetória do objeto conforme apresentado na Figura\r\n    13.\r\n    <Image src=\"https://2.bp.blogspot.com/-HTJYIdaKPfo/WV7ksya140I/AAAAAAAAAW0/mVVB5ByEcfEHSD14V-LR56SWBKW8Moj7QCLcBGAs/s320/trajetoria.jpg\"\r\n                            alt=\"trajetória\" legend=\"Figura 13 - Trajetória.\" />\r\n\r\nNote que como o modelo utilizado é linear, a estimativa obtida é de uma\r\n    trajetória retilínea. No entanto, para situações sem oclusão, por ser utilizado um filtro sintonizado para \"confiar\"\r\n    na medição, obtêm-se um bom desempenho para movimentos não-lineares, conforme apresentado na Figura 14.\r\n    <Image src=\"https://2.bp.blogspot.com/-WSzLStoHZcE/WV7lE7OI4LI/AAAAAAAAAW4/x2HsJzoqSawuF4gBJ_cjsNQQQjFWFFFkACLcBGAs/s320/trajet2.jpg\"\r\n                           alt=\"não-linear\" legend=\"Figura 14 - Movimentos não-lineares\"/>\r\n    <h3>VÍDEO DEMONSTRAÇÃO</h3>\r\n<center>\r\n   <iframe allowfullscreen=\"\"\r\n            class=\"YOUTUBE-iframe-video\" data-thumbnail-src=\"https://i.ytimg.com/vi/tREbIw9DxHA/0.jpg\" frameborder=\"0\"\r\n            height=\"480\" src=\"https://www.youtube.com/embed/tREbIw9DxHA?feature=player_embedded\" width=\"650\"></iframe>\r\n</center>\r\n    <h3>CÓDIGO FONTE</h3> \r\n    <center>\r\n<a href=\"https://github.com/Marofe/Object-Tracking/blob/master/kalman_live.m\">https://github.com/Marofe/Object-Tracking/blob/master/kalman_live.m</a>\r\n</center>\r\n<h3>CONCLUSÃO</h3>\r\n    <p>\r\n    Com o desenvolvimento deste trabalho foi possível verificar na prática o desempenho do\r\n    Filtro de Kalman para estimar a trajetória de objetos com situações no qual existe falta de informação. Também foi\r\n    apresentado os principais detalhes de implementação do sistema de visão computacional, voltando-se para a área de\r\n    rastreamento de objetos. Mostrou-se que é possível obter um desempenho satisfatório para rastreamento de objetos em\r\n    cenas obtidas por uma câmera de baixo custo, mesmo com a presença de mais de um objeto da mesma cor. O algoritmo\r\n    apresentou boa eficiência para situações de rápidas oclusões observou-se que este projeto ilustra de forma simples o\r\n    potencial do Filtro de Kalman e sua relativa simplicidade de implementação.\r\n    </p>\r\n    <h3>REFERÊNCIAS</h3>\r\n    <p>\r\n    <b>ARTERO, A. and TOMMASELLI, A. (2000)</b>. Limiarização automática de imagens digitais,\r\n    Boletim de Ciências Geodésicas 6(1): 38–48.\r\n    </p>\r\n<p>\r\n    <b>Freitas, G. M. et al. (2010)</b>. Rastreamento de objetos\r\n    em vídeos e separação em classes.\r\n    </p>  \r\n    <p>\r\n    <b>Funk, N. (2003)</b>. A study of the kalman filter applied to visual\r\n    tracking, University of Alberta, Project for CMPUT 652(6).\r\n    </p>\r\n    <p>\r\n    <b>Iraei, I. and Faez, K. (2015)</b>. Object\r\n    tracking with occlusion handling using mean shift, kalman filter and edge histogram, Pattern Recognition and Image\r\n    Analysis (IPRIA), 2015 2nd International Conference on, IEEE, pp. 1–6.\r\n    </p>  \r\n    <p>\r\n    <b>Kalman, R. E. et al. (1960)</b>. A new approach to linear filtering and prediction problems, Journal of basic Engineering 82(1):\r\n    35–45.\r\n    </p> \r\n    <p>\r\n    <b>Pinho, R. R., Tavares, J. M. R. S. and Correia, M. F. P. V. (2004).</b> Introdução à análise de\r\n    movimento usando visão computacional.\r\n    </p>\r\n    <p>\r\n    <b>Relli, C. (2014)</b>. Caracterização de algoritmos de\r\n    rastreamento de objetos em video considerando situações de oclusão, RETEC-Revista de Tecnologias\r\n    6(1).\r\n    </p> \r\n    <p>\r\n    <b>Van den Bergh, M. and Van Gool, L. (2011)</b>. Combining rgb and tof cameras for real-time 3d\r\n    hand gesture interaction, Applications of Computer Vision (WACV), 2011 IEEE Workshop on, IEEE,p.\r\n    66–72.\r\n    </p>\r\n    <p>\r\n    <b>WANGENHEIM, A. v. et al. (2001)</b>. Seminario introdução a visão computacional, Visão\r\n    Computacional Aldon von Wangenheim’s HomePage.\r\n    </p>\r\n    <p>\r\n    <b>Welch, G. and Bishop, G. (1995)</b>. An introduction to\r\n    the kalman filter.\r\n    </p>\r\n    <p>\r\n    <b>Weng, S.-K., Kuo, C.-M. and Tu, S.-K. (2006)</b>. Video object tracking using\r\n    adaptive kalman filter,Journal of Visual Communication and Image Representation 17(6): 1190–1208.\r\n    </p>\r\n    <Disqus.DiscussionEmbed shortname={disqusShortname} config={disqusConfig} />\r\n    </article>    \r\n}\r\nexport default Tutorial1;\r\n","import React from 'react';\r\nimport './Tutorials.css';\r\nconst TutorialList = (prop) => {\r\n    return <div className=\"divPage\">\r\n    <div class='listCell'>\r\n    <h2><a href=\"/tutorials/rastreamento_usando_visao_filtro_kalman\">Rastreamento de objetos usando Visão Computacional e Filtro de Kalman</a></h2>\r\n    <p>Este trabalho apresenta um algoritmo em tempo real para rastreamento de objetos\r\nem visão computacional, usando o Filtro de Kalman como mecanismo de predição para situações de oclusão e ou\r\ncontaminação da cena por ruído. O principal objetivo deste trabalho é de apresentar de forma didática o\r\ndesenvolvimento de um algoritmo de rastreamento de objetos baseado em cor. O algoritmo apresentado faz o\r\nrastreamento do maior objeto simétrico de uma cor pré-definida presente na cena. É apresentado em detalhes a\r\nimplementação da etapa de segmentação da imagem, e posteriormente é apresentado uma estratégia para tratar situações\r\ncom dois objetos da mesma cor. Por fim é demonstrado o uso do Filtro de Kalmam.</p>\r\n<p>Última atualização:  13 de Dezembro de 2015.</p>\r\n</div>\r\n</div>\r\n}\r\nexport default TutorialList;","import React from 'react';\r\nimport Helmet from 'react-helmet';\r\nimport {Route} from 'react-router-dom';\r\nimport KfVision from '../../Content/Tutorials/kf_vision_pt';\r\nimport TutorialList from './TutorialList';\r\nimport './Tutorials.css';\r\nconst Tutorials = () => {\r\n    return <div className=\"divPage\">\r\n    <Helmet>\r\n        <title>Tutorials | Marcos Rogério Fernandes</title>\r\n        <meta name=\"description\" content=\"Here you will find some of my tutorials and toy examples. \" />\r\n    </Helmet>\r\n    <div className=\"top\">\r\n       <h1>Tutorials</h1>\r\n    </div>\r\n     <Route path=\"/tutorials\" exact render={(props) => <TutorialList/>}/>\r\n     <Route path=\"/tutorials/rastreamento_usando_visao_filtro_kalman\" exact render={(props) => <KfVision/>}/>\r\n    </div>\r\n}\r\nexport default Tutorials;","import React from 'react';\r\nimport './Notes.css';\r\nimport Helmet from 'react-helmet';\r\nconst NotesList = (props) => {\r\n    let list= props.notes.map((note)=>(\r\n        <div className=\"listCell\">\r\n            <h2><a href={'/notes/'+note.link}>{note.title}</a></h2>\r\n            <p>{note.desc}</p>\r\n        </div>\r\n    ));\r\n    return   <div>\r\n  <Helmet>\r\n    <title>Notes | Marcos Rogério Fernandes</title>\r\n    <meta name=\"description\" content=\"Here you will find my research notes.\" />\r\n</Helmet>\r\n<div className=\"top\">\r\n   <h1>My Notes</h1>\r\n   <p>The following contents are some of my research notes about a few topics that I have been working on.</p>\r\n</div>\r\n{list}\r\n</div>\r\n}\r\nexport default NotesList;","import React from 'react';\r\nimport Helmet from 'react-helmet';\r\nimport '../../../Components/Pages/Tutorials.css';\r\nimport { BlockMath } from 'react-katex';\r\nimport Inline from '../../../Components/Latex/Inline';\r\nimport '../../../../node_modules/katex/dist/katex.css';\r\nimport Image from '../../../Components/Image/Image';\r\nimport Disqus from 'disqus-react';\r\nconst EkfLie = (props) => {\r\n    const disqusShortname = 'marofe-github-io';\r\n        const disqusConfig = {\r\n            url: 'https://marofe.github.io/?p='+props.note.link,\r\n            identifier: 'note-'+props.note.link,\r\n            title: props.title\r\n        };\r\n        //console.log(process.env.PUBLIC_URL+'/tutorials/rastreamento_usando_visao_filtro_kalman');\r\n    return <article>\r\n      <Helmet>\r\n        <title>{props.note.title}| Marofe</title>\r\n        <meta name=\"description\" content={props.note.desc} />\r\n    </Helmet>\r\n    <h1>{props.title}</h1>\r\n<p>{props.desc}</p>\r\n    <p align=\"right\">Last Update:  26 December, 2019.</p>\r\n<div>\r\nConsider a dynamic system in which its states are embedded on a Matrix Lie Group <Inline math=\"G\"/> of dimension <Inline math=\"n\"/> and measurements are available through a map: <Inline math=\"h:G\\rightarrow G'\"/>, where <Inline math=\"G'\"/> is a Matrix Lie Group of dimension <Inline math=\"m\"/>, described by\r\n<BlockMath math=\"\\begin{aligned}\r\n {X}_{k+1}&= {X}_k \\exp_G([ \\Omega( {X}_k, {u}_k)+  w_k]_G^\\wedge),\\\\\r\n {Y}_k &=   h( {X}_k)  \\exp_{G'}([  \\nu_k]_{G'}^\\wedge)\r\n\\end{aligned}\"/>\r\nwhere <Inline math=\"{X}_k\\in M\\subseteq G\"/> is the state and <Inline math=\"{Y}_k \\in M'\\subseteq G'\"/> is the measurement. <Inline math=\"M,M'\"/> are subgroups of <Inline math=\"G,G'\"/>, respectively, such that the following bijection is well defined\r\n<BlockMath math=\"\\begin{aligned}\r\n \\ln_G( \\exp_G( {X}_k))&= {X}_k,\\\\\r\n \\ln_{G'}( \\exp_{G'}( {Y}_k))&= {Y}_k\r\n\\end{aligned}\"/>\r\nand <Inline math=\"w_k\\sim \\mathcal{N}(0,Q_k)\"/> and <Inline math=\"\\nu_k\\sim \\mathcal{N}(0,R_k)\"/>.\r\n<center><h2>Filtering</h2></center>\r\n<b>Prediction:</b>\r\n<BlockMath math=\"\r\n\\begin{aligned}\r\n {\\hat{X}}_{k+1|k}&= {\\hat{X}}_{k|k}\\exp_G([\\hat{\\Omega}_k]_G^\\wedge)\\\\\r\nP_{k+1|k}&=\\mathscr{F}_kP_{k|k}\\mathscr{F}_k^{\\intercal}+\\Phi(\\hat{\\Omega}_k)Q_k\\Phi(\\hat{\\Omega}_k)^\\intercal\r\n\\end{aligned}\"/>\r\nwhere \r\n<BlockMath math=\"\r\n\\begin{aligned}\r\n\\hat{\\Omega}_k&=\\Omega_k( {\\hat{X}}_{k|k},u_k)\\\\\r\n\\mathscr{F}_k&=Ad_G(\\exp_G([-\\hat\\Omega_k]_G^\\wedge))+\\Phi(\\hat\\Omega_k)\\mathscr{C}_k\\\\\r\n\\mathscr{C}_k&=\\frac{\\partial}{\\partial \\epsilon}\\Omega_k( {\\hat{X}}_{k|k}\\exp_G([\\epsilon]_G^\\wedge),u_k)|_{\\epsilon=0}\\\\\r\n\\Phi(a)&=\\sum_{m=0}^\\infty \\frac{(-1)^m}{(m+1)!}ad_G(a)^m\r\n\\end{aligned}\"/>\r\n<b>Update:</b>\r\n<BlockMath math=\"\r\n\\begin{aligned}\r\nK&=P_{k+1|k}\\mathscr{H}^\\intercal(R+\\mathscr{H}_kP_{k+1|k}\\mathscr{H}_k^T)^{-1}\\\\\r\nv_k&=K\\ln_{G'}(h( {\\hat{X}}_{k+1|k})^{-1}y_{k+1})^\\vee_{G'}\\\\\r\n {\\hat{X}}_{k+1|k+1}&= {\\hat{X}}_{k+1|k} \\exp([v_k]_G^\\wedge)\\\\\r\nP_{k+1|k+1}&=\\Phi(v_k)(I-K\\mathscr{H}_k)P_{k+1|k}\\Phi(v_k)^\\intercal\r\n\\end{aligned}\"/>\r\nwhere\r\n<BlockMath math=\"\r\n\\begin{aligned}\r\n\\mathscr{H}_k=\\frac{\\partial}{\\partial \\epsilon}\\left[ \\ln_{G'}(h( {\\hat{X}}_{k+1|k})^{-1}h( {\\hat{X}}_{k+1|k} \\exp([ \\epsilon]^\\wedge_{G})))\\right]^{\\vee}_{G'}\\big|_{ \\epsilon=0}\r\n\\end{aligned}\"/>\r\n</div>\r\n    <Disqus.DiscussionEmbed shortname={disqusShortname} config={disqusConfig} />\r\n    </article>    \r\n}\r\nexport default EkfLie;\r\n","import React from 'react';\r\nimport { BlockMath } from 'react-katex';\r\nconst Latex = (props)=> {\r\nreturn <div id={props.label}>\r\n    <BlockMath math={props.math}/>\r\n    </div>;\r\n}\r\nexport default Latex;","import React from 'react';\r\nimport Helmet from 'react-helmet';\r\nimport '../../../Components/Pages/Tutorials.css';\r\nimport { BlockMath } from 'react-katex';\r\nimport Inline from '../../../Components/Latex/Inline';\r\nimport Latex from '../../../Components/Latex/latex';\r\nimport '../../../../node_modules/katex/dist/katex.css';\r\nimport Image from '../../../Components/Image/Image';\r\nimport Disqus from 'disqus-react';\r\nconst RiccatiEq = (props) => {\r\nconst disqusShortname = 'marofe-github-io';\r\nconst disqusConfig = {\r\n        url: 'https://marofe.github.io/?p='+props.note.link,\r\n        identifier: 'note-'+props.note.link,\r\n        title: props.title\r\n    };\r\nreturn <article>\r\n      <Helmet>\r\n        <title>{props.note.title} | Marofe</title>\r\n        <meta name=\"description\" content={props.note.desc} />\r\n    </Helmet>\r\n    <h1>{props.title}</h1>\r\n<p>{props.desc}</p>\r\n    <p align=\"right\">Last Update:  September 19, 2021.</p>\r\n<div>\r\n<h2>The Differential Riccati Equation</h2>\r\n\r\nThe selection of an optimal control law and the design of optimal filters require the solving of a Riccati Equation. So, Riccati type equations emerge naturally on control and filtering problems of  dynamic systems. \r\n<p></p>\r\nTo find solutions for Riccati Equations, it is convenient to make subdivisions based in the nature of the coefficient matrices and the time interval considered. \r\n<p></p>\r\n<div class='itemize'><lu>\r\n\t<li> Time-varying coefficients; <Inline math=\"t_1<\\infty\"/>.</li>\r\n\t<li> Time-varying coefficients; <Inline math=\"t_1\\rightarrow \\infty\"/>.</li>\r\n\t<li> Constant coefficients; <Inline math=\"t_1<\\infty\"/>.</li>\r\n\t<li> Constant coefficient; <Inline math=\"t_1\\rightarrow \\infty\"/>.</li>\r\n</lu></div>\r\n<p></p>\r\nIn particular, we restrict attention to the Riccati equation occurring in a situation when a boundary condition will be given at <Inline math=\"t_1\"/> with the solution desired for <Inline math=\"t\\le t_1\"/>. Recall that the Riccati Equation in the context of control problem runs \"backward\" in time.\r\n<p></p>\r\n<Image src=\"/images/p_finite.svg\" label=\"fig:p_finite\" legend=\"Trace of $P(t)$ for Finite Horizon. The evolution is 'backward' in time.\" width=\"50%\"/>\r\n<p></p>\r\nThe following results are based on the book <a href=\"#cite.Anderson1971\">Anderson1971</a>. It shows that in all four cases, it is possible to replace the problem of solving the <i>nonlinear</i> Riccati differential equation by the problem of solving a <i>linear</i> differential equation and then computing a matrix inverse. \r\n<h3>Time-Varying Coeff. and Finite Horizon</h3>\r\n\r\nConsider the differential Riccati equation for <Inline math=\"t \\le t_1\"/> of the form\r\n<Latex math=\"\\begin{aligned}\r\n\t-\\dot{P}=P(t)F(t)+F(t)^T P(t)-P(t)G(t)R^{-1}(t)G(t)^T P(t)+Q(t)\r\n\\end{aligned}\" label=\"eq:diff_riccati\"/>\r\nand the following assumptions: \r\n<Latex math=\"\\begin{aligned}\r\nP(t_1)&=P_1=P_1^T \\ge 0\\\\\r\nQ(t)&=Q(t)^T \\ge 0,\\\\\r\nR(t)&=R(t)^T >0.\r\n\\end{aligned}\"/>\r\n<p></p>\r\nAssociated with <a href=\"#eq:diff_riccati\">eq:diff_riccati</a> we define an augmented <i>linear</i> differential equation\r\n<Latex math=\"\\begin{aligned}\r\n\t\\left[\r\n\t\\begin{matrix}\r\n\t\\dot{X}(t)\\\\\r\n\t\\dot{Y}(t)\r\n\t\\end{matrix}\r\n\t\\right]=\\left[\r\n\t\\begin{matrix}\r\n\tF(t) & -G(t)R^{-1}(t)G(t)^T \\\\\r\n\t-Q(t) & -F(t)^T\r\n\t\\end{matrix}\r\n\t\\right]\\left[\r\n\t\\begin{matrix}\r\n\tX(t)\\\\\r\n\tY(t)\r\n\t\\end{matrix}\r\n\t\\right],\\quad \\left[\r\n\t\\begin{matrix}\r\n\tX(t_1)\\\\\r\n\tY(t_1)\r\n\t\\end{matrix}\r\n\t\\right]=\\left[\r\n\t\\begin{matrix}\r\n\tI\\\\\r\n\tP_1\r\n\t\\end{matrix}\r\n\t\\right].\r\n\\end{aligned}\" label=\"eq:augm_riccati\"/>\r\n<div class='lemma'><b>Lemma:</b><br/>\r\n\tIf the solution of <a href=\"#eq:diff_riccati\">eq:diff_riccati</a> exists on <Inline math=\"[t,t_1]\"/> then the solution of <a href=\"#eq:augm_riccati\">eq:augm_riccati</a> has the property that <Inline math=\"X^{-1}(t)\"/> exists and\r\n<Latex math=\"\\begin{aligned}\r\n\t\tP(t)=Y(t)X^{-1}(t).\r\n\\end{aligned}\"/>\r\n</div>\r\n<div class='proof'><b>Proof:</b><br/>\r\n\tBy the <i>product rule</i> and <i>inverse rule</i> of matrix calculus, one have\r\n<Latex math=\"\\begin{aligned}\r\n\t\t\\frac{d}{dt}[Y(t)X^{-1}(t)]&=\\dot{Y}(t)X^{-1}(t)-Y(t)X^{-1}(t)\\dot{X}(t)X^{-1}(t).\r\n\\end{aligned}\"/>\r\n\tNotice that from <a href=\"#eq:augm_riccati\">eq:augm_riccati</a> we have\r\n<Latex math=\"\\begin{aligned}\r\n\t\t\\dot{X}(t)&=F(t)X(t)-G(t)R^{-1}(t)G(t)^T Y(t),\\\\\r\n\t\t\\dot{Y}(t)&=-Q(t)X(t)-F(t)^T Y(t)\r\n\\end{aligned}\" label=\"eq:difY\"/>\r\n\tThus,\r\n<Latex math=\"\\begin{aligned}\r\n\t\\frac{d}{dt}[YX^{-1}]&=(-QX-F^T Y)X^{-1}-YX^{-1}(FX-GR^{-1}G^T Y)X^{-1}\\\\\r\n\t&=-QXX^{-1}-F^T YX^{-1}-YX^{-1}FXX^{-1}+YX^{-1}GR^{-1}G^T YX^{-1}\\\\\r\n\t&=-Q-F^T (YX^{-1})-(YX^{-1})F+(YX^{-1})GR^{-1}G^T(YX^{-1})\\\\\r\n\t&=-Q-F^T P-PF+PGR^{-1}G^T P\r\n\\end{aligned}\"/>\r\n\twhere for notation simplicity we adopt <Inline math=\"X(t)=X,Y(t)=Y,Q(t)=Q,F(t)=F,G(t)=G,R(t)=R\"/> and <Inline math=\"P(t)=P\"/>. As a result, we conclude that\r\n<Latex math=\"\\begin{aligned}\r\n\t\t-\\dot{P}=Q+F^T P+PF-PGR^{-1}G^T P.\r\n\\end{aligned}\"/>\r\nThe preceding manipulations also show that if <Inline math=\"X^{-1}(\\sigma)\"/> exists for all <Inline math=\"\\sigma \\in [t,t_1]\"/> then <Inline math=\"P(t)\"/> exists for the same interval. Let us now check that the existence of <Inline math=\"P(t)\"/> guarantees the existence of <Inline math=\"X^{-1}(t)\"/>.\r\n<p></p>\r\nLet <Inline math=\"\\Phi(\\cdot,\\cdot)\"/> be the <i>Transition Matrix</i> associated with the system\r\n<Latex math=\"\\begin{aligned}\r\n\t\\dot{X}=[F(t)-G(t)R^{-1}(t)G(t)^T P(t)]X(t)\r\n\\end{aligned}\"/>\r\nAs long as <Inline math=\"P(t)\"/> exists for <Inline math=\"t\\le t_1\"/> then <Inline math=\"\\Phi(\\cdot,\\cdot)\"/> is defined for all its arguments values less or equal to <Inline math=\"t_1\"/>. We claim that\r\n<Latex math=\"\\begin{aligned}\r\n\tX(t)=\\Phi(t,t_1),\\quad Y(t)=P(t)\\Phi(t,t_1).\r\n\\end{aligned}\" label=\"eq:claim\"/>\r\nThis is sufficient to prove that <Inline math=\"X^{-1}(t)\"/> exists, since <Inline math=\"\\Phi(t,t_1)^{-1}=\\Phi(t_1,t)\"/> is known to exist.\r\n<p></p>\r\nTo verify the claim <a href=\"#eq:claim\">eq:claim</a>, we have\r\n<Latex math=\"\\begin{aligned}\r\n\t\\dot{\\Phi}&=[F-GR^{-1}G^T P]\\Phi\\\\\r\n\t&=FX-GR^{-1}G^T Y=\\dot{X}\r\n\\end{aligned}\" label=\"eq:difPhi\"/>\r\nand\r\n<Latex math=\"\\begin{aligned}\r\n\t\\frac{d}{dt}[P\\Phi]&=\\dot{P}\\Phi+P\\dot{\\Phi}\\\\\r\n&=-(PF+F^T P-PGR^{-1}G^T P+Q)\\Phi +P(F\\Phi-GR^{-1}G^T Y)\\\\\r\n&=-QX -F^T Y=\\dot{Y}\r\n\\end{aligned}\"/>\r\nTherefore, we have that the relations <a href=\"#eq:claim\">eq:claim</a> satisfy <a href=\"#eq:difX\">eq:difX</a> and <a href=\"#eq:difY\">eq:difY</a>.\r\n<p align=\"right\"><Inline math=\"\\blacksquare\"/></p></div>\r\n<p></p>\r\n<div class='remark'><b>Remark:</b><br/>\r\nAnother scenario that might occur is when <Inline math=\"t_1\\rightarrow \\infty\"/> and the matrix coefficients are varying. For this case, only an approximation for <Inline math=\"P_\\infty\"/> is possible to obtain by integrating <a href=\"#eq:augm_riccati\">eq:augm_riccati</a>. However, that approximation depends on the length <Inline math=\"t_1\"/>. Thus, the approximation becomes better as <Inline math=\"t_1\"/> is increased.\r\n</div>\r\n<h3>Const. Coeff and Finite Horizon (<Inline math=\"t_1<\\infty\"/>)</h3>\r\n\r\nFor this scenario, consider\r\n<Latex math=\"\\begin{aligned}\r\n-\\dot{P}=P(t)F+F^T P(t)-P(t)GR^{-1}G^T P(t)+Q\r\n\\end{aligned}\" label=\"eq:diff_riccati_cost\"/>\r\nwhere <Inline math=\"F,G,R\"/> and <Inline math=\"Q\"/> are constant matrices. The respective augmented linear differential equation is\r\n<Latex math=\"\\begin{aligned}\r\n\\left[\r\n\\begin{matrix}\r\n\\dot{X}(t)\\\\\r\n\\dot{Y}(t)\r\n\\end{matrix}\r\n\\right]=\\left[\r\n\\begin{matrix}\r\nF & -GR^{-1}G^T \\\\\r\n-Q & -F^T\r\n\\end{matrix}\r\n\\right]\\left[\r\n\\begin{matrix}\r\nX(t)\\\\\r\nY(t)\r\n\\end{matrix}\r\n\\right],\\quad \\left[\r\n\\begin{matrix}\r\nX(t_1)\\\\\r\nY(t_1)\r\n\\end{matrix}\r\n\\right]=\\left[\r\n\\begin{matrix}\r\nI\\\\\r\nP_1\r\n\\end{matrix}\r\n\\right].\r\n\\end{aligned}\" label=\"eq:augm_riccati_const\"/>\r\nAs long as all coefficients are constant, the closed-form solution is\r\n<Latex math=\"\\begin{aligned}\r\n\\left[\r\n\\begin{matrix}\r\nX(t)\\\\\r\nY(t)\r\n\\end{matrix}\r\n\\right]=\\exp\\left(\\left[\r\n\\begin{matrix}\r\nF & -GR^{-1}G^T \\\\\r\n-Q & -F^T\r\n\\end{matrix}\r\n\\right](t_1-t)\\right)\\left[\r\n\\begin{matrix}\r\nX(t_1)\\\\\r\nY(t_1)\r\n\\end{matrix}\r\n\\right].\r\n\\end{aligned}\"/>\r\nSetting,\r\n<Latex math=\"\\begin{aligned}\r\n\\left[ \r\n\\begin{matrix}\r\n\\Phi_{11}(t) && \\Phi_{12}(t)\\\\\r\n\\Phi_{21}(t) && \\Phi_{22}(t)\r\n\\end{matrix}\r\n\\right]=\r\n\\exp\\left(\\left[\r\n\\begin{matrix}\r\nF & -GR^{-1}G^T \\\\\r\n-Q & -F^T\r\n\\end{matrix}\r\n\\right](t_1-t)\\right)\r\n\\end{aligned}\"/>\r\nthen, the Riccati closed-form solution is\r\n<Latex math=\"\\begin{aligned}\r\nP(t)=\\left[\\Phi_{21}(t)X(t_1)+\\Phi_{22}(t)Y(t_1)\\right]\\left[\\Phi_{11}(t)X(t_1)+\\Phi_{12}(t)Y(t_1)\\right]^{-1}.\r\n\\end{aligned}\"/>\r\n<h3>Constant Coeff. and <Inline math=\"t_1\\rightarrow \\infty\"/></h3>\r\n\r\nWhen <Inline math=\"t_1 \\rightarrow \\infty\"/> with constant coefficients, we obtain the so-called  <i>Algebraic Riccati Equation</i>\r\n<Latex math=\"\\begin{aligned}\r\n0=P_\\infty F+F^T P_\\infty-P_\\infty GR^{-1}G^T P_\\infty+Q.\r\n\\end{aligned}\" label=\"eq:riccati_const\"/>\r\n<Image src=\"/./images/p_infinite.svg\" label=\"fig:p_infinite\" legend=\"Trace of $P(t)$ for infinite Horizon.\" width=\"50%\"/>\r\nThis is also known as the <i>Steady-state Solution</i> of the Riccati Equation. It is implicitly assumed that the dynamic system associated with the Riccati equation is controllable and observable. The controllability assumption guaranteeing that the steady-state solution exists, and the observability assumption assures that this solution is positive definite.\r\n<p></p>\r\nThere are plenty of different approaches to solve <a href=\"#eq:riccati_const\">eq:riccati_const</a> in the literature. Here, we focus on only one method that consist in construct the augmented matrix\r\n<Latex math=\"\\begin{aligned}\r\n\tM=\\left[\r\n\t\\begin{matrix}\r\n\tF & -GR^{-1}G^T \\\\\r\n\t-Q & -F^T \r\n\t\\end{matrix}\r\n\t\\right].\r\n\\end{aligned}\"/>\r\n<p></p>\r\nThis <Inline math=\"M\"/> matrix has the property that there is no pure imaginary eigenvalue and if <Inline math=\"\\lambda\"/> is an eigenvalue  of <Inline math=\"M\"/>, so is <Inline math=\"-\\lambda\"/>. We then construct a matrix <Inline math=\"T\"/>\r\n<Latex math=\"\\begin{aligned}\r\nT=\\left[\r\n\\begin{matrix}\r\nT_{11} & T_{12} \\\\\r\nT_{21} & T_{22} \r\n\\end{matrix}\r\n\\right]\r\n\\end{aligned}\"/>\r\nsuch that\r\n<Latex math=\"\\begin{aligned}\r\n\tT^{-1}MT=\\left[\r\n\t\\begin{matrix}\r\n\t-\\Lambda & 0 \\\\\r\n\t0 & \\Lambda \r\n\t\\end{matrix}\r\n\t\\right]\r\n\\end{aligned}\"/>\r\nThus, the solution is simply given by\r\n<Latex math=\"\\begin{aligned}\r\n\tP_\\infty=T_{21}T_{11}^{-1}.\r\n\\end{aligned}\"/>\r\n<div class='proof'><b>Proof:</b><br/>\r\nto check this solution, first notice that\r\n<Latex math=\"\\begin{aligned}\r\n\tMT=T\\left[\r\n\t\\begin{matrix}\r\n\t-\\Lambda & 0 \\\\\r\n\t0 & \\Lambda \r\n\t\\end{matrix}\r\n\t\\right]\r\n\\end{aligned}\"/>\r\nThis results in\r\n<Latex math=\"\\begin{aligned}\r\n\tFT_{11}-GR^{-1}G^T T_{21}&=-T_{11}\\Lambda,\\\\\r\n\t-QT_{11}-F^T T_{21}&=-T_{21}\\Lambda.\r\n\\end{aligned}\"/>\r\n<p></p>\r\nMultiplying by <Inline math=\"T_{11}^{-1}\"/> on the right side of both equations and by <Inline math=\"T_{21}T_{11}^{-1}\"/> only in the first, we have\r\n<Latex math=\"\\begin{aligned}\r\n\tT_{21}T_{11}^{-1}F-T_{21}T_{11}^{-1}GR^{-1}G^T T_{21}T_{11}^{-1}=-T_{21}\\Lambda T_{11}^{-1}\r\n\\end{aligned}\"/>\r\nand\r\n<Latex math=\"\\begin{aligned}\r\n\t-Q-F^T T_{21}T_{11}^{-1}=-T_{21}\\Lambda T_{11}^{-1}\r\n\\end{aligned}\"/>\r\nTherefore,\r\n<Latex math=\"\\begin{aligned}\r\n\t(T_{21}T_{11}^{-1})F+F^{T}(T_{21}T_{11}^{-1})-(T_{21}T_{11}^{-1})GR^{-1}G^T (T_{21}T_{11}^{-1})+Q=0.\r\n\\end{aligned}\"/>\r\n<p align=\"right\"><Inline math=\"\\blacksquare\"/></p></div>\r\n<p></p>\r\n<h3><Inline math=\"P(t)\"/> based on <Inline math=\"P_\\infty\"/></h3>\r\n\r\nAs discussed in <a href=\"#cite.Anderson1971\">Anderson1971</a>, if the steady-state solution is available in advance, we can establish a closed-form solution for the differential Riccati Equation for the entire horizon. In other words, we seek the expression <Inline math=\"P(t)\"/> for \r\n<Latex math=\"\\begin{aligned}\r\n\t-\\dot{P}=PF+F^T P-PGR^{-1}G^T P +Q,\r\n\\end{aligned}\"/>\r\na given <Inline math=\"P_\\infty\"/> such that\r\n<Latex math=\"\\begin{aligned}\r\n\tP_\\infty F+F^T P_\\infty-P_\\infty GR^{-1}G^T P_\\infty +Q=0.\r\n\\end{aligned}\"/>\r\n<p></p>\r\nFor this purpose, consider\r\n<Latex math=\"\\begin{aligned}\r\n\tP(t)=P_\\infty+Z^{-1}(t),\\quad  t\\le 0\r\n\\end{aligned}\"/>\r\nwhere <Inline math=\"Z(t)\"/> is the solution of, \r\n<Latex math=\"\\begin{aligned}\r\n\\dot{Z}(t)=[A-GR^{-1}G^T P_\\infty]Z(t)+Z(t)[A-GR^{-1}G^T P_\\infty]^T-GR^{-1}G^T\r\n\\end{aligned}\"/>\r\nwhich is a <i>Differential Lyapunov Equation</i>. The solution for <Inline math=\"Z(t)\"/> is\r\n<Latex math=\"\\begin{aligned}\r\n\tZ(t)=\\bar{Z}+e^{-\\tilde{A}t}[Z(0)-\\bar{Z}]e^{-\\tilde{A}^T t}\r\n\\end{aligned}\"/>\r\nwhere\r\n<Latex math=\"\\begin{aligned}\r\n\t\\tilde{A}&=A-GR^{-1}G^T P_\\infty\\\\\r\n\t0&=\\tilde{A}\\bar{Z}+\\bar{Z}\\tilde{A}-GR^{-1}G^T\\\\\r\n\tZ(0)&=[P(0)-P_\\infty]^{-1}\r\n\\end{aligned}\"/>\r\nThus, we can write the close-form solution for the Differential Riccati Equation as\r\n<Latex math=\"\\begin{aligned}\r\n\tP(t)=P_\\infty+[\\bar{Z}+e^{-\\tilde{A}t}[Z(0)-\\bar{Z}]e^{-\\tilde{A}^T t}]^{-1},\\quad t\\le 0\r\n\\end{aligned}\"/>\r\n<p></p>\r\n<p></p>\r\n<h2>Analytical Solution of the Differential Lyapunov Equation</h2>\r\n\r\nConsider the differential Lyapunov equation of the form\r\n<Latex math=\"\\begin{aligned}\r\n\\dot{X}(t)=A^T X(t)+X(t)A+Q,\\quad X(0)=X_0\r\n\\end{aligned}\" label=\"lyapunov_diff\"/>\r\n<div class='lemma'><b>Lemma:</b><br/>\r\n\tThe analytical closed-form solution for <a href=\"#lyapunov_diff\">lyapunov_diff</a> is given by\r\n<Latex math=\"\\begin{aligned}\r\n\tX(t)=\\bar{X}+e^{At}(X(0)-\\bar{X})e^{A^T t}.\r\n\\end{aligned}\" label=\"sol_lyapunov_diff\"/>\r\n\twhere <Inline math=\"\\bar{X}\"/> is a solution of\r\n<Latex math=\"\\begin{aligned}\r\n\tA\\bar{X}+\\bar{X}A^T -Q=0.\r\n\\end{aligned}\" label=\"eq:algebraic_lyapunov_negative\"/>\r\n</div>\r\n<div class='proof'><b>Proof:</b><br/>\r\n\tFirst, one can prove that if <Inline math=\"A\"/> is Hurwitz then the algebraic equation <a href=\"#eq:algebraic_lyapunov_negative\">eq:algebraic_lyapunov_negative</a> has unique solution. Thus, we can rewrite <a href=\"#lyapunov_diff\">lyapunov_diff</a> as,\r\n<Latex math=\"\\begin{aligned}\r\n\t\\frac{d}{dt}({X(t)-\\bar{X}})=A(X(t)-\\bar{X})+(X(t)-\\bar{X})A^T\r\n\\end{aligned}\"/>\r\n\ttherefore, \r\n<Latex math=\"\\begin{aligned}\r\n\tX(t)=\\bar{X}+e^{At}(X(0)-\\bar{X})e^{A^T t}.\r\n\\end{aligned}\"/>\r\n<p align=\"right\"><Inline math=\"\\blacksquare\"/></p></div>\r\n<div class='remark'><b>Remark:</b><br/>\r\n\tThe solution of <a href=\"#eq:algebraic_lyapunov_negative\">eq:algebraic_lyapunov_negative</a> can be obtained employing the Kronecker Product\r\n<Latex math=\"\\begin{aligned}\r\n\tvec(\\bar{X})=\\left[A\\otimes A\\right]^{-1}vec(Q).\r\n\\end{aligned}\"/>\r\n</div>\r\n<h1 id=\"appendix\">Appendix</h1>\r\n \r\n<h2>Gramian</h2>\r\n\r\n<Latex math=\"\\begin{aligned}\r\n    \\dot{X}=AX+XA^T \r\n\\end{aligned}\"/>\r\nhas solution given by\r\n<Latex math=\"\\begin{aligned}\r\n    X(t)=e^{At}X(0)e^{A^T t}\r\n\\end{aligned}\"/>\r\n\r\n                    </div>\r\n                    <Disqus.DiscussionEmbed shortname={disqusShortname} config={disqusConfig} />\r\n                    </article>\r\n                    }\r\n                    export default RiccatiEq;","import React from 'react';\r\nimport Helmet from 'react-helmet';\r\nimport '../../Components/Pages/Tutorials.css';\r\nimport { BlockMath } from 'react-katex';\r\nimport Inline from '../../Components/Latex/Inline';\r\nimport '../../../node_modules/katex/dist/katex.css';\r\nimport Image from '../../Components/Image/Image';\r\nimport Disqus from 'disqus-react';\r\nconst ParticleFilter = (props) => {\r\nconst disqusShortname = 'marofe-github-io';\r\nconst disqusConfig = {\r\n        url: 'https://marofe.github.io/?p='+props.note.link,\r\n        identifier: 'note-'+props.note.link,\r\n        title: props.title\r\n    };\r\nreturn <article>\r\n      <Helmet>\r\n        <title>{props.note.title} | Marofe</title>\r\n        <meta name=\"description\" content={props.note.desc} />\r\n    </Helmet>\r\n    <h1>{props.title}</h1>\r\n<p>{props.desc}</p>\r\n    <p align=\"right\">Last Update:  1 March, 2020.</p>\r\n<div>\r\n\t<p>\r\nParticle Filter perform <i>Sequential Monte Carlo</i> (SMC) Estimation based on point mass \"particles\" representation of probabilities densities. The basic SMC ideas in the form of <i>Sequential Importance Sampling</i> (SIS) had been introduced in statistics back in the 1950s. Although, the major contribution to the development of SMC method was the inclusion of <i>resampling step</i>, which coupled with the rise of faster and cheap computers made the particle filters quite useful in practical problems.\r\n\t</p>\r\n\t<p>The following content is based on the book <a href=\"#ristic\">ristic2003beyond</a>.</p>\r\n<h2>Monte Carlo Integration</h2>\r\n\r\nSuppose we want to evaluate a multidimensional integral in the form\r\n<BlockMath math=\"\\begin{aligned}\r\n\tI=\\int g(x)dx,\r\n\\end{aligned}\"/>\r\nwhere <Inline math=\"g: \\mathbb{R}^n \\rightarrow \\mathbb{R}^m\"/> is some complicated function that it is not possible to integrate analytically. Now, if we can factorize <Inline math=\"g(x)=f(x)\\pi(x)\"/> in such a way that <Inline math=\"\\pi: \\mathbb{R}^n\\rightarrow \\mathbb{R}\"/> is interpreted as a probability density satisfying\r\n<BlockMath math=\"\\begin{aligned}\r\n\tI=\\int f(x)\\pi(x)dx,\\quad \\pi(x)\\ge 0,\\quad \\int \\pi(x)dx = 1\r\n\\end{aligned}\"/>\r\nand assuming that it is possible to draw <Inline math=\"N>>1\"/> samples <Inline math=\"\\{x^i\\}_{i=1}^N\"/> distributed according to <Inline math=\"\\pi(x)\"/>, thus,  the SMC provides an estimate of <Inline math=\"I\"/> given by\r\n<BlockMath math=\"\\begin{aligned}\r\n\t\\hat{I}_N = \\sum_{i=1}^{N}\\frac{1}{N}f(x^i).\r\n\\end{aligned}\"/>\r\nIn this case, if <Inline math=\"\\{x^i\\}\"/> are independent samples then we can show that <Inline math=\"\\hat{I}_N\"/> is an <i>unbiased</i> estimate of <Inline math=\"I\"/>\r\n<BlockMath math=\"\\begin{aligned}\r\n\t\\mathbb{E}\\{I\\}=\\mathbb{E}\\{\\hat{I}_N\\},\r\n\\end{aligned}\"/>\r\nand according to the <i>law of large numbers</i>, <Inline math=\"\\hat{I}_N\"/> will almost surely converge to <Inline math=\"I\"/> as <Inline math=\"N\\rightarrow \\infty\"/>. The error of this MC estimator is of order <Inline math=\"\\mathcal{O}(N^{-1/2})\"/>, meaning that the rate of convergence is independent of the dimension <Inline math=\"n\"/>. \r\nThis useful and important property of MC integration is due to the choice of samples <Inline math=\"x^i\"/> according to <Inline math=\"\\pi(x)\"/>, as they automatically come from regions of the state space that are important for the integration.\r\n<p/> \r\nIn the Bayesian Estimation context, density <Inline math=\"\\pi(x)\"/> is usually the <i>posterior</i> density. Unfortunately, in almost all cases, it is not possible to sample effectively from the posterior distribution. To overcome this problem, a possible solution is to apply the so-called <i>Importance Sampling Method</i>.\r\n<h3>Importante Sampling Method</h3>\r\n\r\nSuppose we can generate only samples from a specific density <Inline math=\"q(x)\"/>, which is similar to <Inline math=\"\\pi(x)\"/>. Then a correct weighting of the samples might still make the MC estimation effective. The pdf <Inline math=\"q(x)\"/> is referred to as the <i>importance</i> or <i>proposal</i> density. Its \"similarity\" with <Inline math=\"\\pi(x)\"/> can be expressed by the following condition\r\n<BlockMath math=\"\\begin{aligned}\r\n\\pi(x)>0 \\Rightarrow q(x)>0,\\quad \\forall x \\in \\mathbb{R}^n,\r\n\\end{aligned}\"/>\r\nwhich means that <Inline math=\"\\pi(x)\"/> and <Inline math=\"q(x)\"/> have the same support. If this condition is valid, then\r\n<BlockMath math=\"\\begin{aligned}\r\n\tI=\\int f(x)\\pi(x)dx = \\int f(x)\\frac{\\pi(x)}{q(x)}q(x)dx,\r\n\\end{aligned}\"/>\r\nprovided that <Inline math=\"\\frac{\\pi(x)}{q(x)}\"/> is <i>upper bounded</i>. A MC estimate of <Inline math=\"I\"/> is computed by generation <Inline math=\"N>>1\"/> independents samples <Inline math=\"\\{x^i\\}\"/> distributed according to <Inline math=\"q(x)\"/> and forming the weighted sum\r\n<BlockMath math=\"\\begin{aligned}\r\n\t\\hat{I}_N=\\frac{1}{N}\\sum_{i=1}^N f(x^i)\\tilde{w}(x^i),\r\n\\end{aligned}\"/>\r\nwhere \r\n<BlockMath math=\"\\begin{aligned}\r\n\t\\tilde{w}(x^i)=\\frac{\\pi(x^i)}{q(x^i)},\r\n\\end{aligned}\"/>\r\nare the importance weights. If the normalization factor for the desired <Inline math=\"\\pi(x)\"/> is unknown then we also need to perform normalization of the importance weights\r\n<BlockMath math=\"\\begin{aligned}\r\n\t\\hat{I}_N=\\frac{\\frac{1}{N}\\sum_{i=1}^N f(x^i)\\tilde{w}(x^i)}{\\frac{1}{N}\\sum_{i=1}^N \\tilde{w}(x^i)}=\\sum_{i=1}^N f(x^i)w(x^i),\r\n\\end{aligned}\"/>\r\nwhere\r\n<BlockMath math=\"\\begin{aligned}\r\n\tw(x^i)=\\frac{\\tilde{w}(x^i)}{\\sum_{j=1}^N\\tilde{w}(x^j)}.\r\n\\end{aligned}\"/>\r\n<h3>Sequential Importance Sampling (SIS)</h3>\r\n\r\nImportance Sampling is a general MC integration method. In another hand, the <i>Sequential Importance Sampling</i> algorithm is a MC method that forms the basis for most sequential MC filters developed over the past decades.\r\n<p/>\r\nThis sequential MC approach is known variously as <i>bootstrap filtering, the condensation algorithm, particle filters, interacting particles approximations and survival of the fittest</i>. It is a technique for implementing recursive Bayesian Filters by MC simulations. \r\n\r\nThe key idea is to represent the required posterior density function by a set of random samples with associated weights and compute estimates based on these samples and weights. As the number of samples becomes larger, the SIS filter approaches the optimal Bayesian Estimator.\r\n<p/>\r\nThe joint posterior density at time <Inline math=\"k\"/> can be approximated as follows\r\n<BlockMath math=\"\\begin{aligned}\r\np(X_k|Z_k)\\approx \\sum_{i=1}^N w_k^i\\delta(X_k-X_k^i),\r\n\\end{aligned}\"/>\r\nwhere <Inline math=\"X_k=\\{x_0,x_1,\\ldots,x_k\\}\"/> and <Inline math=\"Z_k=\\{z_0,z_1,\\ldots,z_k\\}\"/> are the state path and measurement history, respectively. If the samples <Inline math=\"X_k^i\"/> were drawn from an importance density <Inline math=\"q(X_k|Z_k)\"/> then\r\n<BlockMath math=\"\\begin{aligned}\r\n\tw_k^i \\propto \\frac{p(X_k^i|Z_k)}{q(X_k^i|Z_k)}.\r\n\\end{aligned}\"/>\r\nConsidering that the importance density is chosen to factorize such that\r\n<BlockMath math=\"\\begin{aligned}\r\n\tq(X_k|Z_k)=q(x_k|X_{k-1},z_k)q(X_{k-1}|Z_{k-1}),\r\n\\end{aligned}\"/>\r\nthen we can obtain samples <Inline math=\"X_k^i \\sim q(X_k|Z_k)\"/> by augmenting each of the existing samples <Inline math=\"X_{k-1}^i\\sim q(X_{k-1}|Z_{k-1})\"/> with the new state <Inline math=\"x_k^i \\sim q(x_k|X_{k-1},z_k)\"/>. \r\n<p/>\r\nTo derive the weight update equation, the pdf <Inline math=\"p(X_k|Z_k)\"/> is first factorized as\r\n<BlockMath math=\"\\begin{aligned}\r\n\tp(X_k|Z_k)&=p(X_k|z_k,Z_{k-1})\\\\\r\n\t&=\\frac{p(z_k|X_k,Z_{k-1})p(X_k|Z_{k-1})}{p(z_k|Z_{k-1})}\\\\\r\n\t&=\\frac{p(z_k|x_k,X_{k-1},Z_{k-1})p(x_k|X_{k-1},Z_{k-1})p(X_{k-1}|Z_{k-1})}{p(z_k|Z_{k-1})}\\\\\r\n\t&=\\frac{p(z_k|x_k,X_{k-1},Z_{k-1})p(x_k|x_{k-1},X_{k-2},Z_{k-1})p(X_{k-1}|Z_{k-1})}{p(z_k|Z_{k-1})}\\\\\r\n\t&=p(z_k|x_k)p(x_k|x_{k-1})\\frac{p(X_{k-1}|Z_{k-1})}{p(z_k|Z_{k-1})}.\r\n\\end{aligned}\"/>\r\nThus,\r\n<BlockMath math=\"\\begin{aligned}\r\n\tp(X_k|Z_k)\\propto p(z_k|x_k)p(x_k|x_{k-1})P(X_{k-1}|Z_{k-1}).\r\n\\end{aligned}\"/>\r\nSubstituting in <a href=\"#\">eq:update_weight</a>, we have\r\n<BlockMath math=\"\\begin{aligned}\r\n\tw_k^i \\propto \\frac{p(z_k|x_k^i)p(x_k^i|x_{k-1}^i)}{q(x_k^i|X_{k-1}^i,Z_k)}\\frac{p(X_{k-1}^i|Z_{k-1})}{q(X_{k-1}^i|Z_{k-1})},\r\n\\end{aligned}\"/>\r\ntherefore, we conclude that\r\n<BlockMath math=\"\\begin{aligned}\r\n\t\tw_k^i\\propto w_{k-1}^i\\frac{p(z_k|x_k^i)p(x_k^i|x_{k-1}^i)}{q(x_k^i|X_{k-1}^i,Z_k)}.\r\n\\end{aligned}\"/>\r\n\r\nNow, if <Inline math=\"q(x_k|X_{k-1},Z_{k})=q(x_k|x_{k-1},z_k)\"/> then\r\n<BlockMath math=\"\\begin{aligned}\r\nw_k^i\\propto w_{k-1}^i\\frac{p(z_k|x_k^i)p(x_k^i|x_{k-1}^i)}{q(x_k^i|x_{k-1}^i,z_k)}.\r\n\\end{aligned}\"/>\r\nIn this case, the posterior filtered density <Inline math=\"p(x_k|Z_k)\"/> can be approximated as\r\n<BlockMath math=\"\\begin{aligned}\r\np(x_k|Z_k)\\approx \\sum_{i=1}^n w_k^i\\delta(x_k-x_k^i).\r\n\\end{aligned}\"/>\r\nThe Figure <a href=\"#\">fig:pdf</a> illustrate this approximation for a simple problem.\r\n<Image src=\"/images/pdf.svg\" width=\"50%\"/>\r\n\r\nFiltering via SIS thus consists of recursive propagation of importance weights <Inline math=\"w_k^i\"/> and support points <Inline math=\"x_k^i\"/> as each measurement is received sequentially. This simple and general algorithm forms the basis of most particle filters. However, the choice of the importance density <Inline math=\"q(x)\"/> plays a crucial role in the design of this type of filter.\r\n\r\n<h3>The Optimal Importance Density</h3>\r\n\r\nThe choice of importance density <Inline math=\"q(x_k|x_{k-1},z_k)\"/> is one of the most critical issues in the design of a particle filter. The optimal importance density function that minimizes the variance of importance weights, conditioned upon <Inline math=\"x_{k-1}\"/> and <Inline math=\"z_k\"/> has been shown to be\r\n<BlockMath math=\"\\begin{aligned}\r\n\tq(x_k|x_{k-1},z_k)=p(x_k|x_{k-1},z_k).\r\n\\end{aligned}\"/>\r\nSubstitution of <a href=\"#\">eq:opt_q</a> into <a href=\"#\">eq:update2_weight</a> yields\r\n<BlockMath math=\"\\begin{aligned}\r\nw_k^i&\\propto w_{k-1}^i\\frac{p(z_k|x_k)p(x_k|x_{k-1}^i)}{p(x_k|x_{k-1}^i,z_k)}\\\\\r\n&\\propto w_{k-1}^i\\frac{p(z_k|x_k)p(x_k|x_{k-1}^i)p(z_k|x_{k-1}^i)}{p(z_k|x_k,x_{k-1}^i)p(x_k|x_{k-1}^i)}\\\\\r\n\t&\\propto w_{k-1}^ip(z_k|x_{k-1}^i),\r\n\\end{aligned}\"/>\r\nwhich states that importance weights at time <Inline math=\"k\"/> can be computed (and resampling) before the particles even be propagated to time <Inline math=\"k\"/>. In order to use the optimal importance function, one has to be able to (i) sample from <Inline math=\"p(x_k|x_{k-1}^i,z_k)\"/> and (ii) evaluate\r\n<BlockMath math=\"\\begin{aligned}\r\n\tp(z_k|x_{k-1}^i)&=\\int p(z_k,x_k|x_{k-1}^i)dx_k\\\\\r\n\t&=\\int p(z_k|x_k)p(x_k|x_{k-1}^i)dx_k\r\n\\end{aligned}\"/>\r\nup to a normalizing constant. In the general case either these two may not be straightforward. However, there are some special cases where the use of optimal importance density is possible. \r\n<p/>\r\nThe first case is when <Inline math=\"x_k\"/> is a member of a finite set (e.g. jump-Markov linear systems). The second case is a class of models for which <Inline math=\"p(x_k|x_{k-1}^i,z_k)\"/> is Gaussian.\r\n<h3>Gaussian Optimal Importance Density</h3>\r\nConsider the case where the state dynamics is nonlinear but the measurement equation is linear and all the random elements in the model are additive Gaussian\r\n<BlockMath math=\"\\begin{aligned}\r\nx_k&=f_{k-1}(x_{k-1})+\\nu_{k-1}\\\\\r\nz_k&=H_kx_k+\\varepsilon_k\\\\\r\n\\nu_k\\sim &\\mathcal{N}(0,Q_k),\\quad \\varepsilon_k \\sim \\mathcal{N}(0,R_k)\r\n\\end{aligned}\"/>\r\nFrom the Bayes formula it follows that\r\n<BlockMath math=\"\\begin{aligned}\r\n\tp(x_k|x_{k-1},z_k)\\propto p(z_k|x_k)p(x_k|x_{k-1})\r\n\\end{aligned}\"/>\r\nas the measurement is linear and the random elements are Gaussian, <Inline math=\"p(x_k|x_{k-1},z_k)\"/> will be the product of Gaussian distributions and therefore will result in another Gaussian. Besides, we can write\r\n<BlockMath math=\"\\begin{aligned}\r\np(x_k|x_{k-1},z_k)p(z_k|x_{k-1})= p(z_k|x_k)p(x_k|x_{k-1})\r\n\\end{aligned}\"/>\r\nTaking the logarithm both sides yield\r\n<BlockMath math=\"\\begin{aligned}\r\n\tp(x_k|x_{k-1},z_k)&\\sim \\mathcal{N}(a_k,\\Sigma_k),\\\\\r\n\tp(z_k|x_{k-1})&\\sim \\mathcal{N}(b_k,S_k),\r\n\\end{aligned}\"/>\r\nwith\r\n<BlockMath math=\"\\begin{aligned}\r\n\ta_k&=f_{k-1}(x_{k-1})+\\Sigma_kH_k^\\intercal R_k^{-1}(z_k-b_k),\\\\\r\n\t\\Sigma_k &= Q_{k-1}-Q_{k-1}H_k^\\intercal S_k^{-1}H_kQ_{k-1},\\\\\r\n\tS_k &= H_kQ_{k-1}H_k^\\intercal + R_k,\\\\\r\n\tb_k&=H_kf_{k-1}(x_{k-1}).\r\n\\end{aligned}\"/>\r\n<h3>Degeneracy Problem and Resampling</h3>\r\n\r\nIdeally, the importance density function should be the posterior density itself <Inline math=\"p(x_k|Z_k)\"/>. However, as this cannot be achieved, the variance of the importance weights might increase over time. This leads to the <i>degeneracy phenomenon</i>. \r\n<p/>\r\nIn practical terms, this means that after a certain number of steps, all but one particle will have negligible normalized weight. The degeneracy is impossible to avoid in the SIS framework and, hence, it was a major stumbling block in the development of sequential MC methods. Because a large computational effort is devoted to updating particles whose contribution to the approximation of <Inline math=\"p(x_k|Z_k)\"/> is almost zero. \r\n\r\n<p/>\r\nOne measure of degeneracy of a SIS algorithm follows\r\n<BlockMath math=\"\\begin{aligned}\r\n\tN_{eff}=\\frac{1}{\\sum_{i=1}^N(w_k^i)^2}.\r\n\\end{aligned}\"/>\r\n\r\nIt is straightforward to verify that <Inline math=\"1\\le N_{eff}\\le N\"/> with the following extreme cases: (i) if the weights are uniform (i.e. <Inline math=\"w_k^i=\\frac{1}{N}\"/>) then <Inline math=\"N_{eff}=N\"/>; and (ii) if <Inline math=\"\\exists j\\in \\{1,\\ldots,N\\}\"/> such that <Inline math=\"w_k^j=1\"/> and <Inline math=\"w_k^i=0\"/> for all <Inline math=\"i\\neq j\"/>, then <Inline math=\"N_{eff}=1\"/>. Therefore, small <Inline math=\"N_{eff}\"/> indicates a severe degeneracy and vice versa.\r\n<p/>\r\nTo cope with this problem, we need to perform a resampling step whenever a significant degeneracy is observed (i.e. when <Inline math=\"N_{eff}\"/> fall below some threshold <Inline math=\"N_{thr}\"/>). Resampling eliminates samples with low importance and multiplies ones with high importance. \r\n<p/>\r\nIt involves a mapping of random measures <Inline math=\"\\{x_k^i,w_k^i\\}_{i=1}^N\"/> into new ones <Inline math=\"\\{\\tilde{x}_k^i,\\frac{1}{N}\\}_{i=1}^N\"/> with uniform weights.\r\nThe new set of samples <Inline math=\"\\{\\tilde{x}_k^i\\}_{i=1}^N\"/> is generated by resampling (with replacement) <Inline math=\"N\"/> times from the approximate discrete representation of <Inline math=\"p(x_k|Z_k)\"/>, so that <Inline math=\"P\\{\\tilde{x}_k^i=x_k^j\\}=w_k^j\"/>. The resulting samples compose an i.i.d set and hence the new weights are uniform.\r\n<p/>\r\nOne way to implement the resampling step is by the <i>Cumulative Sum of Weight Algorithm</i> (CSW). This implementation consist of generating <Inline math=\"N\"/> i.i.d variables from the uniform distribution <Inline math=\"\\mathcal{U}[0,1]\"/>, sorting them in ascending order and comparing them with the cumulative sum of normalized weights. The Figure <a href=\"#\">fig:csw</a> illustrate this procedure.\r\n<Image src=\"/images/csw.svg\" width=\"50%\"/>\r\n<h2>The Bootstrap Filter (SIR)</h2>\r\n\r\nProposed in <a href=\"#gordon\">gordon1993novel</a>. The <i>Sequential Importance Resampling</i> (SIR) filter is derived from the SIS algorithm by choosing the importance density to be the <i>transitional prior</i> and performing resampling every time step.\r\n<BlockMath math=\"\\begin{aligned}\r\n\tq(x_k|x_{k-1},z_k)=p(x_k|x_{k-1}).\r\n\\end{aligned}\"/>\r\n\r\nA sample <Inline math=\"x_k^i\\sim p(x_k|x_{k-1}^i)\"/> can be generated first generating a process noise sample <Inline math=\"\\nu_{k-1}^i\\sim p(\\nu_k)\"/> and setting <Inline math=\"x_k^i=f(x_{k-1}^i,\\nu_{k-1}^i)\"/>. For this particular choice of importance density, the weight update is\r\n<BlockMath math=\"\t\\begin{aligned}\r\n\t\tw_k^i\\propto w_{k-1}^ip(z_k|x_k).\r\n\\end{aligned}\"/>\r\n\tHowever, as the resampling step is performed every iteration, we have <Inline math=\"w_{k-1}^i=\\frac{1}{N}\"/> for all <Inline math=\"i=1,\\ldots,N\"/>. Thus, the weight update simplifies to\r\n<BlockMath math=\"\t\\begin{aligned}\r\n\t\tw_k^i \\propto p(z_k|x_k).\r\n\\end{aligned}\"/>\r\n \r\n<h3>Cons</h3>\r\n\r\nAs the importance sampling is independent of measurement <Inline math=\"z_k\"/>, the state space is explored without any knowledge of the observations. Therefore, this filter is sensitive to outliers. Furthermore, as resampling is applied every iteration, this can result in rapid <i>loss of diversity</i> in particles.\r\n<h3>Pros</h3>\r\n\r\nThe SIR method has the advantage that the importance weights are easily evaluated and the importance density can be easily sampled.\r\n<h2>Local Linearization Particle Filters (LLPF)</h2>\r\n\r\nThe optimal importance density can be approximated by incorporating the most current measurement <Inline math=\"z_k\"/> via a bank of extended or unscented Kalman Filters. The idea is to use for each particle a separate EKF or UKF to generate and propagate a Gaussian importance distribution; that is,\r\n<BlockMath math=\"\\begin{aligned}\r\n\tq(x_k^i|x_{k-1}^i,z_k)=\\mathcal{N}(\\hat{x}_k^i,\\hat{P}_k^i),\r\n\\end{aligned}\"/>\r\nwhere <Inline math=\"\\hat{x}_k^i\"/> and <Inline math=\"\\hat{P}_k^i\"/> are estimates of the mean and covariance computed by EKF or UKF at time <Inline math=\"k\"/> using measurement <Inline math=\"z_k\"/>. We refer to the corresponding particle filter as the <i>Local Linearization Particle Filter</i> (LLPF). \r\n<p/>\r\nThe local linearization method for approximation of the importance density propagates the particles towards the likelihood function and consequently, the LLPF performs better than SIR filter. The additional computational cost of using such an importance density is often more than offset by a reduction in the number of samples required to achieve a certain level of performance.\r\n\r\n<div className=\"remark\">\r\n\t<b>Remark: </b>\t\r\nSince Particle Filters are very expensive in terms of computational requirements, one should use them only in cases in which the conventional Kalman Filter does not produce satisfactory results.\r\n</div>\r\n<h3>References:</h3>\r\n<p><a name=\"gordon\"></a>GORDON, N. J.; SALMOND, D. J.; SMITH, A. F. Novel approach to nonlinear/nongaussian\r\nbayesian state estimation. In: IET. IEE proceedings F (radar and signal\r\nprocessing). [S.l.], 1993. v. 140, n. 2, p. 107–113</p>\r\n<p><a name=\"ristic\"></a>RISTIC, B.; ARULAMPALAM, S.; GORDON, N. Beyond the Kalman Filter: Particle\r\nFilters for Tracking Applications. [S.l.]: Artech House, 2003. ISBN 9781580538510.</p>\r\n</div>\r\n<Disqus.DiscussionEmbed shortname={disqusShortname} config={disqusConfig} />\r\n\r\n</article>\r\n}\r\nexport default ParticleFilter;","import React from 'react';\r\nimport Helmet from 'react-helmet';\r\nimport '../../../Components/Pages/Tutorials.css';\r\nimport { BlockMath } from 'react-katex';\r\nimport Inline from '../../../Components/Latex/Inline';\r\nimport Latex from '../../../Components/Latex/latex';\r\nimport '../../../../node_modules/katex/dist/katex.css';\r\nimport Image from '../../../Components/Image/Image';\r\nimport Disqus from 'disqus-react';\r\nconst Lasso = (props) => {\r\nconst disqusShortname = 'marofe-github-io';\r\nconst disqusConfig = {\r\n        url: 'https://marofe.github.io/?p='+props.note.link,\r\n        identifier: 'note-'+props.note.link,\r\n        title: props.title\r\n    };\r\nreturn <article>\r\n      <Helmet>\r\n        <title>{props.note.title} | Marofe</title>\r\n        <meta name=\"description\" content={props.note.desc} />\r\n    </Helmet>\r\n    <h1>{props.title}</h1>\r\n<p>{props.desc}</p>\r\n    <p align=\"right\">Last Update:  September 19, 2021.</p>\r\n<div>\r\n<h2>Introduction</h2>\r\n\r\nConsider available a collection of <Inline math=\"N\"/> predictor-response samples <Inline math=\"\\{(x_i,y_i)\\}_{i=1}^N\"/> where each <Inline math=\"x_i=(x_{i1},x_{1,i2},\\ldots,x_{ip})\"/> is a p-dimensional vector of features or predictors, and <Inline math=\"y_i \\in \\mathbb{R}\"/> is the associated response variable. In the linear regression setting, the goal is to approximate the response variable using a linear combination of the predictors\r\n<Latex math=\"\\begin{aligned}\r\n\ty_i=\\beta_0+\\sum_{j=1}^p x_{ij}\\beta_j ,\\quad i=1,\\ldots,N\r\n\\end{aligned}\"/>\r\nwhere the main problem is to estimate the model parameters <Inline math=\"\\beta=(\\beta_0,\\beta_1,\\ldots,\\beta_p)\"/>. \r\nThe usual \"least-square\" estimator is based on minimizing squared-error loss\r\n<Latex math=\"\\begin{aligned}\r\n\t\\min_{\\beta} \\frac{1}{2N}\\|y-X\\beta\\|_2^2\r\n\\end{aligned}\"/>\r\nwhere <Inline math=\"y=(y_1,y_2,\\ldots,y_N)\"/> and\r\n<Latex math=\"\\begin{aligned}\r\n\tX=\\left[\r\n\t\\begin{matrix}\r\n\t1 & x_{11} & x_{12} & \\cdots & x_{1p}\\\\\r\n\t1 & x_{21} & x_{22} & \\cdots & x_{2p}\\\\\r\n\t\\vdots & \\vdots & \\vdots & \\ddots & \\vdots\\\\\r\n\t1 & x_{N1} & x_{N2} & \\cdots & x_{Np}\\\\\r\n\t\\end{matrix}\r\n\t\\right]\r\n\\end{aligned}\"/>\r\nTypically, first a standardization of the predictors are made so that each column is centered (<Inline math=\"\\frac{1}{N}\\sum_i x_{ij}=0\"/>) and has unit variance (<Inline math=\"\\frac{1}{N}\\sum_ix_{ij}^2=1\"/>). Without standardization the solutions would depend on the units. A simple way to standardize is computing the mean <Inline math=\"\\mu_x = \\sum_i x_{ij}\"/> and variance <Inline math=\"\\sigma_x^2=\\frac{1}{N-1}\\sum_i (x_{ij}-\\mu)^2\"/> and replace each predictor by\r\n<Latex math=\"\\begin{aligned}\r\n\\tilde{x}_{ij}=\\frac{x_{ij}-\\mu_x}{\\sigma_x}\r\n\\end{aligned}\"/>\r\nWith the standardization the bias coefficient <Inline math=\"\\beta_0\"/> can be omitted.\r\nIt is usually convenient also to work with the outcome values <Inline math=\"y_i\"/> centered (<Inline math=\"\\frac{1}{N}\\sum_i y_i=0\"/>).\r\n<p></p>\r\nHowever, there are, at least, two reasons why we might consider alternatives to the usual \"least-square\". The first reason is <i>accuracy</i>. It is well-known that the LS estimator often has low bias but large variance. This can be improved by shrinking the values of the model parameters. Although, by doing so we introduce more bias but reduce the variance of the predicted values, and hence may improve the overall prediction accuracy assessed by the Mean Square Error (MSE).\r\n<p></p>\r\nThe second reason is <i>interpretation</i>. It is much harder to interpret too many features, consequently, we often would like to identify a smaller subset of features that exhibit the strongest effects. \r\n<p></p>\r\nThe lasso provides an automatic way to simultaneously shrinking the coefficients and reduce the model complexity. In order to do so, a <Inline math=\"l_1\"/>-constraint is added to the usual least-square problem\r\n<Latex math=\"\\begin{aligned}\r\n\\min_{\\beta} &\\frac{1}{2N}\\|y-X\\beta\\|_2^2\\\\\r\n\\text{s.t. } &\\|\\beta\\|_1 \\le t\r\n\\end{aligned}\" label=\"problem1\"/>\r\nThe bound <Inline math=\"t\"/> in the lasso criterion controls the complexity of the model. A value <Inline math=\"t\"/> too small can prevent the lasso from capturing the main signal in the data, while too large a value can lead to overfitting.\r\n<p></p>\r\nThe problem <a href=\"#problem1\">problem1</a> can be rewritten in an equivalent form so-called <i>Lagrangian form</i>\r\n<Latex math=\"\\begin{aligned}\r\n\\min_{\\beta} \\frac{1}{2N}\\|y-X\\beta\\|_2^2+\\lambda \\|\\beta\\|_1 \r\n\\end{aligned}\" label=\"problem2\"/>\r\nIt is possible to demonstrate that there exist one-to-one correspondence between <a href=\"#problem1\">problem1</a> and <a href=\"#problem2\">problem2</a>: for each <Inline math=\"t\"/> chosen as bound <Inline math=\"\\|\\beta\\|_1\\le t\"/> in <a href=\"#problem1\">problem1</a> there exist a corresponding value <Inline math=\"\\lambda\"/> for <a href=\"#problem2\">problem2</a> that yields the same solution. Conversely, for an fixed <Inline math=\"\\lambda\"/>, the solution <Inline math=\"\\hat{\\beta}_\\lambda\"/> of the Lagrangian form solves the problem <a href=\"#problem1\">problem1</a> with <Inline math=\"t=\\|\\hat{\\beta}_\\lambda\\|_1\"/>. \r\n<div class='remark'><b>Remark:</b><br/>\r\n\tNote that in many descriptions of the lasso, the term <Inline math=\"1/2N\"/> is often replaced by <Inline math=\"1/2\"/> or <Inline math=\"1\"/>. This makes no difference for <a href=\"#problem1\">problem1</a> or just mean a different value of <Inline math=\"\\lambda\"/> at <a href=\"#problem2\">problem2</a>; However, this kind of standardization makes <Inline math=\"\\lambda\"/> values comparable for different sample sizes (useful for cross-validation).\r\n</div>\r\n<h2>Lasso Solution</h2>\r\n\r\nThe theory of convex analysis tell us that the sufficient and necessary conditions for a solution to problem <a href=\"#problem2\">problem2</a> take the form\r\n<Latex math=\"\\begin{aligned}\r\n\t-\\frac{1}{N}X^T(y-X\\beta)+\\lambda s=0\r\n\\end{aligned}\" label=\"subgradient_eq\"/>\r\nwhere <Inline math=\"s=(s_1,s_2,\\ldots,s_p)\"/> represents the subgradient for the absolute function (<Inline math=\"s_i=sign(\\beta_i)\"/> if <Inline math=\"\\beta_i\\neq 0\"/> or <Inline math=\"s_i \\in [-1,1]\"/> otherwise). In other words, the solutions <Inline math=\"\\hat{\\beta}\"/> to problem <a href=\"#problem2\">problem2</a> are the same as <Inline math=\"(\\hat{\\beta},\\hat{s})\"/> to <a href=\"#subgradient_eq\">subgradient_eq</a>. Expressing a problem in subgradient form can be useful for designing algorithms for finding its solutions.\r\n<p></p>\r\nHowever, the Lagrangian Form is specially convenient for numerical computation by a simple procedure known as <i>coordinate descent</i>.\r\n<h3>Scalar case: single predictor</h3>\r\n\r\nConsider the following lasso problem\r\n<Latex math=\"\\begin{aligned}\r\n\\min_{\\beta} \\frac{1}{2N}\\sum_{i=1}^N(y_i-x_i\\beta)^2+\\lambda |\\beta| \r\n\\end{aligned}\" label=\"problem_scalar\"/>\r\nwhere <Inline math=\"\\beta \\in \\mathbb{R}\"/> . The optimal solutions is given by\r\n<Latex math=\"\\begin{aligned}\r\n\\beta^* = \\left\\{\r\n\\begin{matrix}\r\n(x^T x)^{-1}(x^T y-\\lambda N), & \\text{ if } \\frac{1}{N}x^T y > \\lambda \\\\\r\n0, & \\text{ if } |\\frac{1}{N}x^T y| \\le \\lambda \\\\\r\n(x^T x)^{-1}(x^T y+\\lambda N), & \\text{ if } \\frac{1}{N}x^T y < -\\lambda \\\\\r\n\\end{matrix}\r\n\\right.\r\n\\end{aligned}\"/>\r\nwith <Inline math=\"x=(x_1,x_2,\\ldots,x_N)\"/>. \r\n<div class='proof'><b>Proof:</b><br/>\r\n\tFrom <a href=\"#problem_scalar\">problem_scalar</a>, one have\r\n<Latex math=\"\\begin{aligned}\r\n\tJ&= \\frac{1}{2N}\\sum_i (y_i^2-2y_ix_i\\beta+\\beta^2x_i^2)+\\lambda|\\beta|\\\\\r\n\t&=\\frac{1}{2N}y^T y - \\frac{1}{N}x^T y \\beta + \\frac{1}{2N}x^T x\\beta^2 +\\lambda|\\beta|\r\n\\end{aligned}\"/>\r\n\tBy taking the sub-gradient\r\n<Latex math=\"\\begin{aligned}\r\n\t\\partial J =  - \\frac{1}{N}x^T y + \\frac{1}{N}x^T x\\beta +\\lambda\\mathcal{D}(\\beta).\r\n\\end{aligned}\"/>\r\nIf <Inline math=\"\\beta^* >0\"/> then <Inline math=\"\\beta^*=(x^T x)^{-1}(x^T y-\\lambda N)\"/>. On the other hand, if <Inline math=\"\\beta^*<0\"/> then <Inline math=\"\\beta^*=(x^T x)^{-1}(x^T y+\\lambda N)\"/>. Note that <Inline math=\"\\beta^*=0\"/> implies <Inline math=\"\\frac{1}{N}x^T y +\\lambda\\mathcal{D}(0)=0\"/>, thus because <Inline math=\"\\mathcal{D}(0)=[-1,1]\"/>, one conclude that\r\n <Inline math=\"\\beta^*=0\\Leftrightarrow|\\frac{1}{N}x^T y|\\le \\lambda  \"/>.  \r\n<p align=\"right\"><Inline math=\"\\blacksquare\"/></p></div>\r\n<p></p>\r\nFor the case when the estimator is standardized (<Inline math=\"\\frac{1}{N}\\sum_i x_i = 0\"/> and <Inline math=\"\\frac{1}{N}\\sum_i x_i^2=1\"/>), the optimal solution simplifies to\r\n<Latex math=\"\\begin{aligned}\r\n\\beta^* = \\left\\{\r\n\\begin{matrix}\r\n\\frac{1}{N}x^T y-\\lambda, & \\text{ if } \\frac{1}{N}x^T y > \\lambda \\\\\r\n0, & \\text{ if } |\\frac{1}{N}x^T y| \\le \\lambda \\\\\r\n\\frac{1}{N}x^T y+\\lambda, & \\text{ if } \\frac{1}{N}x^T y < -\\lambda \\\\\r\n\\end{matrix}\r\n\\right.\r\n\\end{aligned}\"/>\r\n<p></p>\r\nThe solution also can be rewritten in short-form as \r\n<Latex math=\"\\begin{aligned}\r\n\\beta^* = \\mathcal{S}_\\lambda \\left(\\frac{1}{N}x^T y\\right)\r\n\\end{aligned}\"/>\r\nwhere <Inline math=\"\\mathcal{S}_\\lambda\"/> is the <i>soft-threshoulding operator</i> \r\n<Inline math=\"\\mathcal{S}_\\lambda(x)=sign(x)(|x|-\\lambda)_+\"/> that translate the argument <Inline math=\"x\"/> toward zeros by the amount <Inline math=\"\\lambda\"/> and sets it to zero if <Inline math=\"|x|\\le \\lambda\"/> and <Inline math=\"(t)_+=\\max(0,t)\"/> denotes the positive part of <Inline math=\"t\"/> (equal to <Inline math=\"t\"/> if <Inline math=\"t>0\"/> or zero otherwise). \r\n<p></p>\r\nFor the case when the estimator is not standardized, the short-form becomes\r\n<Latex math=\"\\begin{aligned}\r\n\\beta^* = (x^T x)^{-1}\\mathcal{S}_{\\lambda N} \\left(x^T y\\right).\r\n\\end{aligned}\"/>\r\n<h3>Multivariate case: multiple predictors</h3>\r\n\r\nTo solve the full lasso problem, we can develop a simple coordinate-wise scheme where we repeatedly cycle through the predictor in some fixed (but arbitrary) order where at the <Inline math=\"j^{th}\"/> step, we update the coefficient <Inline math=\"\\beta_j\"/> while holding fixed all other coefficients (<Inline math=\"\\beta_k,k\\neq j\"/>).\r\n<p></p>\r\nWriting the objective function as\r\n<Latex math=\"\\begin{aligned}\r\n\t\\frac{1}{2N}\\sum_{i=1}^N\\left(y_i-\\sum_{k\\neq j} x_{ik}\\beta_k-x_{ij}\\beta_j\\right)^2+\\lambda \\sum_{k\\neq j} |\\beta_k| + \\lambda |\\beta_j|\r\n\\end{aligned}\"/>\r\nwe see that the solution for each <Inline math=\"\\beta_j\"/> can be expressed succinctly in terms of the <i>partial residual</i>\r\n<Latex math=\"\\begin{aligned}\r\n\tr_i^{(j)}=y_i-\\sum_{k\\neq j} x_{ik}\\hat{\\beta}_k.\r\n\\end{aligned}\"/>\r\nThe objective function, thus, can be rewritten as\r\n<Latex math=\"\\begin{aligned}\r\n   J= \\frac{1}{2N}\\sum_{i=1}^N\\left(r_i^{(j)}-x_{ij}\\beta_j\\right)^2+\\lambda \\sum_{k\\neq j} |\\beta_k| + \\lambda |\\beta_j|\\\\=\\frac{1}{2N}\\sum_{i=1}^N\\left((r_i^{(j)})^2-2r_i^{(j)}x_{ij}\\beta_j+x_{ij}^2\\beta_j^2\\right)+\\lambda \\sum_{k\\neq j} |\\beta_k| + \\lambda |\\beta_j|\\\\\r\n   =\\frac{1}{2N}\\left((r^{(j)})^T r^{(j)}- 2x_j^T r^{(j)}\\beta_j+x_j^T x_j\\beta_j^2\\right)+\\lambda \\sum_{k\\neq j} |\\beta_k| + \\lambda |\\beta_j|\r\n\\end{aligned}\"/>\r\nwhere <Inline math=\"x_j=(x_{1j},x_{2j},\\ldots,x_{Nj})\"/> and <Inline math=\"r^{(j)}=(r_1^{(j)},r_2^{(j)},\\ldots,r_N^{(j)})\"/>.\r\nThe sub-gradient w.r.t. the <Inline math=\"j\"/>-th component is\r\n<Latex math=\"\\begin{aligned}\r\n    \\partial_{\\beta_j}J =-\\frac{1}{N}x_j^T r^{(j)}+\\frac{1}{N}x_j^T x_j\\beta_j+\\lambda \\mathcal{D}(\\beta_j)\r\n\\end{aligned}\"/>\r\nTherefore, in terms of partial residual, the <Inline math=\"j^{th}\"/> coefficient is updated as\r\n<Latex math=\"\\begin{aligned}\r\n\t\\hat{\\beta}_j=(x_j^T x_j)^{-1}\\mathcal{S}_{\\lambda N}\\left(x_j^T r^{(j)}\\right).\r\n\\end{aligned}\"/>\r\nOr equivalently, in terms of the <i>full residual</i> <Inline math=\"r=y-X\\hat{\\beta}=r^{(j)}-x_{j}\\hat{\\beta}_j\"/>, one has\r\n<Latex math=\"\\begin{aligned}\r\n\\hat{\\beta}_j=(x_j^T x_j)^{-1}\\mathcal{S}_{\\lambda N}\\left(x_j^T(r+x_{j}\\hat{\\beta}_j)\\right)=(x_j^T x_j)^{-1}\\mathcal{S}_{\\lambda N}\\left(x_j^T x_j\\hat{\\beta}_j+x_j^T r\\right).\r\n\\end{aligned}\"/>\r\n<p></p>\r\nThe algorithm just described corresponds to the method of <i>cyclical coordinate descent</i>, which minimizes this convex objective along each coordinate at a time. \r\n<p></p>\r\nIt is important to note that some conditions are required because there are instances, involving non-separable penalty functions, in which coordinate descent schemes can become \"jammed\".\r\nBesides, in practice, one is often interested in finding the lasso solution not just for a single fixed value of <Inline math=\"\\lambda\"/>, but rather the entire path of solutions over a range of possible <Inline math=\"\\lambda\"/> values.\r\n<p></p>\r\nA reasonable method for doing so is to begin with a value of <Inline math=\"\\lambda\"/> just large enough so that the only optimal solution is the all-zeros vector. This value is equal to <Inline math=\"\\lambda_{max} = \\max_j |\\frac{1}{N}x_j^T y|\"/>. Then we decrease <Inline math=\"\\lambda\"/> by a small amount and run coordinate descent until convergence. Decreasing <Inline math=\"\\lambda\"/> again and using the previous solution as a \"warm start\", we then run coordinate descent until convergence. In this way we can efficiently compute the solutions over a grid of <Inline math=\"\\lambda\"/> values. We refer to this method as <i>pathwise coordinate descent</i>.\r\n<div class='remark'><b>Remark:</b><br/>\r\n\tCoordinate descent is especially fast for the lasso because the coordinatewise minimizers are explicitly available. Secondly, it exploits the sparsity of the problem for large enough values of <Inline math=\"\\lambda\"/> most coefficients will be zero and will not be moved from zero. Another more efficient method is the <i>Least Angle Regression</i> (LARS) algorithm which is a homotopy method that constructs the piecewise linear path.\r\n</div>\r\n<h3>Special Case: orthogonal predictors</h3>\r\n\r\nThe coordinate minimization scheme takes an especially simple form if the predictors are orthogonal, meaning that\r\n<Latex math=\"\\begin{aligned}\r\n\t\\frac{1}{N}x_j^T x_k = 0,\\quad \\text{for each } j\\neq k.\r\n\\end{aligned}\"/>\r\nIn this case, the update rule simplifies\r\n<Latex math=\"\\begin{aligned}\r\n\t\\frac{1}{N}x_j^T r^{(j)} = \\frac{1}{N}x_j^T y\r\n\\end{aligned}\"/>\r\nThus, in the special case of an orthogonal design, the lasso has an explicit closed-form solution, and no iterations are required.\r\n<p></p>\r\nInteresting connection is the <i>wavelet filtering</i>. Since wavelet bases are orthogonal, wavelet filtering correspond to this special case of lasso.\r\n<h2>Lasso vs Minimax</h2>\r\n\r\nConsider the robust regression problem\r\n<Latex math=\"\\begin{aligned}\r\n\t\\min_{\\beta} \\max_{\\delta X \\in \\mathcal{U}} \\|y-(X+\\delta X)\\beta\\|_2\r\n\\end{aligned}\" label=\"robust_minimax\"/>\r\nwhere the uncertainty set <Inline math=\"\\mathcal{U}\"/> are defined by\r\n<Latex math=\"\\begin{aligned}\r\n\t\\mathcal{U}=\\{(\\delta_1,\\delta_2,\\ldots,\\delta_m)| \\|\\delta_i\\|_2\\le c_i, i=1,2,\\ldots,m,\\delta_i \\in \\mathbb{R}^n\\}\r\n\\end{aligned}\"/>\r\n<div class='theorem'><b>Theorem:</b><br/>\r\n\tThe solution for <a href=\"#robust_minimax\">robust_minimax</a> is equivalent to\r\n<Latex math=\"\\begin{aligned}\r\n\t\t\\min_{\\beta} \\|y-X\\beta\\|_2+\\sum_{i=1}^m c_i|\\beta_i|\r\n\\end{aligned}\"/>\r\n</div>\r\n<div class='proof'><b>Proof:</b><br/>\r\n\tAssume that <Inline math=\"\\beta\"/> is given. Notice that\r\n<Latex math=\"\\begin{aligned}\r\n\t\t\\|y-(X+\\delta X)\\beta\\|_2&=\\|y-(X+(\\delta_1,\\delta_2,\\ldots,\\delta_m))\\beta\\|_2\\\\\r\n\t\t&=\\|y-X\\beta-\\sum_{i=1}^m \\delta_i \\beta_i\\|_2\\\\\r\n\t\t&\\le \\|y-X\\beta\\|_2-\\|\\sum_{i=1}^m \\delta_i \\beta_i\\|_2\\\\\r\n\t\t&\\le\\|y-X\\beta\\|_2-\\sum_{i=1}^m c_i |\\beta_i|\\\\\r\n\\end{aligned}\"/>\r\n<p></p>\r\n\tNote that the maximum <Inline math=\"\\delta X^*=(\\delta_1^*,\\delta_2^*,\\ldots,\\delta_m^*)=(c_1,c_2,\\ldots,c_m)\"/>.\r\n\tNow, consider a particular structure to the uncertainty <Inline math=\"\\delta_i\"/> given by\r\n<Latex math=\"\\begin{aligned}\r\n\t\\delta_i&=\\left\\{\r\n\t\\begin{matrix}\r\n\t-c_iusign(\\beta_i), & \\text{ if }\\beta_i \\neq 0,\\\\\r\n\t-c_iu,& \\text{ if } \\beta_i=0.\r\n\t\\end{matrix}\r\n\t\\right.\\\\\r\n\t\\text{where}\\\\\r\n\tu&=\\left\\{\r\n\t\\begin{matrix}\r\n\t\\frac{y-X\\beta}{\\|y-X\\beta\\|_2}, & \\text{ if } y\\neq X\\beta,\\\\\r\n\t\\text{any unitary vector} & \\mbox{ otherwise.}\r\n\t\\end{matrix}\r\n\t\\right.\r\n\\end{aligned}\"/>\r\n\t Consequently, one have\r\n<Latex math=\"\\begin{aligned}\r\n\t\t\\max_{\\delta X \\in \\mathcal{U}} \\|y-(X+\\delta X)\\beta\\|_2&\\ge\\|y-(X+\\delta X^*)\\beta\\|_2\\\\\r\n\t\t&=\\|y-X\\beta+\\sum_{\\beta_i\\neq 0} c_iusign(\\beta_i)\\beta_i\\|_2\\\\\r\n\t\t&=\\|y-X\\beta+\\left(\\sum_{i} c_i|\\beta_i|\\right)u\\|_2\r\n\\end{aligned}\"/>\r\n<p align=\"right\"><Inline math=\"\\blacksquare\"/></p></div>\r\n<h2>Bayesian Interpretation</h2>\r\n\r\nRecall that the ridge regression estimator can be viewed as a Bayesian estimate of <Inline math=\"\\beta\"/> when imposing a Gaussian prior. Similarly, the lasso regression estimator can be viewed as a Bayesian estimate when imposing a Laplacian (or double exponential) prior for each parameter\r\n<Latex math=\"\\begin{aligned}\r\n\tp(\\beta_j)=\\frac{1}{2}\\lambda \\exp (-\\lambda |\\beta_j|)\r\n\\end{aligned}\"/>\r\nwith joint density\r\n<Latex math=\"\\begin{aligned}\r\n\tp(\\beta)=p(\\beta_1)\\cdots p(\\beta_p)=\\frac{1}{2\\tau}\\exp\\left(-\\frac{\\|\\beta\\|_1}{\\tau}\\right), \\quad \\text{ with } \\tau = \\frac{1}{\\lambda}\r\n\\end{aligned}\"/>\r\nMoreover, the lasso prior puts more mass close to zero and in the tails than the ridge prior. hence, the tendency of the lasso to produce either zero or large estimates as depicted in Figure <a href=\"#fig:gaussian_laplacian\">fig:gaussian_laplacian</a> \r\n<Image src=\"/images/gaussian_laplacian.svg\" label=\"fig:gaussian_laplacian\" legend=\"Comparison between the Gaussian and Laplacian Distribution.\" width=\"50%\"/>\r\n<p></p>\r\nThe LASSO estimate then corresponds to the mode of the posterior distribution given by the Bayes' Rule\r\n<Latex math=\"\\begin{aligned}\r\n\tp(\\beta|Y)=\\frac{p(Y|\\beta)p(\\beta)}{p(Y)}\r\n\\end{aligned}\"/>\r\nor in other words, the MAP estimator\r\n<Latex math=\"\\begin{aligned}\r\n\t\\beta = \\arg \\min_\\beta -\\log p(\\beta|Y).\r\n\\end{aligned}\"/>\r\n<div class='remark'><b>Remark:</b><br/>\r\n\tThe \"true Bayesian\" also puts a prior on the penalty parameter, giving rise to Bayesian LASSO regression. In addition, for high-dimensions, the Bayesian posterior need not concentrate on the \"true\" parameter. Even though, its mode is a good estimator of the regression parameter. \r\n</div>\r\n<h2>Moments of the LASSO</h2>\r\n\r\nIn contrast to ridge regression, there are no explicit expressions for the bias and variance of the lasso estimator, only approximations. However, as with the ridge estimator, the <i>trade-off</i> between bias and variance still holds, e.g., the bias of the lasso estimator increases and the variance decreases in proportion to the lasso penalty parameter.\r\n<p></p>\r\nIn order to assess the moments of the LASSO, first, consider the following approximation\r\n<Latex math=\"\\begin{aligned}\r\n\\|Y-X\\beta\\|_2^2+\\lambda\\|\\beta\\|_1 \\approx \\|Y-X\\beta\\|_2^2+\\frac{\\lambda}{2}\\sum_{j=1}^m\\frac{1}{|\\hat{\\beta}(\\lambda)|}\\beta_j^2\r\n\\end{aligned}\"/>\r\nOptimization of this approximation gives a \"ridge approximation\" to the lasso\r\n<Latex math=\"\\begin{aligned}\r\n\t\\hat{\\beta}(\\lambda)\\approx [X^T X+\\lambda \\Psi(\\hat{\\beta}(\\lambda))]^{-1}X^T Y\r\n\\end{aligned}\"/>\r\nwhere <Inline math=\"\\Psi\"/> is a diagonal matrix with <Inline math=\"\\Psi_{jj}=1/|\\hat{\\beta}_j(\\lambda)|\"/> if <Inline math=\"\\hat{\\beta}_j(\\lambda)\\neq 0\"/> and zero otherwise.\r\n<p></p>\r\nAnalogous to moment derivation of the ridge estimator, one obtains\r\n<Latex math=\"\\begin{aligned}\r\n\t\\mathbb{E}\\{\\hat{\\beta}(\\lambda)\\}\\approx [X^T X+\\lambda \\Psi(\\hat{\\beta}(\\lambda))]^{-1}X^T X\\beta \r\n\\end{aligned}\"/>\r\nand\r\n<Latex math=\"\\begin{aligned}\r\nvar\\{\\hat{\\beta}(\\lambda)\\}\\approx \\sigma^2[X^T X+\\lambda \\Psi(\\hat{\\beta}(\\lambda))]^{-1}X^T X[X^T X+\\lambda \\Psi(\\hat{\\beta}(\\lambda))]^{-1}\r\n\\end{aligned}\"/>\r\n<h2>Variations of LASSO</h2>\r\n\r\n<h3>Ordinary Lasso</h3>\r\n\r\n<p></p>\r\n<Latex math=\"\\begin{aligned}\r\n\\|y-X\\beta\\|_2^2 + \\lambda \\|\\beta\\|_1\r\n\\end{aligned}\"/>\r\n<p></p>\r\n<h3>Elastic Net</h3>\r\n\r\n<Latex math=\"\\begin{aligned}\r\n\\|y-X\\beta\\|_2^2 + \\lambda (\\alpha\\|\\beta\\|_2^2+(1-\\alpha)\\|\\beta\\|_1)\r\n\\end{aligned}\"/>\r\n<h3>Fused Lasso</h3>\r\n\r\n<Latex math=\"\\begin{aligned}\r\n\\|y-X\\beta\\|_2^2 + \\lambda_1 \\|\\beta\\|_1+\\lambda_2 \\sum_{j=2}^p |\\beta_j-\\beta_{j-1}|\r\n\\end{aligned}\"/>\r\n<h2>LASSO vs EVIU</h2>\r\n\r\nLASSO Cost\r\n<Latex math=\"\\begin{aligned}\r\n\t\\|y-X\\beta\\|_2^2 + \\lambda \\|\\beta\\|_1\r\n\\end{aligned}\"/>\r\n<p></p>\r\nEVIU Cost\r\n<Latex math=\"\\begin{aligned}\r\n\t\\|\\beta_0-\\beta\\|_G^2+\\|y-X\\beta\\|_W^2 + d^T |\\beta|\r\n\\end{aligned}\"/>\r\nNotice that the EVIU cost is equivalent to LASSO if <Inline math=\"G=0\"/>, <Inline math=\"W=I\"/> and <Inline math=\"d=\\lambda[1,\\ldots,1]^T\"/>.\r\n\r\n                    </div>\r\n                    <Disqus.DiscussionEmbed shortname={disqusShortname} config={disqusConfig} />\r\n                    </article>\r\n                    }\r\n                    export default Lasso;","import React from 'react';\r\nimport Helmet from 'react-helmet';\r\nimport '../../../Components/Pages/Tutorials.css';\r\nimport { BlockMath } from 'react-katex';\r\nimport Inline from '../../../Components/Latex/Inline';\r\nimport '../../../../node_modules/katex/dist/katex.css';\r\nimport Image from '../../../Components/Image/Image';\r\nimport Disqus from 'disqus-react';\r\nconst BayesianFiltering = (props) => {\r\nconst disqusShortname = 'marofe-github-io';\r\nconst disqusConfig = {\r\n        url: 'https://marofe.github.io/?p='+props.note.link,\r\n        identifier: 'note-'+props.note.link,\r\n        title: props.title\r\n    };\r\nreturn <article>\r\n      <Helmet>\r\n        <title>{props.note.title} | Marofe</title>\r\n        <meta name=\"description\" content={props.note.desc} />\r\n    </Helmet>\r\n    <h1>{props.title}</h1>\r\n<p>{props.desc}</p>\r\n    <p align=\"right\">Last Update:  26 August, 2020.</p>\r\n<div>\r\n    <p>\r\n        The following content is based on the book <a href=\"#sarkka\">SARKKA, 2013</a>.\r\n    </p>\r\n<h2>Bayes Framework</h2>\r\n\r\nIn the Bayes Framework, all results are treated as being approximations to certain probability distributions or their parameters. Probability distributions are used both to represent uncertainties in the models and for modeling the physical randomness. <p></p>\r\n\r\nThe term optimal filtering traditionally refers to a class of methods that can be used for estimating the state of a time-varying system which is indirectly observed through noisy measurements. The term optimal in this context refers to statistical optimality. Bayesian filtering refers to the Bayesian way of formulating optimal filtering. <p></p>\r\n\r\nIn the case of state estimation of a dynamic system, the term state refers to the collection of dynamic variables which fully describe the system in a given instant of time.\r\n<p></p>\r\nThe noise in the measurements means that they are uncertain. Even if we knew the true system state, the measurements would not be deterministic functions of the state, but would have a distribution of possible values. The time evolution of the state is modeled as a dynamic system which is perturbed by a certain process noise. This noise is used for modeling the uncertainties in the system dynamics which can be a natural disturb that the system is facing or a poorly knowledge of the system behavior itself. In most cases, the system may not be truly stochastic, but stochasticity is used for representing the model uncertainties.<p></p>\r\n\r\nBayesian Smoothing is considered a class of methods within the field of Bayesian filtering. However, while Bayesian filters in their basic form only compute estimates of the current state of the system given the history of measurements, Bayesian smoothers can be used to reconstruct states that happened before  the current time.<p></p>\r\n\r\nPhenomena which can be modeled as time-varying systems of the above type are very common in engineering applications. For example, in navigation, aerospace engineering, space engineering, remote surveillance, telecommunications, physics, audio signal processing, control engineering, finance, and many other fields. <p></p>\r\n<p></p>\r\nIn medicine, we can use the Bayesian framework to work with brain imaging methods such as electroencephalography (EEG), magnetoencephalography (MEG), parallel functional magnetic resonance imaging (fMRI) and many others.\r\n<p></p>\r\nAnother case is the estimation of spread of infectious diseases which often has uncertainties in the dynamic equation and measurements. Others dynamic process in biology such predator-prey models, population growth can also be modeled as stochastic differential equations and the state estimation problem also can be formulated as an optimal filtering and smoothing problem.\r\n<p></p>\r\nIn the same vein, learning systems or adaptive systems can often be mathematically formulated in terms of optimal filters and smoother as well, and they have a close relationship with Bayesian non-parametric modeling.\r\n<p></p>\r\nIn general, any physical system which is measured through non-ideal sensors can be formulated as stochastic state space models, and the time evolution of the system can be estimated using Bayesian filtering.\r\n<p></p>\r\nThe history of optimal filtering starts from the Wiener filter in 1950, which is a frequency domain solution to the problem of least squares optimal filtering of stationary Gaussian signals. The Wiener filter is still important in communication applications, digital signal processing and image processing. The disadvantage of the Wiener filter is that it can only be applied to stationary signals.\r\n<p></p>\r\nThe success of optimal linear filtering in engineering applications is mostly due to the seminal article of Kalman (1960), which describe the recursive solution to the optimal discrete-time (or sampled) linear filtering problem. One reason for the success is that the Kalman Filter can be understood and applied with very much lighter mathematical machinery than the Wiener filter. Besides, the Kalman filter also contains the Wiener filter as its limiting special case. \r\n<p></p>\r\nIn the early states of its history, the Kalman Filter was soon discovered to belong to the class of Bayesian filters. Although the original derivation of the Kalman Filter was based on the least squares approach, the same equations can be derived from pure probabilistic Bayesian analysis. The corresponding Bayesian smoothers were also developed soon after the invention of the Kalman Filter.\r\n<p></p>\r\nIn mathematical terms, optimal filtering and smoothing are considered to be statistical inversion problems where the unknown quantity is a vector valued time series <Inline math=\"\\{x_0,x_1,\\ldots\\}\"/> which is observed through a set of noisy measurements <Inline math=\"\\{y_1,y_2,\\ldots\\}\"/>.\r\nThe purpose of the statistical inversion problem is to estimate the hidden states <Inline math=\"x_{0:T}=\\{x_0,x_1,\\ldots,x_T\\}\"/> from the observed measurements set <Inline math=\"y_{1:T}=\\{y_1,y_2,\\ldots,y_T\\}\"/>, which means that in the Bayesian sense we want to compute the joint posterior distribution of all the states given all the measurements. In principle, this can be done by straightforward application of Bayes' rule\r\n<BlockMath math=\"\\begin{aligned}\r\n\tp(x_{0:T}|y_{1:T})=\\frac{p(y_{1:T}|x_{0:T})p(x_{0:T})}{p(y_{1:T})},\r\n\\end{aligned}\"/>\r\nwhere <Inline math=\"p(x_{0:T})\"/> is the prior distribution defined by the dynamic model, <Inline math=\"p(y_{1:T}|x_{0:T})\"/> is the likelihood model for the measurements and <Inline math=\"p(y_{1:T})\"/> is the normalization factor to ensure that <Inline math=\"\\int p(x_{0:T}|y_{1:T})dx_{0:T} = 1\"/>. This factor can be computed by the total probability theorem\r\n<BlockMath math=\"\\begin{aligned}\r\n\tp(y_{1:T})=\\int p(y_{1:T}|x_{0:T})p(x_{0:T})dx_{0:T}.\r\n\\end{aligned}\"/>\r\n\r\nUnfortunately, this full posterior formulation has the serious disadvantage that each time we obtain a new measurement, the full posterior distribution would have to be recomputed. In other words, when the number of time steps increase, the dimensionality of the full posterior distribution also increases, which means that the computational complexity of a single time step increases. Thus eventually the computations will become intractable, no matter how much computational power is available. Without additional information or restrictive approximations, there is no way of getting over this problem in the full posterior computation.\r\n<p></p>\r\nIn order to solve this problem, we may relax this a bit in such a way that we can be satisfied with just a selected marginal distribution of the states. We also need to restrict the class of dynamic models to probabilistic Markov Sequences, which is not as restrictive as it may first seem.\r\n<p></p>\r\nUsually, the following assumptions are made\r\n<ul>\r\n\t<li>\r\n\t An initial distribution specifies the prior probability distribution <Inline math=\"p(x_0)\"/> of the hidden state <Inline math=\"x_0\"/> at the initial time step <Inline math=\"k=0\"/>.\r\n\t </li>\r\n\t<li> A dynamic model describes the system dynamics and its uncertainties as a Markov Sequence, defined in terms of the transition probability distribution <Inline math=\"p(x_k|x_{k-1})\"/>.</li>\r\n\r\n\t<li>A measurement model describes how the measurement <Inline math=\"y_k\"/> depends on the current state <Inline math=\"x_k\"/>. This dependence is modeled by specifying the conditional probability distribution of the measurement given the state, which is denoted as <Inline math=\"p(y_k|x_k)\"/>.\r\n\t</li>\r\n\t</ul>\r\n\r\nBecause computing the full joint distribution of the states at all times steps is computacionally very inefficient and unnecessary in real-time applications, in Bayesian filtering and smoothing the following marginal distributions are considered instead.\r\n<ul>\r\n\t<li><b>Filtering distributions</b> computed by the Bayesian filter are the marginal distributions of the current state <Inline math=\"x_k\"/> given the current and previous measurement <Inline math=\"y_{1:k}=\\{y_1,\\ldots,y_k\\}\"/>:\r\n<BlockMath math=\"\t\\begin{aligned}\r\n\t\tp(x_k|y_{1:k}),\\quad k=1,\\ldots, T\r\n\\end{aligned}\"/>\r\n</li> \r\n<li><b>Prediction distributions</b> which can be computed with the prediction step of the Bayesian filter are the marginal distributions of the future state <Inline math=\"x_{k+n}\"/>, <Inline math=\"n\"/> steps after the current time step:\r\n<BlockMath math=\"\t\\begin{aligned}\r\n\t\tp(x_{k+n}|y_{1:k}),\\quad k=1,\\ldots, T, \\quad n = 1,2,\\ldots\r\n\\end{aligned}\"/>\r\n</li>\r\n<li><b>Smoothing Distributions</b> computed by the Bayesian smoother are the marginal distributions of the state <Inline math=\"x_k\"/> given a certain interval <Inline math=\"y_{1:T}=\\{y_1,\\ldots,y_T\\}\"/> of measurements with <Inline math=\"T>k\"/>:\r\n<BlockMath math=\"\t\\begin{aligned}\r\n\t\tp(x_k|y_{1:T}), \\quad k=1,\\ldots , T.\r\n\\end{aligned}\"/>\r\n</li>\r\n</ul>\r\n\r\nComputing the filtering, prediction, and smoothing distributions require only a constant number of computations per time step, and thus the problem of processing arbitrarily long time series is solved.\r\n<p></p>\r\nThe well-known <i>Kalman Filter</i> (KF) is a closed form solution to the linear Gaussian filtering problem.  The <i>Rauch-Tung-Striebel</i> smoother (RTS) is the corresponding closed form smoother for linear Gaussian state space models. <i>Grid Filters</i> and <i>Grid smoothers</i> are solutions to Markov models with finite state spaces.\r\n<p></p>\r\nBut because the Bayesian optimal filtering and smoothing equations are generally computationally intractable, many kinds of numerical approximations methods have been developed, for example:\r\n<ul>\r\n\t<li><i>The extended Kalman Filter</i> (EKF) approximates the non-linear and non-Gaussian measurements and dynamic models by first order Taylor expansion at the nominal solution. This results in a Gaussian approximation to the filtering distributions.</li>\r\n\t<p></p><li> <i>The extended Rauch-Tung-Striebel smoother</i> is the approximate non-linear smoothing algorithm corresponding to EKF.</li>\r\n\t<p></p><li> <i>The unscentend Kalman Filter</i> (UKF) approximates the propagation of densities through the non-linearities of measurement and noise processes using the <i>unscented transform</i>. This also results in a Gaussian approximation.</li>\r\n\t<p></p><li> <i>The unscented Rauch-Tung-Striebel smoother</i> is the approximate non-linear smoothing algorithm corresponding to UKF.</li>\r\n\t<p></p><li> <i>Sequential Monte Carlo methods</i> or <i>particle filters (PF) and smoothers</i> represent the posterior distribution as a weighted set of Monte Carlo samples.</li>\r\n\t<p></p><li> <i>The unscented particle filter</i> (UPF) or <i>local linearization based particle filter</i> (LLPF) filtering methods that use UKF and EKF, respectively, for approximating the optimal importance distributions in particle filter settings.</li>\r\n\t<p></p><li> <i>Rao-Blackwellized particle filters and smoothers</i> use closed form integration (e.g., Kalman Filter and RTS smoothers) for some of the state variables and Monte Carlo integration for others.</li>\r\n\t</ul>\r\nOther methods also exist, for example, based on Gaussian mixtures.\r\n<h2>Bayesian filtering equations and exact solutions</h2>\r\n\r\nBayesian filtering is considered with state estimation in general probabilistic state space models which have the following form\r\n<BlockMath math=\"\t\\begin{aligned}\r\n\tx_k&\\sim p(x_k|x_{k-1})\\\\\r\n\ty_k&\\sim p(y_k|x_k)\\\\\r\n\tk&=1,2,\\ldots\r\n\\end{aligned}\"/>\r\nwhere <Inline math=\"x_k \\in \\mathbb{R}^n\"/> is the state of the system at time step <Inline math=\"k\"/>, <Inline math=\"y_k \\in \\mathbb{R}^m\"/> is the measurement at time step <Inline math=\"k\"/>, <Inline math=\"p(x_k|x_{k-1})\"/> is the dynamic model which describes the stochastic dynamic of the system, and <Inline math=\"p(y_k|x_k)\"/> is the measurement model, which is the distribution of measurements given the state.\r\n\r\nThe model is assumed to be Markovian, which means that it has the following properties\r\n<BlockMath math=\"\\begin{aligned}\r\np(x_k|x_{0:k-1},y_{1:k-1})&=p(x_k|x_{k-1})\\\\\r\np(x_{k-1}|x_{k:T},y_{k:T})&=p(x_{k-1}|x_k)\r\n\\end{aligned}\"/>\r\nAnother assumption usually made is the <i>Conditional independence of measurements</i> that means\r\n<BlockMath math=\"\\begin{aligned}\r\n\tp(y_k|x_{1:k},y_{1:k-1})=p(y_k|x_k).\r\n\\end{aligned}\"/>\r\n\r\nWith the Markovian assumption and conditional independence of measurements, the <i>joint prior distribution</i> of the states and the <i>joint likelihood</i> of the measurements are, respectively\r\n<BlockMath math=\"\\begin{aligned}\r\n\tp(x_{0:T})&=p(x_0)\\prod_{k=1}^Tp(x_k|x_{k-1})\\\\\r\n\tp(y_{1:T})&=\\prod_{k=1}^T p(y_k|x_k)\r\n\\end{aligned}\"/>\r\nIn principle, for a given <Inline math=\"T\"/>, we could simply compute the posterior distribution of the states by <i>Bayes' rule</i>.\r\nHowever, this is intractable for most applications because the number of computations increases as new observations arrive. To cope with real problem we need to have some recursive algorithm that does a constant number of operations independent of the number of observations. For this reason, we shall not consider the full posterior computation at all, but concentrate on the above mentioned distributions: filtering and prediction distributions and corresponding smoothing distributions.\r\n<h3>Bayesian filtering</h3>\r\n\r\nThe purpose of Bayesian filtering is to compute the marginal posterior distribution or filtering distribution of the state <Inline math=\"x_k\"/> at each time step <Inline math=\"k\"/> given the history of measurements up to the time step <Inline math=\"k\"/>:\r\n<BlockMath math=\"\\begin{aligned}\r\n\tp(x_k|y_{1:k})\r\n\\end{aligned}\"/>\r\n\r\n<div className=\"lemma\">\r\n    <b>Lemma:</b><br/>\r\nThe recursive equations for the Bayesian filter are given by the following equations\r\n<ul>\r\n\t<li><b>Initialization:</b> The recursion starts from the prior distribution <Inline math=\"p(x_0)\"/>;</li>\r\n\t<li><b>Prediction step:</b> The predictive distribution fo the state <Inline math=\"x_k\"/> at the time step <Inline math=\"k\"/>, given the dynamic model, can be computed by the <i>Chapman-Kolmogorov equation</i>\r\n<BlockMath math=\"\t\\begin{aligned}\r\n\t\tp(x_k|y_{1:k-1})=\\int p(x_k|x_{k-1})p(x_{k-1}|y_{1:k-1})dx_{k-1}.\r\n\\end{aligned}\"/>\r\n</li>\r\n\t<li> <b>Update step:</b> Given the measurement <Inline math=\"y_k\"/> at time step <Inline math=\"k\"/> the posterior distribution of the state <Inline math=\"x_k\"/> can be computed by <i>Bayes' rule</i>\r\n<BlockMath math=\"\t\\begin{aligned}\r\n\t\tp(x_k|y_{1:k})=\\frac{1}{c}p(y_k|x_k)p(x_k|y_{1:k-1}),\r\n\\end{aligned}\"/>\r\n\twhere the constant <Inline math=\"c\"/> is the normalization factor given by\r\n<BlockMath math=\"\t\\begin{aligned}\r\n\t\tc=\\int p(y_k|x_k)p(x_k|y_{1:k-1})dx_k.\r\n\\end{aligned}\"/>\r\n</li>\r\n</ul>\r\n</div>\r\n<div className=\"proof\"><b>Proof:</b><br/>\r\n\tBased on the Markovian and Conditioned Independence of measurement assumptions, one has\r\n<BlockMath math=\"\\begin{aligned}\r\np(x_k,x_{0:k-1}|y_{1:k})&=p(x_k,x_{k-1}|y_k,y_{1:k-1})\\\\\r\n&=\\frac{p(y_k|x_k,x_{k-1},y_{1:k-1})p(x_k,x_{k-1}|y_{1:k-1})}{p(y_k|y_{1:k-1})}\\\\\r\n&=\\frac{p(y_k|x_k,x_{k-1},y_{1:k-1})p(x_k|x_{k-1},y_{1:k-1})p(x_{k-1}|y_{1:k-1})}{p(y_k|y_{1:k-1})}\\\\\r\n&=\\frac{p(y_k|x_k)p(x_k|x_{k-1})p(x_{k-1}|y_{1:k-1})}{p(y_k|y_{1:k-1})}.\r\n\\end{aligned}\"/>\r\nTherefore,\r\n<BlockMath math=\"\\begin{aligned}\r\np(x_k|y_{1:k})&=\\int p(x_k,x_{k-1}|y_{1:k})dx_{k-1}\\\\\r\n&=\\int \\frac{p(y_k|x_k)p(x_k|x_{k-1})p(x_{k-1}|y_{1:k-1})}{p(y_k|y_{1:k-1})} dx_{k-1}\\\\\r\n&=\\frac{p(y_k|x_k)\\int p(x_k|x_{k-1})p(x_{k-1}|y_{1:k-1}) dx_{k-1}}{p(y_k|y_{1:k-1})}\\\\\r\n&=\\frac{p(y_k|x_k)p(x_k|y_{1:k-1})}{\\int p(y_k,x_k|y_{1:k-1})dx_k}\\\\\r\n&=\\frac{1}{c}p(y_k|x_k)p(x_k|y_{1:k-1}).\r\n\\end{aligned}\"/>\r\n<p align=\"right\"><Inline math=\"\\blacksquare\"/></p>\r\n</div>\r\n<h2>References:</h2>\r\n<p><a name=\"sarkka\"></a>Särkkä, S., 2013. Bayesian filtering and smoothing. Cambridge University Press.</p>\r\n</div>\r\n<Disqus.DiscussionEmbed shortname={disqusShortname} config={disqusConfig} />\r\n</article>\r\n}\r\nexport default BayesianFiltering;","import React from 'react';\r\nimport Helmet from 'react-helmet';\r\nimport '../../../Components/Pages/Tutorials.css';\r\nimport { BlockMath } from 'react-katex';\r\nimport Inline from '../../../Components/Latex/Inline';\r\nimport Latex from '../../../Components/Latex/latex';\r\nimport '../../../../node_modules/katex/dist/katex.css';\r\nimport Image from '../../../Components/Image/Image';\r\nimport Disqus from 'disqus-react';\r\nconst IntroKalmanFilter = (props) => {\r\nconst disqusShortname = 'marofe-github-io';\r\nconst disqusConfig = {\r\n        url: 'https://marofe.github.io/?p='+props.note.link,\r\n        identifier: 'note-'+props.note.link,\r\n        title: props.title\r\n    };\r\nreturn <article>\r\n      <Helmet>\r\n        <title>{props.note.title} | Marofe</title>\r\n        <meta name=\"description\" content={props.note.desc} />\r\n    </Helmet>\r\n    <h1>{props.title}</h1>\r\n<p>{props.desc}</p>\r\n    <p align=\"right\">Last Update:  September 19, 2021.</p>\r\n<div>\r\n<h2>Introduction</h2>\r\n\r\nKalman-type filters are extremely useful in diverse\r\nreal-world applications, including robotics, communication systems, GNSS, inertial navigation, chemical plant control, predicting the weather, multi-sensor data fusion, tracking of aircraft, satellites, ships, rockets, cars, people, cows, etc. Moreover, Kalman filters are relatively easy to design and code, and, besides its simplicity, they often provide good estimation accuracy for various real applications.\r\n<p></p>\r\nThe reason for the use of the word \"filter\" is because it consists of a process to obtain the \"best estimate\" from noisy data, thus, amounts to \"filtering out\" the noise. But, more than that, the Kalman Filter also can provide estimates of variables that we do not even measure. For example, in tracking applications, we might only observe the position of a target and through the Kalman Filter we can obtain estimates of the velocity and heading as well. In another example, the Kalman Filter can provide estimates of the biases of accelerometer and gyroscope sensors in Inertial Navigation Systems without any direct measure of these biases.\r\n<p></p>\r\nFrom a theoretical viewpoint, the Kalman Filter is known to be the optimal filter for linear systems disturbed by Gaussian Noises. The optimality is in the MSE sense, i.e. the filter provides the smallest mean square error for systems that have linear state-space representation and are immersed in Gaussian noises.\r\n<p></p>\r\nRoughly speaking, the Kalman Filter combines knowledge about the system dynamic (prediction) with available measurements from sensors in a probabilistic manner. This allows one to characterize various random factors (disturbances) that the system might encounter.\r\n<p></p>\r\nThere are various ways to derive the Kalman Filter equations. The first derivations given by Rudolf Emil Kalman in <a href=\"#cite.Kalman1960\">Kalman1960</a> was based in the orthogonality principle. However, here we focus on the Bayesian derivation, as it seems to be the most elegant way to think about the Kalman Filter.\r\n<p></p>\r\nThe purpose of Bayesian filtering, in a nutshell, is to compute <i>the probability density function </i> (pdf) of the system state given all the measurement up to the present time. In particular, this pdf is referred to as the posterior distribution or filtering distribution of the system state, and it is denoted by <Inline math=\"p(x_k|y_{1:k})\"/> where <Inline math=\"x_k\\in\\mathbb{R}^n\"/> is the system state and <Inline math=\"y_{1:k}\"/> denotes the set of all measurements up to time instant <Inline math=\"k\"/>.\r\n<p></p>\r\nFor Markovian Systems, i.e. systems where the future state depends solely on the present state, this is accomplished by two equations. First, the so-called <i>Chapman-Komogorov Equation</i>,\r\n<Latex math=\"\\begin{aligned}\r\n\t\tp(x_{k+1}|y_{1:k})=\\int p(x_{k+1}|x_{k})p(x_{k}|y_{1:k})dx_{k},\r\n\\end{aligned}\" label=\"eq:chapman.komogorov\"/>\r\nprovides the predictive distribution (prior state). The pdf <Inline math=\"p(x_{k+1}|x_k)\"/> is the transition distribution, which encodes the dynamic model of the system by describing the probability of the next state given the present one. In addition, <Inline math=\"p(x_k|y_{1:k})\"/> stands for the pdf of the present state given all measurements available.\r\n<p></p>\r\nThereafter, when a new measurement <Inline math=\"y_{k+1}\"/> becomes available from the sensors, the predictive distribution is updated to form the posterior distribution using the <i>Bayes' rule</i>,\r\n<Latex math=\"\\begin{aligned}\r\n\t\tp(x_{k+1}|y_{1:k+1})=\\frac{p(y_{k+1}|x_{k+1})p(x_{k+1}|y_{1:k})}{p(y_{k+1}|y_{1:k})},\r\n\\end{aligned}\" label=\"eq:bayes.rule\"/>\r\nwhere <Inline math=\"p(y_{k+1}|x_{k+1})\"/> is the measurement distribution or likelihood distribution and <Inline math=\"p(y_{k+1}|y_{1:k})\"/> acts as a normalization constant.\r\n<p></p>\r\nUnfortunately, the Bayesian Filter cannot be analytically obtained for the majority of systems because the integral in <a href=\"#eq:chapman.komogorov\">eq:chapman.komogorov</a> becomes intractable, and the product <a href=\"#eq:bayes.rule\">eq:bayes.rule</a> usually do not result in a known distribution. So, numeric approximations such as Particle Filters are used instead.\r\n<p></p>\r\nHowever, remarkably, for linear systems with Gaussian noises both <a href=\"#eq:chapman.komogorov\">eq:chapman.komogorov</a>-<a href=\"#eq:bayes.rule\">eq:bayes.rule</a> can be evaluated in closed-form resulting in the celebrated Kalman Filter.\r\n<p></p>\r\n<h2>From Bayes to Kalman Filter</h2>\r\n\r\nConsider a linear system described in state-space by\r\n<Latex math=\"\\begin{aligned}\r\n    x_{k+1}=Ax_k+Bu_k+Gw_k\r\n\\end{aligned}\" label=\"eq:sys.dynamic\"/>\r\nwhere <Inline math=\"A\\in\\mathbb{R}^{n\\times n}\"/> is the dynamic matrix, <Inline math=\"B\\in\\mathbb{R}^{n\\times p}\"/> is the input matrix, <Inline math=\"u_k\\in\\mathbb{R}^p\"/> is the input vector, <Inline math=\"G\\in\\mathbb{R}^{n\\times l}\"/> is the disturbance matrix, i.e. describes how the noise affect the states, and <Inline math=\"w_k\\sim\\mathcal{N}(0,Q_k)\"/> is a Gaussian noise with zero-mean and covariance matrix <Inline math=\"Q_k=Q_k^T\\succ 0 \\in \\mathbb{R}^{l\\times l}\"/> referred to as <i>the process noise</i>. \r\n<p></p>\r\n<div class='remark'><b>Remark:</b><br/>\r\nAlthough the system coefficient matrices are denoted without time-index, all the following results are valid as well for time-varying matrices.\r\n</div>\r\n<p></p>\r\nFrom <a href=\"#eq:sys.dynamic\">eq:sys.dynamic</a>, note that if we know the present state <Inline math=\"x_k\"/> and the input <Inline math=\"u_k\"/> then the only random component is <Inline math=\"Gw_k\"/>. Therefore, <Inline math=\"x_{k+1}\"/> is a random variable with mean <Inline math=\"(Ax_k+Bu_k)\"/> and covariance <Inline math=\"GQ_kG^T\"/>. Accordingly, one can state the transition distribution of a linear system corrupted by Gaussian noise as\r\n<Latex math=\"\\begin{aligned}\r\n    p(x_{k+1}|x_k)=\\mathcal{N}(x_{k+1};Ax_k+Bu_k,GQ_kG^T).\r\n\\end{aligned}\"/>\r\n<p></p>\r\nMoreover, if the present state is also Gaussian distributed, i.e. <Inline math=\"x_k\\sim\\mathcal{N}(x_k;\\hat{x}_{k|k},P_{k|k})\"/>, thus, by evaluating the Chapman-Komogorov Equation one conclude that\r\n<Latex math=\"\\begin{aligned}\r\n    p(x_{k+1}|y_{1:k})=\\mathcal{N}(x_{k+1};\\hat{x}_{k+1|k},P_{k+1|k})\r\n\\end{aligned}\"/>\r\nwhere\r\n<Latex math=\"\\begin{aligned}\r\n\\hat{x}_{k+1|k}&=A\\hat{x}_{k|k}+Bu_k,\\\\\r\nP_{k+1|k}&=AP_{k|k}A^T+GQ_kG^T.\r\n\\end{aligned}\"/>\r\nObs: See the proof in the appendix <a href=\"#app:kf.time.update\">app:kf.time.update</a>.\r\n<p></p>\r\nFurthermore, consider the measurement model in the form\r\n<Latex math=\"\\begin{aligned}\r\ny_{k+1}=Hx_{k+1}+\\varepsilon_{k+1}\r\n\\end{aligned}\" label=\"eq:sys.meas\"/>\r\nwhere <Inline math=\"H\\in\\mathbb{R}^{m\\times n}\"/> is the output matrix and <Inline math=\"\\varepsilon_k\\sim\\mathcal{N}(0,R_{k+1})\"/> is the measurement noise. This means that the available measurements are obtained by sensors that are modeled by a linear map of the system state, and the measurement noise is also Gaussian. Note that from <a href=\"#eq:sys.meas\">eq:sys.meas</a>, given the state <Inline math=\"x_{k+1}\"/> the only random part is the measurement noise. Thus, the measurement distribution is\r\n<Latex math=\"\\begin{aligned}\r\np(y_{k+1}|x_{k+1})=\\mathcal{N}(y_{k+1};Hx_{k+1},R_{k+1}).\r\n\\end{aligned}\"/>\r\nIn this case, because the Gaussian distribution is a conjugate prior to itself, the Baye's Rule results in\r\n<Latex math=\"\\begin{aligned}\r\n    p(x_{k+1}|y_{1:k+1})=\\mathcal{N}(x_{k+1};\\hat{x}_{k+1|k+1},P_{k+1|k+1}),\r\n\\end{aligned}\"/>\r\nwhere\r\n<Latex math=\"\\begin{aligned}\r\n    \\hat{x}_{k+1|k+1}&=\\hat{x}_{k+1|k}+K(y_{k+1}-H\\hat{x}_{k+1|k}),\\\\\r\n    K&=P_{k+1|k}H^T(R_{k+1}+HP_{k+1|k}H^T)^{-1},\\\\\r\n    P_{k+1|k+1}&=(I-KH)P_{k+1|k}.\r\n\\end{aligned}\"/>\r\nObs: See the proof in the appendix <a href=\"#app:kf.meas.update\">app:kf.meas.update</a>\r\n<p></p>\r\nIn summary, given the initial state in the form <Inline math=\"x_0\\sim\\mathcal{N}(x_0,\\hat{x}_{0|0},P_{0|0})\"/>, the Kalman Filter consist of evaluating recursively from <Inline math=\"k=0,1,2,3,\\ldots\"/> the following five equations\r\n<Latex math=\"\\begin{aligned}\r\n    \\hat{x}_{k+1|k}&=A\\hat{x}_{k|k}+Bu_k,\\\\\r\nP_{k+1|k}&=AP_{k|k}A^T+GQ_kG^T\\\\\r\n\\hat{x}_{k+1|k+1}&=\\hat{x}_{k+1|k}+K(y_{k+1}-H\\hat{x}_{k+1|k}),\\\\\r\n    K&=P_{k+1|k}H^T(R_{k+1}+HP_{k+1|k}H^T)^{-1},\\\\\r\n    P_{k+1|k+1}&=(I-KH)P_{k+1|k}.\r\n\\end{aligned}\"/>\r\n<p></p>\r\nInterestingly, the Kalman Filter can be interpreted as a two-stage recursive algorithm where first a prediction is made based on the dynamic model followed by a correction provided by the measurement. Figure <a href=\"#fig:recursive.diagram\">fig:recursive.diagram</a> illustrate this recursive nature of the Kalman Filter.\r\n<p></p>\r\n<Image src=\"/images/recursive_diagram.svg\" label=\"fig:recursive.diagram\" legend=\"Recursive structure of the Kalman Filter.\" width=\"50%\"/>\r\n<p></p>\r\nIf numeric stability is a concern, the last equation for the posterior covariance can be replaced by the so-called <i>Joseph Form</i>,\r\n<Latex math=\"\\begin{aligned}\r\n    P_{k+1|k+1}=(I-KH)P_{k+1|k}(I-KH)^T +KR_{k+1}K^T,\r\n\\end{aligned}\"/>\r\nthat reduces the loss of symmetry of the covariance matrix due to numeric round-off.\r\n<p></p>\r\n<h2>Example: 1D Tracking</h2>\r\n\r\nTo illustrate how a Kalman Filter works, let's consider a toy example of a unidimensional tracking problem of a car, as illustrated in Figure <a href=\"#fig:1d.tracking.example\">fig:1d.tracking.example</a>.\r\n<Image src=\"/images/1d_tracking_gaussian.svg\" label=\"fig:1d.tracking.example\" legend=\"1D Tracking example.\" width=\"50%\"/>\r\nSuppose the system follows a <i>quasi-constant velocity model</i> where the states are the position and velocity of the target, i.e. <Inline math=\"x_k=[p_k~v_k]^T\"/>. The state-space models is then,\r\n<Latex math=\"\\begin{aligned}\r\n   \\begin{bmatrix}\r\n    p_{k+1}\\\\\r\n    v_{k+1}\r\n   \\end{bmatrix} =\\begin{bmatrix}\r\n    1 & \\Delta t\\\\\r\n    0 & 1\r\n   \\end{bmatrix} \\begin{bmatrix}\r\n    p_{k}\\\\\r\n    v_{k}\r\n   \\end{bmatrix} +\\begin{bmatrix}\r\n    0\\\\\r\n    1\r\n   \\end{bmatrix} w_k.\r\n\\end{aligned}\"/>\r\nFor this example, there is no direct input, but we assume that there is a little fluctuation in the velocity represented by a Gaussian noise <Inline math=\"w_k\\sim \\mathcal{N}(0,Q_k)\"/> that enters only the velocity state, this explains the terminology \"quasi-constant velocity\" model. \r\n<p></p>\r\nIn addition, suppose that a radar provides noisy position measurements of the target. Thus, the measurement model is in the form\r\n<Latex math=\"\\begin{aligned}\r\n    y_k=[1~0]x_k+\\varepsilon_k,\r\n\\end{aligned}\"/>\r\nwhere <Inline math=\"\\varepsilon_k\\sim\\mathcal{N}(0,R_k)\"/> is the radar noise. Assume that the target start about <Inline math=\"90\"/> meters far away of the radar and its velocity is close to <Inline math=\"3\"/>m/s. But, we do not know this initial condition. Thus, we use a Gaussian distribution for the initial state in the form <Inline math=\"x_0\\sim\\mathcal{N}(\\hat{x}_{0|0},P_{0|0})\"/> where <Inline math=\"\\hat{x}_{0|0}=[100~5]^T\"/> is the initial guess and <Inline math=\"P_{0|0}=diag((5m)^2,(1m/s)^2)\"/> the confidence, i.e. with <Inline math=\"95\\%\"/> probability the initial position is about <Inline math=\"100\\pm 15m\"/> and the velocity <Inline math=\"5\\pm 3m/s\"/> (<Inline math=\"3\\sigma\"/> interval). Also, suppose that the radar noise has a standard deviation of <Inline math=\"2m\"/> and the velocity fluctuation has a standard deviation of <Inline math=\"0.1m/s\"/> , i.e. <Inline math=\"R=(2m)^2\"/>, <Inline math=\"Q=(0.1m/s)^2\"/>. Thus, <Inline math=\"y_k=p_k\\pm 6m\"/> and <Inline math=\"v_{k+1}=v_k\\pm 0.3m/s\"/> with <Inline math=\"95\\%\"/> probability. The Kalman Filter for this example is then\r\n<Latex math=\"\\begin{aligned}\r\n     \\hat{x}_{k+1|k}&=\\begin{bmatrix}\r\n    1 & \\Delta t\\\\\r\n    0 & 1\r\n   \\end{bmatrix}\\hat{x}_{k|k},\\\\\r\nP_{k+1|k}&=\\begin{bmatrix}\r\n    1 & \\Delta t\\\\\r\n    0 & 1\r\n   \\end{bmatrix}P_{k|k}\\begin{bmatrix}\r\n    1 & \\Delta t\\\\\r\n    0 & 1\r\n   \\end{bmatrix}^T+\\begin{bmatrix}\r\n    0 \\\\ 1\r\n   \\end{bmatrix}Q\\begin{bmatrix}\r\n    0 & 1\r\n   \\end{bmatrix},\\\\\r\n\\hat{x}_{k+1|k+1}&=\\hat{x}_{k+1|k}+K(y_{k+1}-[1~0]\\hat{x}_{k+1|k}),\\\\\r\n    K&=P_{k+1|k}[1~0]^T(R+[1~0]P_{k+1|k}[1~0]^T)^{-1},\\\\\r\n    P_{k+1|k+1}&=(I-K[1~0])P_{k+1|k}.\r\n\\end{aligned}\"/>\r\nThe result of a simulation using Matlab is shown in the Figure <a href=\"#fig:1d.tracking\">fig:1d.tracking</a>.\r\n<p></p>\r\n<Image src=\"/images/1d_tracking.svg\" label=\"fig:1d.tracking\" legend=\"Example of the Kalman Filter for 1D tracking.\" width=\"50%\"/>\r\n<h1 id=\"appendix\">Appendix</h1>\r\n\r\n<h2>Time-update</h2>\r\n\r\n<a class=\"label\" id=\"app:kf.time.update\"></a>\r\n<div class='lemma'><b>Lemma:</b><br/>\r\n<a class=\"label\" id=\"lemma:kf.time.update\"></a>\r\nConsider the linear and Gaussian systems in the form\r\n<Latex math=\"\\begin{aligned}\r\n    x_{k+1}&=Ax_k+w_k\r\n\\end{aligned}\"/>\r\nwith <Inline math=\"w_k\\sim\\mathcal{N}(0,Q_k)\"/>. For a given a distribution of the state at time <Inline math=\"k\"/> in the form <Inline math=\"x_k\\sim\\mathcal{N}(x_k;\\hat{x}_{k|k},P_{k|k})\"/>, <b>the predictive distribution one-step ahead</b> is given by\r\n<Latex math=\"\\begin{aligned}\r\n    p(x_{k+1}|y_{1:k})&=\\mathcal{N}(x_{k+1};A\\hat{x}_{k|k},P_{k+1|k})\\\\\r\n    &=\\frac{1}{\\sqrt{(2\\pi)^n|P_{k+1|k}|}}\\exp\\left(-\\frac{1}{2}\\|x_{k+1}-A\\hat{x}_{k|k}\\|_{P_{k+1|k}^{-1}}^2\\right),\r\n\\end{aligned}\"/>\r\nwith \r\n<Latex math=\"\\begin{aligned}\r\n    P_{k+1|k}=AP_{k|k}A^T +Q_k.\r\n\\end{aligned}\"/>\r\n</div>\r\n<div class='proof'><b>Proof:</b><br/>\r\n<Latex math=\"\\begin{aligned}\r\n    p(x_{k+1}|y_{1:k})=\\int p(x_{k+1}|x_k)p(x_k|y_{1:k})dx_k\r\n    \\\\\r\n    =\\alpha\\int \\exp\\left(-\\frac{1}{2}(\\|x_{k+1}-Ax_k\\|_{Q_k^{-1}}^2+\\|x_k-\\hat{x}_{k|k}\\|_{P_{k|k}^{-1}}^2)\\right)dx_k\\\\\r\n    =\\alpha \\exp\\left(-\\frac{1}{2}(\\|x_{k+1}\\|_{Q_k^{-1}}^2+\\|\\hat{x}_{k|k}\\|_{P_{k|k}^{-1}}^2)\\right)\\\\\\times \\int \\exp\\left(-\\frac{1}{2}\\|x_k\\|^2_{W}+x^T_k(P_{k|k}^{-1}\\hat{x}_{k|k}+A^T Q^{-1}x_{k+1})\\right)dx_k\r\n\\end{aligned}\"/>\r\nwhere \r\n<Latex math=\"\\begin{aligned}\r\n\\alpha&=((2\\pi)^{2n}|Q_k||P_{k|k}|)^{-1/2},\\\\\r\nW&=A^T Q_k^{-1}A+P_{k|k}^{-1}\r\n\\end{aligned}\"/>\r\n<p></p>\r\nNotice that\r\n<Latex math=\"\\begin{aligned}\r\n    -\\frac{1}{2}\\|x_k-W^{-1}(P_{k|k}^{-1}\\hat{x}_{k|k}+A^T Q^{-1}x_{k+1})\\|_W^2\\\\=-\\frac{1}{2}\\|x_k\\|^2_W+x_k^T (P_{k|k}^{-1}\\hat{x}_{k|k}+A^T Q^{-1}x_{k+1})-\\frac{1}{2}\\|P_{k|k}^{-1}\\hat{x}_{k|k}+A^T Q^{-1}x_{k+1}\\|^2_{W^{-1}}\r\n\\end{aligned}\"/>\r\nTherefore,\r\n<Latex math=\"\\begin{aligned}\r\n    p(x_{k+1}|y_{1:k})\r\n    =\\alpha \\exp\\left(-\\frac{1}{2}(\\|x_{k+1}\\|_{Q_k^{-1}}^2+\\|\\hat{x}_{k|k}\\|_{P_{k|k}^{-1}}^2-\\|P_{k|k}^{-1}\\hat{x}_{k|k}+A^T Q_k^{-1}x_{k+1}\\|^2_{W^{-1}})\\right)\\\\\\times \\int \\exp\\left(-\\frac{1}{2}\\|x_k-W^{-1}(P_{k|k}^{-1}\\hat{x}_{k|k}+A^T Q^{-1}x_{k+1})\\|^2_{W}\\right)dx_k\\\\\r\n    =\\alpha\\exp\\Bigl(-\\frac{1}{2}(\\|x_{k+1}\\|_{Q_k^{-1}-Q_k^{-1}AW^{-1}A^T Q_k^{-1}}^2+\\|\\hat{x}_{k|k}\\|_{P_{k|k}^{-1}-P_{k|k}^{-1}W^{-1}P_{k|k}^{-1}}^2\\\\-2\\hat{x}_{k|k}^T P_{k|k}^{-1}W^{-1}A^T Q^{-1}_kx_{k+1})\\Bigr)\\times \\sqrt{(2\\pi)^n|W^{-1}|}.\r\n\\end{aligned}\"/>\r\nLet <Inline math=\"P_{k+1|k}=AP_{k|k}A^T + Q_k\"/>, thus \r\n<Latex math=\"\\begin{aligned}\r\n    \\|x_{k+1}-A\\hat{x}_{k|k}\\|_{P_{k+1|k}^{-1}}^2=\\|x_{k+1}\\|_{P_{k+1|k}^{-1}}^2+\\|\\hat{x}_{k|k}\\|_{A^T P_{k+1|k}^{-1}A}^2-2x_{k+1}^T P_{k+1|k}^{-1}A\\hat{x}_{k|k}\r\n\\end{aligned}\"/>\r\nand\r\n<Latex math=\"\\begin{aligned}\r\nP_{k+1|k}^{-1}=(AP_{k|k}A^T+Q_k)^{-1}\\\\\r\n=Q_k^{-1}-Q_k^{-1}A [P_{k|k}^{-1}+A^T Q_k^{-1}A]^{-1}A^T Q_k^{-1}\\\\\r\n=Q_k^{-1}-Q_k^{-1}A W^{-1}A^T Q_k^{-1}\r\n\\end{aligned}\"/>\r\nwith  <Inline math=\"W^{-1}=P_k-P_kA^T [Q_k+AP_{k|k}A^T]^{-1}A P_k\"/>. Accordingly,\r\n<Latex math=\"\\begin{aligned}\r\n    P_{k|k}^{-1}-P_{k|k}^{-1}W^{-1}P_{k|k}^{-1}\\\\=P_{k|k}^{-1}-P_{k|k}^{-1}(P_k-P_kA^T [Q_k+AP_{k|k}A^T]^{-1}A P_k)P_{k|k}^{-1}\\\\\r\n    =A^T P_{k+1|k}^{-1}A.\r\n\\end{aligned}\"/>\r\nFinally, as <Inline math=\"AP_{k|k}A^T=P_{k+1|k}-Q_k\"/>, one has\r\n<Latex math=\"\\begin{aligned}\r\n    Q_k^{-1}AW^{-1}P_{k|k}^{-1}=Q_k^{-1}A[P_{k|k}-P_{k|k}A^T P_{k+1|k}^{-1}AP_{k|k}]P_{k|k}^{-1}\\\\\r\n    =Q_k^{-1}A-Q_k^{-1}A P_{k|k}A^T P_{k+1|k}^{-1}A\\\\\r\n    =Q_k^{-1}A-Q_k^{-1}(P_{k+1|k}-Q_k) P_{k+1|k}^{-1}A    =P_{k+1}^{-1}A.\r\n\\end{aligned}\"/>\r\nRegarding the constant factor, one has\r\n<Latex math=\"\\begin{aligned}\r\n    p(x_{k+1}|y_{1:k+1})  =\\frac{1}{\\sqrt{(2\\pi)^n|Q_k||P_{k|k}||W|}} \\exp\\left(-\\frac{1}{2}\\|x_{k+1}-A\\hat{x}_{k|k}\\|_{P_{k+1|k}^{-1}}^2\\right)\r\n\\end{aligned}\"/>\r\nNote that\r\n<Latex math=\"\\begin{aligned}\r\n    |P_{k+1|k}|=|Q_k+AP_{k|k}A^T|\r\n    =|Q_k||I+Q_k^{-1}AP_{k|k}A^T|\\\\\r\n    =|Q_k||A^{-T}A^T+Q_k^{-1}AP_{k|k}A^T|\r\n    =|Q_k||A^{-T}+Q_k^{-1}AP_{k|k}||A^T|\\\\\r\n    =|Q_k||A^{-T}P_{k|k}^{-1}P_{k|k}+Q_k^{-1}AP_{k|k}||A^T|\\\\\r\n    =|Q_k||A^{-T}P_{k|k}^{-1}+Q_k^{-1}A||P_{k|k}||A^T|\\\\\r\n    =|Q_k||P_k||A^T||A^{-T}P_{k|k}^{-1}+Q_k^{-1}A|\\\\\r\n    =|Q_k||P_k||P_{k|k}^{-1}+A^T Q_k^{-1}A|\r\n    =|Q_k||P_{k|k}||W|.\r\n\\end{aligned}\"/>\r\nIn conclusion, one has\r\n<Latex math=\"\\begin{aligned}\r\n    p(x_{k+1}|y_{1:k+1})&=\\frac{1}{\\sqrt{(2\\pi)^n|P_{k+1|k}|}}\\exp\\left(-\\frac{1}{2}\\|x_{k+1}-A\\hat{x}_{k|k}\\|_{P_{k+1|k}^{-1}}^2\\right)\\\\\r\n    &=\\mathcal{N}(x_{k+1};A\\hat{x}_{k|k},P_{k+1|k}).\r\n\\end{aligned}\"/>\r\n<p align=\"right\"><Inline math=\"\\blacksquare\"/></p></div>\r\n<h2>Measurement-Update</h2>\r\n\r\n<a class=\"label\" id=\"app:kf.meas.update\"></a>\r\nConsider a linear measurement model in the form\r\n<Latex math=\"\\begin{aligned}\r\n    y_{k+1}=Hx_{k+1}+\\varepsilon_{k+1}\r\n\\end{aligned}\"/>\r\nwith <Inline math=\"\\varepsilon_{k+1}\\sim\\mathcal{N}(0,R_{k+1})\"/>.\r\nGiven a prior <Inline math=\"x_{k+1}\\sim\\mathcal{N}(x_{k+1};\\hat{x}_{k+1|k},P_{k+1|k})\"/> and assuming that <Inline math=\"x_{k+1}\"/> and <Inline math=\"y_{k+1}\"/> are jointly normal distributed, one find that \r\n<Latex math=\"\\begin{aligned}\r\n\tp(x_{k+1}|y_{1:k+1})&=p(x_{k+1}|y_{k+1},y_{1:k})\\\\\r\n\t&=\\frac{p(y_{k+1}|x_{k+1},y_{1:k})p(x_{k+1}|y_{1:k})}{p(y_{k+1}|y_{1:k})}\\\\\r\n\t&=\\frac{p(y_{k+1}|x_{k+1})p(x_{k+1}|y_{1:k})}{p(y_{k+1}|y_{1:k})}\\\\\r\n\t&=\\frac{p(x_{k+1},y_{k+1}|y_{1:k})}{p(y_{k+1}|y_{1:k})}\\\\&=\\frac{\\alpha_1\\exp(-\\frac{1}{2}\\|m-\\bar{m}\\|_{M^{-1}}^2)}{\\alpha_2\\exp(-\\frac{1}{2}\\|y_{k+1}-\\bar{y}_{k+1}\\|_{P_{yy}^{-1}}^2)}\\\\\r\n\t&=\\alpha \\exp\\left(-\\frac{1}{2}(\\|m-\\bar{m}\\|_{M^{-1}}^2-\\|y_{k+1}-\\bar{y}_{k+1}\\|_{P_{yy}^{-1}}^2)\\right)\r\n\\end{aligned}\"/>\r\nwhere <Inline math=\"m=[x_{k+1}^T ~y_{k+1}^T]^T\"/>, <Inline math=\"\\bar{m}=[\\hat{x}_{k+1|k}^T ~\\bar{y}_{k+1}^T]^T\"/> and\r\n<Latex math=\"\\begin{aligned}\r\n    M:=\\begin{bmatrix}\r\n    P_{k+1|k} & P_{k+1|k}H^T\\\\\r\n    HP_{k+1|k} & R+HP_{k+1|k}H^T\r\n    \\end{bmatrix}.\r\n\\end{aligned}\"/>\r\nDefining\r\n<Latex math=\"\\begin{aligned}\r\n    \\xi_1&=x_{k+1}-\\hat{x}_{k+1|k},\\\\\r\n    \\xi_2&=y_{k+1}-\\bar{y}_{k+1},\r\n\\end{aligned}\"/>\r\none has\r\n<Latex math=\"\\begin{aligned}\r\n\t\\|m-\\bar{m}\\|_{M^{-1}}^2-\\|y_{k+1}-\\bar{y}_{k+1}\\|_{(R+HP_{k+1|k}H^T)^{-1}}^2=\\\\\\xi_1^T \\Sigma_{xx}\\xi_1+\\xi_1^T \\Sigma_{xy}\\xi_2+\\xi_2^T \\Sigma_{yx}\\xi_1+\\xi_2^T \\Sigma_{yy}\\xi_2-\\xi_2^T (\\Sigma_{yy}-\\Sigma_{yx}\\Sigma_{xx}^{-1}\\Sigma_{xy})\\xi_2\\\\\r\n\t=\\xi_1^T \\Sigma_{xx}\\xi_1+\\xi_1^T (\\Sigma_{xx}\\Sigma_{xx}^{-1})\\Sigma_{xy}\\xi_2+\\xi_2^T \\Sigma_{yx}(\\Sigma_{xx}^{-1}\\Sigma_{xx})\\xi_1+\\xi_2^T \\Sigma_{yx}\\Sigma_{xx}^{-1}\\Sigma_{xy}\\xi_2\\\\\r\n\t= \\|\\xi_1+\\Sigma_{xx}^{-1}\\Sigma_{xy}\\xi_2\\|_{\\Sigma_{xx}}^2\r\n\\end{aligned}\"/>\r\nwhere the following identity for the inverse of partitioned matrix is employed\r\n<Latex math=\"\\begin{aligned}\r\n\tM^{-1}=\t\\begin{bmatrix}\r\n\t\\Sigma_{xx} & \\Sigma_{xy}\\\\\r\n\t\\Sigma_{yx} & \\Sigma_{yy}\r\n\t\\end{bmatrix}\r\n\\end{aligned}\"/>\r\nwith \r\n<Latex math=\"\\begin{aligned}\r\n\t\\Sigma_{xx}&=(P_{k+1|k}-P_{k+1|k}H^T (R+HP_{k+1|k}H^T)^{-1}HP_{k+1|k})^{-1}\\\\\r\n\t\\Sigma_{xy}&=-\\Sigma_{xx}^{-1}P_{k+1|k}H^T (R+HP_{k+1|k}H^T)^{-1}\\\\\r\n\t\\Sigma_{yx}&=\\Sigma_{xy}^T\\\\\r\n\t\\Sigma_{yy}&=R^{-1}\r\n\\end{aligned}\"/>\r\nIn addition, note that the following relations hold \r\n<p></p>\r\n<Latex math=\"\\begin{aligned}\r\n\t\\Sigma_{xx}^{-1}\\Sigma_{xy}=-P_{k+1|k}H^T (R+HP_{k+1|k}H^T)^{-1}\r\n\\end{aligned}\"/>\r\nand\r\n<Latex math=\"\\begin{aligned}\r\n(R+HP_{k+1|k}H^T)^{-1}=R^{-1}-\\Sigma_{yx}\\Sigma_{xx}^{-1}\\Sigma_{xy}\r\n\\end{aligned}\"/>\r\nThereafter, one concludes that the posterior <Inline math=\"p(x_{k+1}|y_{1:k+1})\"/> is also Gaussian distributed. Which implies that\r\n<Latex math=\"\\begin{aligned}\r\n\t\\hat{x}_{k+1|k+1}&=\\hat{x}_{k+1|k}+K(y_{k+1}-H\\hat{x}_{k+1|k})\\\\\r\n\tK&=P_{k+1|k}H^T (R+HP_{k+1|k}H^T)^{-1}\\\\\r\n\tP_{k+1|k+1}&=\\Sigma_{xx}^{-1}=P_{k+1|k}-P_{k+1|k}H^T (R+HP_{k+1|k}H^T)^{-1}HP_{k+1|k}.\r\n\\end{aligned}\"/>\r\nMoreover, note that\r\n<Latex math=\"\\begin{aligned}\r\n    P_{k+1|k+1}=P_{k+1|k}-P_{k+1|k}H^T (R+HP_{k+1|k}H^T)^{-1}HP_{k+1|k}\\\\\r\n    =P_{k+1|k}-KHP_{k+1|k}=(I-KH)P_{k+1|k}\r\n\\end{aligned}\"/>\r\nwhich concludes the derivation.\r\n<h2>Gaussian Identities</h2>\r\n\r\n<div class='itemize'><lu>\r\n    <li> <b>Product:</b></li>\r\n<Latex math=\"\\begin{aligned}\r\n    \\mathcal{N}(x;a,A)\\mathcal{N}(x;b,B)=\\mathcal{N}(x;c,C)\\mathcal{N}(a;b,A+B)\r\n\\end{aligned}\"/>\r\nwhere\r\n<Latex math=\"\\begin{aligned}\r\n    C&=(A^{-1}+B^{-1})^{-1}\\\\\r\n    c&=C(A^{-1}a+B^{-1}b)\r\n\\end{aligned}\"/>\r\n<p></p>\r\nLet \r\n<Latex math=\"\\begin{aligned}\r\np(x,y)=\\mathcal{N}\\left(\\begin{bmatrix}x\\\\y\r\n    \\end{bmatrix};\\begin{bmatrix}\\mu_x\\\\\\mu_y\r\n    \\end{bmatrix},\\begin{bmatrix}\\Sigma_x & \\Sigma_{xy}\\\\\\Sigma_{yx} & \\Sigma_y\r\n    \\end{bmatrix}\\right).\r\n\\end{aligned}\"/>\r\n<p></p>\r\n<li> <b>Marginal</b></li>\r\n<Latex math=\"\\begin{aligned}\r\n    \\int \\mathcal{N}\\left(\\begin{bmatrix}x\\\\y\r\n    \\end{bmatrix};\\begin{bmatrix}\\mu_x\\\\\\mu_y\r\n    \\end{bmatrix},\\begin{bmatrix}\\Sigma_x & \\Sigma_{xy}\\\\\\Sigma_{yx} & \\Sigma_y\r\n    \\end{bmatrix}\\right)dy=\\mathcal{N}(x;\\mu_x,\\Sigma_x)\r\n\\end{aligned}\"/>\r\nand\r\n<Latex math=\"\\begin{aligned}\r\n    \\int \\mathcal{N}\\left(\\begin{bmatrix}x\\\\y\r\n    \\end{bmatrix};\\begin{bmatrix}\\mu_x\\\\\\mu_y\r\n    \\end{bmatrix},\\begin{bmatrix}\\Sigma_x & \\Sigma_{xy}\\\\\\Sigma_{yx} & \\Sigma_y\r\n    \\end{bmatrix}\\right)dx=\\mathcal{N}(y;\\mu_y,\\Sigma_y)\r\n\\end{aligned}\"/>\r\n<li> <b>Conditional</b></li>\r\n<Latex math=\"\\begin{aligned}\r\n    p(x|y)=\\frac{p(x,y)}{p(y)}=\\mathcal{N}(x;\\mu_x+\\Sigma_{xy}\\Sigma_y^{-1}(y-\\mu_y),\\Sigma_x-\\Sigma_{xy}\\Sigma_y^{-1}\\Sigma_{yx})\r\n\\end{aligned}\"/>\r\n<li> <b>Projection</b></li>\r\n<Latex math=\"\\begin{aligned}\r\n    p(z)=\\mathcal{N}(z;\\mu,\\Sigma)\\Rightarrow p(Az)=\\mathcal{N}(Az;A\\mu,A\\Sigma A^T)\r\n\\end{aligned}\"/>\r\n<li> <b>Integral of the (linear) product</b></li>\r\n<Latex math=\"\\begin{aligned}\r\n    \\int \\mathcal{N}(y;Ax,\\Sigma_y)\\mathcal{N}(x;\\mu_x,\\Sigma_x)dx = \\mathcal{N}(x;A\\mu_x,A\\Sigma_xA^T+\\Sigma_y)\r\n\\end{aligned}\"/>\r\n<li> <b>Integral of the (disturbed) product</b></li>\r\n<Latex math=\"\\begin{aligned}\r\n    \\int \\mathcal{N}(y;h(x)+\\xi,\\Sigma_y)\\mathcal{N}(\\xi;\\mu_\\xi,\\Sigma_\\xi)d\\xi = \\mathcal{N}(y;h(x)+\\mu_\\xi,\\Sigma_y+\\Sigma_\\xi)\r\n\\end{aligned}\"/>\r\n<p></p>\r\n<li> <b>Joint</b> </li>\r\n<p></p>\r\nConsider\r\n<Latex math=\"\\begin{aligned}\r\n    x&\\sim\\mathcal{N}(\\mu_x,P_x)\\\\\r\n    y|x&\\sim\\mathcal{N}(Hx+b,R)\r\n\\end{aligned}\"/>\r\nThus,\r\n<Latex math=\"\\begin{aligned}\r\n    p(x,y)=p(y|x)p(x)=\\mathcal{N}\\left(\\begin{bmatrix}x\\\\y\r\n    \\end{bmatrix};\\begin{bmatrix}\\mu_x\\\\H\\mu_x+b\r\n    \\end{bmatrix},\\begin{bmatrix}P_x & PH^T\\\\HP & R+HP_xH^T\r\n    \\end{bmatrix}\\right).\r\n\\end{aligned}\"/>\r\n</lu></div>\r\n<h2>Woodbury matrix Identity</h2>\r\n\r\n<Latex math=\"\\begin{aligned}\r\n    [A+UCV]^{-1}=A^{-1}-A^{-1}U[C^{-1}+VA^{-1}U]^{-1}VA^{-1}\r\n\\end{aligned}\"/>\r\n<p></p>\r\n<h2>Partitioned Inverse</h2>\r\n\r\n<Latex math=\"\\begin{aligned}\r\n\t\\left[\r\n\t\\begin{matrix}\r\n\tP_{xx} & P_{xy}\\\\\r\n\tP_{yx} & P_{yy}\r\n\t\\end{matrix}\r\n\t\\right]^{-1}&=\\left[\r\n\t\\begin{matrix}\r\n\t(P_{xx}-P_{xy}P_{yy}^{-1}P_{yx})^{-1} & -(P_{xx}-P_{xy}P_{yy}^{-1}P_{yx})^{-1}P_{xy}P_{yy}^{-1}\\\\\r\n\t-P_{yy}^{-1}P_{yx}(P_{xx}-P_{xy}P_{yy}^{-1}P_{yx})^{-1} & (P_{yy}-P_{yx}P_{xx}^{-1}P_{xy})^{-1}\r\n\t\\end{matrix}\r\n\t\\right]\\\\\r\n\t&=\\left[\r\n\t\\begin{matrix}\r\n\t\\Sigma_{xx} & \\Sigma_{xy}\\\\\r\n\t\\Sigma_{yx} & \\Sigma_{yy}\r\n\t\\end{matrix}\r\n\t\\right]\r\n\\end{aligned}\"/>\r\nIn addition, note that the following relations hold \r\n<p></p>\r\n<Latex math=\"\\begin{aligned}\r\n\t\t\\Sigma_{xy}&=-\\Sigma_{xx}P_{xy}P_{yy}^{-1}\\\\\r\n\t\t\\Rightarrow &\\Sigma_{xx}^{-1}\\Sigma_{xy}=-P_{xy}P_{yy}^{-1}.\r\n\\end{aligned}\"/>\r\nand\r\n<Latex math=\"\\begin{aligned}\r\n\\Sigma_{yy}&=P_{yy}^{-1}+P_{yy}^{-1}P_{yx}\\Sigma_{xx}P_{xy}P_{yy}^{-1}\\\\\r\n&=P_{yy}^{-1}+\\Sigma_{yx}\\Sigma_{xx}^{-1}\\Sigma_{xy}\\\\\r\n\\Rightarrow & P_{yy}^{-1}=\\Sigma_{yy}-\\Sigma_{yx}\\Sigma_{xx}^{-1}\\Sigma_{xy}.\r\n\\end{aligned}\"/>\r\n\r\n                    </div>\r\n                    <Disqus.DiscussionEmbed shortname={disqusShortname} config={disqusConfig} />\r\n                    </article>\r\n                    }\r\n                    export default IntroKalmanFilter;","import React from 'react';\r\nimport Helmet from 'react-helmet';\r\nimport '../../../Components/Pages/Tutorials.css';\r\nimport { BlockMath } from 'react-katex';\r\nimport Inline from '../../../Components/Latex/Inline';\r\nimport Latex from '../../../Components/Latex/latex';\r\nimport '../../../../node_modules/katex/dist/katex.css';\r\nimport Image from '../../../Components/Image/Image';\r\nimport Disqus from 'disqus-react';\r\nconst KalmanSmoothing = (props) => {\r\nconst disqusShortname = 'marofe-github-io';\r\nconst disqusConfig = {\r\n        url: 'https://marofe.github.io/?p='+props.note.link,\r\n        identifier: 'note-'+props.note.link,\r\n        title: props.title\r\n    };\r\nreturn <article>\r\n      <Helmet>\r\n        <title>{props.note.title} | Marofe</title>\r\n        <meta name=\"description\" content={props.note.desc} />\r\n    </Helmet>\r\n    <h1>{props.title}</h1>\r\n<p>{props.desc}</p>\r\n    <p align=\"right\">Last Update:  September 19, 2021.</p>\r\n<div>\r\n<h2>Introduction</h2>\r\n\r\nSometimes it is also of interest to estimate states for each time step conditional on all the measurements that we have obtained. This problem can be solved with Bayesian smoothing. In this note, the Bayesian theory of smoothing is presented. After that, the Rauch-Tung-Striebel (RTS) smoother, which is the closed form smoothing solution to linear Gaussian models, is derived.\r\n<h2>Smoother</h2>\r\n\r\nThe purpose of Bayesian smoothing is to compute the marginal posterior distribution of the state <Inline math=\"x_k\"/> at the time step <Inline math=\"k\"/> after receiving a set of measurements up to a time step <Inline math=\"T\"/>, where <Inline math=\"T> k\"/>. This pdf is denoted by <Inline math=\"p(x_k|y_{1:T})\"/>. \r\n<p></p>\r\nThe difference between filters and smoother is that the Bayesian filter computes its estimates using only the measurements obtained before and at the time step <Inline math=\"k\"/>, but the Bayesian smoother uses also the future measurements for computing its estimates <a href=\"#cite.sarkka2013\">sarkka2013</a>.\r\n<div class='theorem'><b>Theorem:</b><br/>\r\nThe backward recursive equations for computing the smoothed distributions <Inline math=\"p(x_k|y_{1:T})\"/> for any <Inline math=\"k<T\"/> are \r\n<Latex math=\"\\begin{aligned}\r\np(x_k|y_{1:T})&=p(x_{k}|y_{1:k})\\int \\frac{p(x_{k+1}|x_{k})p(x_{k+1}|y_{1:T})}{p(x_{k+1}|y_{1:k})}dx_{k+1}\r\n\\end{aligned}\"/>\r\nwhere <Inline math=\"p(x_k|y_{1:k})\"/> is the filtering distribution and <Inline math=\"p(x_{k+1}|y_{1:k})\"/> is the predictive distribution one-step ahead, given by the Chapman-Komogorov Equation,\r\n<Latex math=\"\\begin{aligned}\r\n    p(x_{k+1}|y_{1:k})=\\int p(x_{k+1}|x_k)p(x_k|y_{1:k})dx_k.\r\n\\end{aligned}\"/>\r\n</div>\r\n<div class='proof'><b>Proof:</b><br/>\r\nNote that\r\n<Latex math=\"\\begin{aligned}\r\n    p(x_k,x_{k+1}|y_{1:T})=p(x_k|x_{k+1},y_{1:T})p(x_{k+1}|y_{1:T})\r\n\\end{aligned}\"/>\r\nDue to the Markov properties of the state <Inline math=\"x_k\"/>, one has <Inline math=\"p(x_k|x_{k+1},y_{1:T})=p(x_k|x_{k+1},y_{1:k})\"/> and <Inline math=\"p(x_{k+1}|x_k,y_{1:k})=p(x_{k+1}|x_k)\"/>, thus,\r\n<Latex math=\"\\begin{aligned}\r\n    p(x_k,x_{k+1}|y_{1:T})=p(x_k|x_{k+1},y_{1:k})p(x_{k+1}|y_{1:T})\\\\\r\n    =\\frac{p(x_{k+1}|x_k)p(x_k|y_{1:k})}{p(x_{k+1}|y_{1:k})}p(x_{k+1}|y_{1:T})\r\n\\end{aligned}\"/>\r\nAs <Inline math=\"p(x_k|y_{1:T})=\\int p(x_k,x_{k+1}|y_{1:T})dx_{k+1}\"/>, one concludes\r\n<Latex math=\"\\begin{aligned}\r\n    p(x_k|y_{1:T})=\\int\\frac{p(x_{k+1}|x_k)p(x_k|y_{1:k})}{p(x_{k+1}|y_{1:k})}p(x_{k+1}|y_{1:T})dx_{k+1}\\\\\r\n    =p(x_k|y_{1:k})\\int\\frac{p(x_{k+1}|x_k)p(x_{k+1}|y_{1:T})}{p(x_{k+1}|y_{1:k})}dx_{k+1}.\r\n\\end{aligned}\"/>\r\n<p align=\"right\"><Inline math=\"\\blacksquare\"/></p></div>\r\nNote that by starting at <Inline math=\"k=T-1\"/>, one has\r\n<Latex math=\"\\begin{aligned}\r\n    p(x_{T-1}|y_{1:T})=p(x_{T-1}|y_{1:T-1})\\int \\frac{p(x_T|x_{T-1})p(x_T|y_{1:T})}{p(x_T|y_{1:T-1})}dx_T\r\n\\end{aligned}\"/>\r\nTherefore, given <Inline math=\"p(x_T|y_{1:T})\"/> (last filtering distribution), one can solve the smoothing problem for all <Inline math=\"k=T-1,T-2,\\ldots,1\"/> running backward in time.\r\n<h2>RTS</h2>\r\n\r\nThe Rauch-Tung-Striebel (RTS) smoother, which is also called the Kalman smoother, can be used for computing the closed form smoothing solution for linear and Gaussian systems.\r\n<div class='theorem'><b>Theorem:</b><br/>\r\nThe backward recursion equations for the (fixed interval) Rauch-Tung-Striebel smoother for a linear and Gaussian system are given as,\r\n<Latex math=\"\\begin{aligned}\r\n    \\hat{x}_{k+1|k}&=A\\hat{x}_{k|k}\\\\\r\n    P_{k+1|k}&=AP_{k|k}A^T+Q_k\\\\\r\n    G_k&=P_{k|k}A^T P_{k+1|k}^{-1}\\\\\r\n    \\hat{x}_k^s&=\\hat{x}_{k|k}+G_k(\\hat{x}_{k+1}^s-\\hat{x}_{k+1|k})\\\\\r\n    P_{k}^s&=P_{k|k}-G_k(P_{k+1}^s-P_{k+1|k})G_k^T\r\n\\end{aligned}\"/>\r\nwhere <Inline math=\"\\{\\hat{x}_{k|k},P_{k|k}\\}\"/> are the mean and covariance computed by the Kalman Filter.\r\n</div>\r\n<div class='proof'><b>Proof:</b><br/>\r\nFirst, consider the following auxiliary lemma,\r\n<div class='lemma'><b>Lemma:</b><br/>\r\n<a class=\"label\" id=\"lemma:aux1\"></a>\r\nIf two random variables <Inline math=\"x\\in\\mathbb{R}^n\"/> and <Inline math=\"y\\in\\mathbb{R}^m\"/> have Gaussian distributions in the form\r\n<Latex math=\"\\begin{aligned}\r\n    x&\\sim \\mathcal{N}(\\mu_x,P_x)\\\\\r\n    y|x&\\sim\\mathcal{N}(Hx,P_{y|x})\r\n\\end{aligned}\"/>\r\nThus, the joint distribution of <Inline math=\"x\"/> and <Inline math=\"y\"/> is given by\r\n<Latex math=\"\\begin{aligned}\r\n    p(x,y)=\\mathcal{N}\\left(\r\n    \\begin{bmatrix}\r\n    \\mu_x\\\\\r\n    H\\mu_x\r\n    \\end{bmatrix};\\begin{bmatrix}\r\n    P_x & P_xH^T \\\\\r\n    HP_x & P_{y|x}+HP_xH^T \r\n    \\end{bmatrix}\r\n    \\right)\r\n\\end{aligned}\"/>\r\n</div>\r\n<div class='proof'><b>Proof:</b><br/>\r\nSee <a href=\"#cite.sarkka2013\">sarkka2013</a>.\r\n<p align=\"right\"><Inline math=\"\\blacksquare\"/></p></div>\r\nAccordingly, one can state,\r\n<Latex math=\"\\begin{aligned}\r\n    x_{k}|y_{1:k}&\\sim\\mathcal{N}(\\hat{x}_{k|k},P_{k|k})\\\\\r\n    x_{k+1}|x_{k}&\\sim \\mathcal{N}(Ax_k,Q_k)\r\n\\end{aligned}\"/>\r\nand from <a href=\"#emma:aux1\">lemma:aux1</a> one has\r\n<Latex math=\"\\begin{aligned}\r\n    p(x_k,x_{k+1}|y_{1:k})=\\mathcal{N}\\left(\r\n    \\begin{bmatrix}\r\n    \\hat{x}_{k|k}\\\\\r\n    A\\hat{x}_{k|k}\r\n    \\end{bmatrix};\\begin{bmatrix}\r\n    P_{k|k} & P_{k|k}A^T \\\\\r\n    AP_{k|k} & AP_{k|k}A^T +Q_k\r\n    \\end{bmatrix}\r\n    \\right).\r\n\\end{aligned}\" label=\"eq:joint.predictive.dist\"/>\r\nNow, consider a second auxiliary lemma.\r\n<div class='lemma'><b>Lemma:</b><br/>\r\n<a class=\"label\" id=\"lemma:aux2\"></a>\r\nIf two random variables have joint Gaussian distribution in the form\r\n<Latex math=\"\\begin{aligned}\r\n    p(x,y)=\\mathcal{N}\\left(\r\n    \\begin{bmatrix}\r\n    \\mu_x\\\\\r\n    \\mu_y\r\n    \\end{bmatrix};\\begin{bmatrix}\r\n    P_x & P_{xy} \\\\\r\n    P_{yx} & P_y\r\n    \\end{bmatrix}\r\n    \\right)\r\n\\end{aligned}\"/>\r\nThus,\r\n<Latex math=\"\\begin{aligned}\r\n    p(x|y)&=\\mathcal{N}(\\mu_x+P_{xy}P_y^{-1}(y-\\mu_y),P_x-P_{xy}P_y^{-1}P_{yx})\\\\\r\n    p(y|x)&=\\mathcal{N}(\\mu_y+P_{yx}P_x^{-1}(x-\\mu_x),P_y-P_{yx}P_x^{-1}P_{xy})\r\n\\end{aligned}\"/>\r\n</div>\r\nTherefore, from <a href=\"#q:joint.predictive.dist\">eq:joint.predictive.dist</a>, one has\r\n<Latex math=\"\\begin{aligned}\r\n    p(x_k|x_{k+1},y_{1:k})=\\mathcal{N}(\\hat{x}_{k|k}+G_k(x_{k+1}-\\hat{x}_{k+1|k}),P_{k|k}-G_kP_{k+1|k}G_k^T)\r\n\\end{aligned}\"/>\r\nNote that we have\r\n<Latex math=\"\\begin{aligned}\r\n    x_{k+1}|y_{1:T}&\\sim\\mathcal{N}(\\hat{x}_{k+1}^s,P_{k+1}^s)\\\\\r\n    x_k|x_{k+1},y_{1:k}&\\sim\\mathcal{N}(\\hat{x}_{k|k}+G_k(x_{k+1}-\\hat{x}_{k+1|k}),P_{k|k}-G_kP_{k+1|k}G_k^T)\r\n\\end{aligned}\"/>\r\nTherefore, using again <a href=\"#emma:aux1\">lemma:aux1</a>, one gets\r\n<Latex math=\"\\begin{aligned}\r\n p(x_k,x_{k+1}|y_{1:T})=   \\mathcal{N}\\left(\r\n    \\begin{bmatrix}\r\n    \\hat{x}_{k+1}^s\\\\\r\n    \\hat{x}_{k}^s\r\n    \\end{bmatrix};\\begin{bmatrix}\r\n    P_{k+1}^s & P_{k+1}^sG^T \\\\\r\n    GP_{k+1}^s & P_{k}^s\r\n    \\end{bmatrix}\r\n    \\right)\r\n\\end{aligned}\"/>\r\nFinally, taking <Inline math=\"p(x_k|y_{1:T})=\\int p(x_k,x_{k+1}|y_{1:T})dx_{k+1}\"/> one conclude that <Inline math=\"p(x_k|y_{1:T})=\\mathcal{N}(\\hat{x}^s,P_{k}^s)\"/> where <Inline math=\"\\hat{x}_k^s=\\hat{x}_{k|k}+G_k(\\hat{x}_{k+1}^s-\\hat{x}_{k+1|k})\"/> and <Inline math=\"P_{k}^s=P_{k|k}-G_k(P_{k+1}^s-P_{k+1|k})G_k^T\"/>.\r\n<p align=\"right\"><Inline math=\"\\blacksquare\"/></p></div>\r\n\r\n                    </div>\r\n                    <Disqus.DiscussionEmbed shortname={disqusShortname} config={disqusConfig} />\r\n                    </article>\r\n                    }\r\n                    export default KalmanSmoothing;","import React from 'react';\r\nimport Helmet from 'react-helmet';\r\nimport '../../../Components/Pages/Tutorials.css';\r\nimport { BlockMath } from 'react-katex';\r\nimport Inline from '../../../Components/Latex/Inline';\r\nimport Latex from '../../../Components/Latex/latex';\r\nimport '../../../../node_modules/katex/dist/katex.css';\r\nimport Image from '../../../Components/Image/Image';\r\nimport Disqus from 'disqus-react';\r\nconst ClassicEstimation = (props) => {\r\nconst disqusShortname = 'marofe-github-io';\r\nconst disqusConfig = {\r\n        url: 'https://marofe.github.io/?p='+props.note.link,\r\n        identifier: 'note-'+props.note.link,\r\n        title: props.title\r\n    };\r\nreturn <article>\r\n      <Helmet>\r\n        <title>{props.note.title} | Marofe</title>\r\n        <meta name=\"description\" content={props.note.desc} />\r\n    </Helmet>\r\n    <h1>{props.title}</h1>\r\n<p>{props.desc}</p>\r\n    <p align=\"right\">Last Update:  September 19, 2021.</p>\r\n<div>\r\n<h2>Introduction</h2>\r\n\r\nThe main goal is to convey the knowledge necessary for the design and evaluation of state estimation algorithms that operate in a stochastic environment. These algorithms form the backbone of <i>information extraction systems</i>. The following sections are based on <a href=\"#cite.Bar-Shalom2001\">Bar-Shalom2001</a>\r\n<h2>Estimation Problem</h2>\r\n\r\nEstimation is the process of inferring the value of a quantity of interest from indirect, inaccurate and uncertain observations. Some cases are parameter identification, state estimation and stochastic control of partial observed systems.\r\n<p></p>\r\nOther scenario is the determination of model parameters for predicting the state of a physical system or forecasting economic or other variables. As well the determination of the characteristics of a transmitted message from noise-corrupted channels.\r\n<p></p>\r\nRecently, the state estimation techniques have been gaining wider attention due to their applicability to such fields as robotics, computer vision for autonomous navigation, and image feature extraction with application to medical diagnosis.\r\n<p></p>\r\nAn optimal estimator is a computational algorithm that processes observations (measurements) to yield an estimate of a variable of interest, which optimizes a certain criterion.\r\n<p></p>\r\nIn general, one can classify the variable that is to be estimated into the following two categories: <i>parameter</i> for static problems or <i>state vector</i> for dynamic systems. Consequently, one has two classes of estimators: <i>Parameter Estimators</i> and <i>State Estimators</i>.\r\n<p></p>\r\nGauss made the following (philosophical) observations on the (physical) observations that could be made on the planetary motion:\r\n<div class='itemize'><lu>\r\n\t<li> If the observations were absolutely correct, the parameters could be determined with perfect accuracy from a minimum number of observations (n observations for n parameters);</li>\r\n\t\r\n\t<li> Then subsequent observations would confirm, but not correct, the values obtained for the parameters;</li>\r\n\t\r\n\t<li> But, since the observations are only approximations of the truth, we should combine more observations than the minimum to determine more accurately the unknown quantities;</li>\r\n\t\r\n\t<li> Thus, starting with approximate knowledge, we can correct it with subsequent observations so as to satisfy all the observations in the most accurate manner possible;</li>\r\n</lu></div>\r\n<p></p>\r\n<h2>Parameter Estimation</h2>\r\n\r\nParameter estimations is special case also called <i>static estimation problem</i>. The term <i>parameter</i> is used to designate a quantity (scalar or vector valued) that is assumed to be <i>time invariant</i>. The problem of estimating a time invariant parameter <Inline math=\"x\"/> is the following. Given the measurements\r\n<Latex math=\"\\begin{aligned}\r\nz(j)=h_j(x,\\varepsilon(j)),\\quad j=1,\\ldots,k\r\n\\end{aligned}\"/>\r\nmade in presence of the disturbances (noises) <Inline math=\"\\varepsilon(j)\"/>, find a function of the <Inline math=\"k\"/> observations\r\n<Latex math=\"\\begin{aligned}\r\n\\hat{x}(k)\\equiv \\hat{x}(k,Z^k)\r\n\\end{aligned}\" label=\"eq:estimator\"/>\r\nwhere these observations are denoted compactly as <Inline math=\"Z^k=\\{z(j)\\}_{j=1}^k\"/> that estimates the value of <Inline math=\"x\"/> in some sense. The function <a href=\"#eq:estimator\">eq:estimator</a> is called the <i>estimator</i>. The value of this function is the <i>estimate</i>.\r\n<p></p>\r\nThe <i>estimation error</i> corresponding to the estimate <Inline math=\"\\hat{x}\"/> is\r\n<Latex math=\"\\begin{aligned}\r\n \\tilde{x}=x-\\hat{x}\r\n\\end{aligned}\"/>\r\n<p></p>\r\nOne can approach the estimation problem through at least three ways. First, assuming that <Inline math=\"x\"/> is non-stochastic and only the measurements are disturbed by some randomness. For this case, we define the <i>Likelihood</i> function\r\n<Latex math=\"\\begin{aligned}\r\n\t\\Lambda(x)\\equiv p(Z|x)\r\n\\end{aligned}\"/>\r\nas a measure of how \"likely\" a given parameter value is based on obtained observations. Thus, the Likelihood function serves as a measure of evidence from the data.\r\n<p></p>\r\nSecond, one might consider <Inline math=\"x\"/> as some random variable with <i>prior</i> distribution <Inline math=\"p(x)\"/> and then based on the measurements obtain the <i>posteriori</i> distribution following the Bayesian philosophy.\r\n<Latex math=\"\\begin{aligned}\r\n\tp(x|Z)=\\frac{1}{c}p(Z|x)p(x)\r\n\\end{aligned}\"/>\r\nThis is also called the Bayesian Approach to Estimation. \r\n<p></p>\r\nA third approach might be through some optimization process where a cost involving the estimation error is defined and the estimator is obtained in such way that minimize this cost, e.g., Least Square Estimator. \r\n<p></p>\r\n<h3>The Maximum Likelihood Estimator</h3>\r\n\r\nA common method of estimating non-random parameters is the maximum likelihood method that maximizes the likelihood function and yields the maximum likelihood estimator (MLE)\r\n<Latex math=\"\\begin{aligned}\r\n\\hat{x}^{ML}(Z)=\\arg \\max_x \\Lambda (x)\r\n\\end{aligned}\"/>\r\nNote that, while <Inline math=\"x\"/> is an unknown deterministic value, <Inline math=\"\\hat{x}^{ML}(Z)\"/> is a function of the set of random observations and, consequently, is a random variable.\r\n<p></p>\r\n<h3>The maximum A Posteriori Estimator</h3>\r\n\r\nThe counter-part MLE for a random parameter is the maximum a posteriori (MAP) estimator, which follows from the maximization of the posterior pdf\r\n<Latex math=\"\\begin{aligned}\r\n\\hat{x}^{MAP}(Z)=\\arg\\max_x p(x|Z)\r\n\\end{aligned}\"/>\r\nNote that similar to the MLE, the MAP estimator is a function of the observations set, and through them also on the realization of <Inline math=\"x\"/>, thus it is as well a random variable.\r\n<div class='remark'><b>Remark:</b><br/>\r\n\tNotice that the MLE is the MAP estimator with complete prior ignorance. In more formal way, if the prior pdf is adopted as the <i>Diffuse Distribution</i>\r\n<Latex math=\"\\begin{aligned}\r\n\t\tp(x)=\\epsilon, \\quad |x|<\\frac{1}{2\\epsilon}, \\epsilon\\rightarrow 0\r\n\\end{aligned}\"/>\r\nthen the posterior becomes proportional to its likelihood function and, thus, the MAP coincide with the MLE.\r\n<Latex math=\"\\begin{aligned}\r\n\tp(x|Z)=\\frac{p(Z|x)p(x)}{p(z)}=\\frac{p(Z|x)p(x)}{\\int p(z|x)p(x)dx} = \\frac{p(Z|x)\\epsilon}{\\int p(z|x)\\epsilon dx}\\propto p(Z|x)\r\n\\end{aligned}\"/>\r\n\t Another name for this distribution is <i>non-informative pdf</i> because it carries no information about the parameter. This provides a philosophically unifying view of the Bayesian and non-Bayesian approaches to estimation.\r\n</div>\r\n<h3>The Least Square Approach</h3>\r\n\r\nAnother common estimation procedure for nonrandom parameters is the <i>least squares</i> (LS) method. Given the measurements\r\n<Latex math=\"\\begin{aligned}\r\nz(j)=h_j(x)+\\varepsilon(j),\\quad j=1,\\ldots,k\r\n\\end{aligned}\"/>\r\nthe <i>least squares estimator</i> (LSE) of <Inline math=\"x\"/> is\r\n<Latex math=\"\\begin{aligned}\r\n\t\\hat{x}^{LS}(k)=\\arg \\min_x \\left\\{\\sum_{j=1}^k(z(j)-h(j,x))^2\\right \\}\r\n\\end{aligned}\" label=\"eq:ls_estimator\"/>\r\nIt is worth point out that this criterion <a href=\"#eq:ls_estimator\">eq:ls_estimator</a> makes no assumption about the \"measurement errors\" or \"noises\" <Inline math=\"\\varepsilon(j)\"/>. However, if these are independent and identically distributed zero-mean Gaussian random variables, that is, <Inline math=\"\\varepsilon \\sim \\mathcal{N}(0,\\sigma_z^2)\"/>, then the LSE coincides with the MLE. In other words, under these assumptions, the LS method is a \"disguised\" ML approach.\r\n<p></p>\r\n<h3>The MMSE Estimator</h3>\r\n\r\nFor random parameters, the counterpart of the LSE is the minimum mean squared error estimator (MMSE).\r\n<Latex math=\"\\begin{aligned}\r\n\t\\hat{x}^{MMSE}(Z)=\\arg \\min_{\\hat{x}} \\mathbb{E}\\{(x-\\hat{x})^2|Z\\}\r\n\\end{aligned}\"/>\r\nThe optimal solution for the MMSE is well-known given by the conditional mean of x\r\n<Latex math=\"\\begin{aligned}\r\n\t\\hat{x}^{MMSE}(Z)=\\mathbb{E}\\{x|Z\\}=\\int x p(z|Z)dx\r\n\\end{aligned}\"/>\r\nwhere the expectation is evaluated w.r.t the conditional pdf <Inline math=\"p(x|Z)\"/>. For Gaussian Noise, the MMSE coincides with the MAP estimator.\r\n<h2>Unbiased Estimators</h2>\r\n\r\n<h3>Non-random Case</h3>\r\n\r\nFor a non-random parameter <Inline math=\"x\"/>, an estimator is said to be <i>unbiased</i> if \r\n<Latex math=\"\\begin{aligned}\r\n\t\\mathbb{E}\\{\\hat{x}(k,Z^k)\\}=x_0\r\n\\end{aligned}\"/>\r\nwhere <Inline math=\"x_0\"/> is the true value of the parameter. This expectation is over the estimate, which is a random variable since it is a function of the measurements, and it is taken w.r.t the conditional pdf <Inline math=\"p(Z^k|x=x_0)\"/>.\r\n<h3>Random Case</h3>\r\n\r\nIf <Inline math=\"x\"/> is a random variable with pdf <Inline math=\"p(x)\"/>, then the unbiasedness property is written as\r\n<Latex math=\"\\begin{aligned}\r\n\t\\mathbb{E}\\{\\hat{x}(k,Z^k)\\}=\\mathbb{E}\\{x\\},\r\n\\end{aligned}\"/>\r\nwhere the expectation on the left-hand side above is w.r.t the joint pdf <Inline math=\"p(Z^k,x)\"/> and the one on the right-hand side is w.r.t <Inline math=\"p(x)\"/>.\r\n<Latex math=\"\\begin{aligned}\r\n\t\\int \\hat{x}(k,Z^k) dp(Z^k,x) = \\int x dp(x).\r\n\\end{aligned}\"/>\r\n<h3>General Case</h3>\r\n\r\nThe unbiasedness requirement can be unified by requiring that the estimation error <Inline math=\"\\tilde{x}(Z^k)=x-\\hat{x}(Z^k)\"/> be zero-mean, that is\r\n<Latex math=\"\\begin{aligned}\r\n\t\\mathbb{E}\\{\\tilde{x}(Z^k)\\}=\\int (x-\\hat{x}(Z^k))dp(x,Z^k)=0.\r\n\\end{aligned}\" label=\"eq:unbiasedness\"/>\r\nThis definition covers both random and non-random cases by adopting the <i>Bayesian point of view</i> even for the non-random case, i.e., if the parameter to be estimate is known to be constant then one might set the prior <Inline math=\"p(x)=\\delta (x-x_0)\"/>, which results in <Inline math=\"p(x,Z^k)=p(Z^k|x)p(x)=p(Z^k|x=x_0)\"/>.\r\n<p></p>\r\nAnother representation for the unbiasedness property based on the <i>Law of Total Probability</i> is\r\n<Latex math=\"\\begin{aligned}\r\n\t\\mathbb{E}\\{\\mathbb{E}\\{x-\\hat{x}(Z^k)|x\\}\\}=0.\r\n\\end{aligned}\"/>\r\n<p></p>\r\n<p></p>\r\nBesides, an estimator is said to be unbiased if <a href=\"#eq:unbiasedness\">eq:unbiasedness</a> holds for all <Inline math=\"k\"/> and is said to be <i>asymptotically unbiased</i> if it holds in the limit as <Inline math=\"k\\rightarrow \\infty\"/>. \r\n<h2>Variance and MSE</h2>\r\n\r\n<h3>Non-random Case</h3>\r\n\r\nFor a non-random parameter <Inline math=\"x\"/>, the unbiased estimator <Inline math=\"\\hat{x}(Z)\"/> has variance defined by\r\n<Latex math=\"\\begin{aligned}\r\n\t\\text{var}(\\hat{x}(Z))=\\mathbb{E}\\{(\\hat{x}(Z)-x_0)^2\\},\r\n\\end{aligned}\"/>\r\nwhere <Inline math=\"x_0\"/> is the true value of the parameter and the averaging is over the measurement set <Inline math=\"Z\"/>. \r\n<p></p>\r\nHowever, if the estimator is biased (<Inline math=\"\\mathbb{E}\\{\\hat{x}\\}\\neq x_0\"/>), then\r\n<Latex math=\"\\begin{aligned}\r\n\t\t\\text{var}(\\hat{x})&=\\mathbb{E}\\{(\\hat{x}(Z)-\\mathbb{E}\\{\\hat{x}(Z)\\})^2\\}\\\\\r\n\t\t&=\\mathbb{E}\\{(\\hat{x}(Z)-x_0-b)^2\\}\\\\\r\n\t\t&=\\mathbb{E}\\{(\\tilde{x}-b)^2\\}=\\mathbb{E}\\{\\tilde{x}^2-2\\tilde{x}b+b^2\\}\\\\\r\n\t\t&=MSE(\\hat{x})-b^2.\r\n\\end{aligned}\"/>\r\nwhere <Inline math=\"MSE(\\hat{x})\\equiv \\mathbb{E}\\{(\\hat{x}-x_0)^2\\}\"/> is the Estimator <i>Mean Error Squared</i> (MSE). Notice that the MSE is equal to variance plus bias squared\r\n<Latex math=\"\\begin{aligned}\r\n\tMSE(\\hat{x})=\\text{var}(\\hat{x})+b^2.\r\n\\end{aligned}\"/>\r\n<div class='remark'><b>Remark:</b><br/>\r\nThe <i>error variance</i> of an estimator is\r\n<Latex math=\"\\begin{aligned}\r\n\t\\text{var}(\\tilde{x})=\\mathbb{E}\\{(\\tilde{x}-\\mathbb{E}\\{\\tilde{x}\\})^2\\}.\r\n\\end{aligned}\"/>\r\nIf the  estimator is unbiased, i.e. <Inline math=\"\\mathbb{E}\\{\\tilde{x}\\}=0\"/>, then\r\n<Latex math=\"\\begin{aligned}\r\n\\text{var}(\\tilde{x})=MSE(\\hat{x})=\\mbox{var}(\\hat{x})\r\n\\end{aligned}\"/>\r\nOtherwise, \r\n<Latex math=\"\\begin{aligned}\r\n\\text{var}(\\tilde{x})=\\mathbb{E}\\{(\\tilde{x}-b)^2\\}=MSE(\\hat{x})-b^2=\\mbox{var}(\\hat{x}(Z)).\r\n\\end{aligned}\"/>\r\ntherefore, the <i>error variance</i> always coincides with the <i>estimator variance</i>.\r\n</div>\r\n<h3>Random Case</h3>\r\n\r\nFor a random parameter <Inline math=\"x\"/>, the Bayesian estimator has <i>unconditional MSE</i> given by\r\n<Latex math=\"\\begin{aligned}\r\n\tMSE(\\hat{x}(Z))\\equiv \\mathbb{E}\\{(x-\\hat{x}(Z))^2\\}\r\n\\end{aligned}\"/>\r\nwhere the averaging is w.r.t the joint pdf <Inline math=\"p(x,Z)\"/>. Using the iterate property of expectation, one has\r\n<Latex math=\"\\begin{aligned}\r\n\t\tMSE(\\hat{x}(Z))= \\mathbb{E}\\{\\mathbb{E}\\{(x-\\hat{x}(Z))^2|Z\\}\\}=\\mathbb{E}\\{MSE(\\hat{x}(Z)|Z)\\}\r\n\\end{aligned}\"/>\r\nwhere <Inline math=\"MSE(\\hat{x}(Z)|Z)\"/> is the <i>conditional MSE</i>, i.e., for a given realization of observations <Inline math=\"Z\"/>. For the MMSE, the conditional MSE is\r\n<Latex math=\"\\begin{aligned}\r\n\tMSE(\\hat{x}^{MMSE}(Z)|Z)= \\mathbb{E}\\{(x-\\mathbb{E}\\{x|Z\\})^2|Z\\}=\\text{var}(x|Z)\r\n\\end{aligned}\"/>\r\nthat is, the <i>conditional variance</i> of <Inline math=\"x\"/> given <Inline math=\"Z\"/>.\r\n<div class='remark'><b>Remark:</b><br/>\r\n\tNotice that the optimal Bayesian estimator <Inline math=\"\\mathbb{E}\\{x|Z\\}\"/> is also unbiased <Inline math=\"\\mathbb{E}\\{\\mathbb{E}\\{x|Z\\}\\}=\\mathbb{E}\\{x\\}\"/>.\r\n</div>\r\n<p></p>\r\n<h2>Cram�r Rao Low Bound</h2>\r\n\r\n<h3>Unbiased case</h3>\r\n\r\nConsider an scalar estimation problem where a non-random parameter <Inline math=\"x\"/> is inferred with an unbiased estimator <Inline math=\"\\hat{x}(Z)\"/>, the variance is bounded from below as follows\r\n<Latex math=\"\\begin{aligned}\r\n\\mathbb{E}\\{(\\hat{x}(Z)-x_0)^2\\}\\ge J^{-1}\r\n\\end{aligned}\"/>\r\nwhere the expectation is w.r.t <Inline math=\"Z\"/> and <Inline math=\"J\"/> is the <i>Fisher Information</i> defined as\r\n<Latex math=\"\\begin{aligned}\r\nJ\\equiv \\left.-\\mathbb{E}\\left\\{\\frac{\\partial^2 \\ln \\Lambda(x)}{\\partial x^2}\\right\\}\\right|_{x=x_0}=\\left.\\mathbb{E}\\left\\{\\left[\\frac{\\partial \\ln \\Lambda(x)}{\\partial x}\\right]^2\\right\\}\\right|_{x=x_0}\r\n\\end{aligned}\"/>\r\nwhere <Inline math=\"\\Lambda(x)=p(Z|x)\"/> is the likelihood function.  Notice that the Fisher Information has two forms, one with first partial derivative and another with second partial derivatives.\r\n<p></p>\r\nFor a multidimensional problem and a non-random vector-valued parameter, the covariance matrix of an unbiased estimator is bounded from below as follows\r\n<Latex math=\"\\begin{aligned}\r\n\\mathbb{E}\\{(\\hat{x}(Z)-x_0)(\\hat{x}(Z)-x_0)^T \\} \\ge J^{-1}\r\n\\end{aligned}\"/>\r\nwhere the expectation is now w.r.t both <Inline math=\"x\"/> and <Inline math=\"Z\"/>. Besides, <Inline math=\"J\"/> is the <i>Fisher Information Matrix</i> given by\r\n<Latex math=\"\\begin{aligned}\r\nJ\\equiv -\\mathbb{E}\\{\\nabla_x\\nabla_x^T \\ln \\Lambda(x)\\}\\bigr |_{x=x_0} = \\mathbb{E}\\{(\\nabla_x \\ln \\Lambda(x))(\\nabla_x \\ln \\Lambda(x))^T \\}\\bigr |_{x=x_0}\r\n\\end{aligned}\"/>\r\nand <Inline math=\"x_0\"/> is the true value of the vector parameters <Inline math=\"x\"/>. As in the scalar case, note the two forms of the Fisher Information Matrix, one with the Hessian of the log-likelihood and the other with the dyad of its gradient. \r\n<p></p>\r\nThe Fisher Information Matrix can be seen as a quantification of the maximum existing information in the data about a parameter.  Therefore, the <i>Cram�r Rao Low Bound</i> (CRLB) for an unbiased estimator is defined as the inverse of the respective Fisher Information.\r\n<Latex math=\"\\begin{aligned}\r\n\tCRLB\\equiv J^{-1}\r\n\\end{aligned}\"/>\r\n<p></p>\r\n<div class='proof'><b>Proof:</b><br/>\r\n\tLet <Inline math=\"\\hat{x}(z)\"/> be an <i>unbiased estimate of the non-random</i> real-valued parameter <Inline math=\"x\"/> based on the observation (or set of observations) denoted now as <Inline math=\"z\"/>. The likelihood function of <Inline math=\"x\"/> is then <Inline math=\"\\Lambda(x)=p(z|x)\"/>. It will be assumed that the first and second derivatives of the likelihood function w.r.t. <Inline math=\"x\"/> exists (<Inline math=\"\\Lambda(x) \\in \\mathcal{C}^2\"/>) and are absolutely integrable.\r\n\t\r\n\tFrom the unbiasedness condition on the estimate <Inline math=\"\\hat{x}(z)\"/>, one has\r\n<Latex math=\"\\begin{aligned}\r\n\t\\mathbb{E}\\{\\hat{x}(z)-x\\}=\\int_{-\\infty}^{\\infty}(\\hat{x}(z)-x)p(z|x)dz = 0\r\n\\end{aligned}\"/>\r\n\tHere the true value is denoted by <Inline math=\"x\"/> instead of <Inline math=\"x_0\"/> for simplicity. Taking the derivative w.r.t <Inline math=\"x\"/> results in\r\n<Latex math=\"\\begin{aligned}\r\n\t\\frac{d}{dx}\\int_{-\\infty}^{\\infty}(\\hat{x}(z)-x)p(z|x)dx&=\\int_{-\\infty}^{\\infty}\\frac{\\partial}{\\partial x}[(\\hat{x}(z)-x)p(z|x)]dz\\\\\r\n\t&=-\\int_{-\\infty}^{\\infty} p(z|x)dz+\\int_{-\\infty}^{\\infty}(\\hat{x}(z)-x)\\frac{\\partial p(z|x)}{\\partial x} dz\\\\\r\n\t&=0\r\n\\end{aligned}\"/>\r\n\tUsing the following identity\r\n<Latex math=\"\\begin{aligned}\r\n\t\\frac{d g(x)}{dx}=\\frac{d[\\ln g(x)]}{dx}g(x), \\quad g(x)> 0~\\forall x\r\n\\end{aligned}\" label=\"eq:identity_der\"/>\r\n\tand noticing that <Inline math=\"\\int_{-\\infty}^{\\infty}p(z|x)dz = 1\"/>, one obtain\r\n<Latex math=\"\\begin{aligned}\r\n\t\\int_{-\\infty}^{\\infty}(\\hat{x}(z)-x)\\frac{\\partial \\ln p(z|x)}{\\partial x}p(z|x)dz = 1\r\n\\end{aligned}\"/>\r\n\tRewriting the above expression as\r\n<Latex math=\"\\begin{aligned}\r\n\t\\int_{-\\infty}^{\\infty}\\left\\{(\\hat{x}(z)-x)\\sqrt{p(z|x)}\\right\\}\\left\\{\\frac{\\partial \\ln p(z|x)}{\\partial x}\\sqrt{p(z|x)}\\right\\}dz = 1\r\n\\end{aligned}\"/>\r\n\tCalling the <i>Couch-Schwarz Inequality</i> for real-valued functions, which states that\r\n<Latex math=\"\\begin{aligned}\r\n\t|\\langle f_1,f_2\\rangle|\\equiv \\int_{-\\infty}^\\infty f_1(z)f_2(z)dz \\le \\|f_1\\|\\|f_2\\|\r\n\\end{aligned}\"/>\r\n\twhere\r\n<Latex math=\"\\begin{aligned}\r\n\t\\|f_i\\| \\equiv \\sqrt{\\int_{-\\infty}^{\\infty}f_i(z)^2dz}\r\n\\end{aligned}\"/>\r\n\tone find \r\n<Latex math=\"\\begin{aligned}\r\n\t\\int_{-\\infty}^{\\infty}\\left\\{(\\hat{x}(z)-x)\\sqrt{p(z|x)}\\right\\}\\left\\{\\frac{\\partial \\ln p(z|x)}{\\partial x}\\sqrt{p(z|x)}\\right\\}dz \\le \\\\\r\n\t\\left\\{\\int_{-\\infty}^\\infty (\\hat{x}(z)-x)^2p(z|x)dz\\right\\}^{1/2}\\left\\{\\int_{-\\infty}^\\infty\\left [\\frac{\\partial \\ln p(z|x)}{\\partial x}\\right]^2p(z|x)dz\\right\\}^{1/2}\r\n\\end{aligned}\"/>\r\n\tThereafter, \r\n<Latex math=\"\\begin{aligned}\r\n\t\\left\\{\\int_{-\\infty}^\\infty (\\hat{x}(z)-x)^2p(z|x)dz\\right\\}\\left\\{\\int_{-\\infty}^\\infty\\left [\\frac{\\partial \\ln p(z|x)}{\\partial x}\\right]^2p(z|x)dz\\right\\}\\ge 1\r\n\\end{aligned}\"/>\r\n\tAs <Inline math=\"\\int g(x)p(x)dx=\\mathbb{E}\\{g(x)\\}\"/>, the above expression bring us to the definition of the Cram�r-Rao Low Bound\r\n<Latex math=\"\\begin{aligned}\r\n\t\\mathbb{E}\\{(\\hat{x}(z)-x)^2\\}\\ge \\mathbb{E}\\left\\{\\left[\\frac{\\partial \\ln\\Lambda(x)}{\\partial x}\\right]^2\\right\\}^{-1}\r\n\\end{aligned}\"/>\r\n\twhere the partial derivative is evaluated at the true value <Inline math=\"x\"/>. \r\n\t\r\n\tA second form to express the Fisher Information can be derived from the following identity\r\n<Latex math=\"\\begin{aligned}\r\n\t\\int_{-\\infty}^\\infty \\frac{\\partial p(z|x)}{\\partial x}dz = 0\r\n\\end{aligned}\"/>\r\n\twhich is a result from the fact that <Inline math=\"\\int_{-\\infty}^\\infty p(z|x)dz = 1\"/>. Applying the identity <a href=\"#eq:identity_der\">eq:identity_der</a> and taking again the partial derivative w.r.t <Inline math=\"x\"/>, one get\r\n<Latex math=\"\\begin{aligned}\r\n\t\\frac{d}{dx}\\int_{-\\infty}^\\infty \\frac{\\partial p(z|x)}{\\partial x}dz &= \\frac{d}{dx}\\int_{-\\infty}^\\infty \\frac{\\partial\\ln p(z|x)}{\\partial x}p(z|x)dz \\\\\r\n\t&=\\int_{-\\infty}^\\infty \\left[\\frac{\\partial^2\\ln p(z|x)}{\\partial x^2}p(z|x) + \\frac{\\partial\\ln p(z|x)}{\\partial x}\\frac{\\partial p(z|x)}{\\partial x}\\right]dz\\\\\r\n\t&=\\int_{-\\infty}^\\infty\\frac{\\partial^2\\ln p(z|x)}{\\partial x^2}p(z|x)dz +\\int_{-\\infty}^\\infty   \\left[\\frac{\\partial\\ln p(z|x)}{\\partial x}\\right]^2p(z|x)dz\\\\\r\n\t&=0\r\n\\end{aligned}\"/>\r\n\tThus,\r\n<Latex math=\"\\begin{aligned}\r\n\t\\mathbb{E}\\left\\{\\left[\\frac{\\partial\\ln p(z|x)}{\\partial x}\\right]^2\\right\\}=-\\mathbb{E}\\left\\{\\frac{\\partial^2\\ln p(z|x)}{\\partial x^2}\\right\\}\r\n\\end{aligned}\"/>\r\n<p align=\"right\"><Inline math=\"\\blacksquare\"/></p></div>\r\n<div class='remark'><b>Remark:</b><br/>\r\n\tRemember that the CRLB is evaluated within the true value. Beside particular cases where the Fisher Information might be independent of the <Inline math=\"x\"/>, the evaluation are done at some estimate of <Inline math=\"x\"/>. Caution has to be exercised though. Since the unavoidable estimation errors can lead a possibly incorrect value of the resulting Fisher Information <Inline math=\"J\"/>, which in general is a matrix.\r\n</div>\r\n<h4>Random case</h4>\r\n\r\nIn other hand, for a random parameter <Inline math=\"x\"/> and an unbiased estimator the variance is bounded from below as follows\r\n<Latex math=\"\\begin{aligned}\r\n\\mathbb{E}\\{(\\hat{x}(Z)-x)^2\\}\\ge J^{-1}\r\n\\end{aligned}\"/>\r\nwith\r\n<Latex math=\"\\begin{aligned}\r\nJ\\equiv -\\mathbb{E}\\left\\{\\frac{\\partial^2 \\ln p(x,Z)}{\\partial x^2}\\right\\}=\\mathbb{E}\\left\\{\\left[\\frac{\\partial \\ln p(x,Z)}{\\partial x}\\right]^2\\right\\}\r\n\\end{aligned}\"/>\r\n<p></p>\r\nA similar expression holds for the case of a multidimensional random parameter. \r\n<div class='proof'><b>Proof:</b><br/>\r\n<p></p>\r\nThis result comes from the unbiasedness property for random case\r\n<Latex math=\"\\begin{aligned}\r\n\t\\mathbb{E}\\{\\tilde{x}\\}=\\int (\\hat{x}-x)dp(Z,x)=0.\r\n\\end{aligned}\"/>\r\nTaking the derivative w.r.t <Inline math=\"x\"/> results in\r\n<Latex math=\"\\begin{aligned}\r\n\t\\frac{d}{dx}\\int_{-\\infty}^{\\infty}\\int_{-\\infty}^{\\infty}(\\hat{x}(z)-x)p(z,x)dzdx=\\int_{-\\infty}^{\\infty}\\int_{-\\infty}^{\\infty}\\frac{\\partial}{\\partial x}[(\\hat{x}(z)-x)p(z,x)]dzdx\\\\\r\n\t=-\\int_{-\\infty}^{\\infty}\\int_{-\\infty}^{\\infty} p(z,x)dzdx+\\int_{-\\infty}^{\\infty}\\int_{-\\infty}^{\\infty}(\\hat{x}(z)-x)\\frac{\\partial p(z,x)}{\\partial x} dzdx=0\r\n\\end{aligned}\"/>\r\n\tUsing the following identity\r\n<Latex math=\"\\begin{aligned}\r\n\t\\frac{\\partial g(x,z)}{\\partial x}=\\frac{\\partial[\\ln g(x,z)]}{dx}g(x,z), \\quad g(x,z)> 0~\\forall x\r\n\\end{aligned}\" label=\"eq:identity_der_joint\"/>\r\n\tand noticing that <Inline math=\"\\int_{-\\infty}^{\\infty}\\int_{-\\infty}^{\\infty}p(z,x)dzdx = 1\"/>, one obtain\r\n<Latex math=\"\\begin{aligned}\r\n\t\\int_{-\\infty}^{\\infty}\\int_{-\\infty}^{\\infty}(\\hat{x}(z)-x)\\frac{\\partial \\ln p(z,x)}{\\partial x}p(z,x)dzdx = 1\r\n\\end{aligned}\"/>\r\n\tRewriting the above expression as\r\n<Latex math=\"\\begin{aligned}\r\n\t\\int_{-\\infty}^{\\infty}\\int_{-\\infty}^{\\infty}\\left\\{(\\hat{x}(z)-x)\\sqrt{p(z,x)}\\right\\}\\left\\{\\frac{\\partial \\ln p(z,x)}{\\partial x}\\sqrt{p(z,x)}\\right\\}dzdx = 1\r\n\\end{aligned}\"/>\r\n\tCalling the <i>Couch-Schwarz Inequality</i> for real-valued functions, which states that\r\n<Latex math=\"\\begin{aligned}\r\n\t|\\langle f_1,f_2\\rangle|\\equiv \\int_\\mathcal{Z} f_1(z)f_2(z)dz \\le \\|f_1\\|\\|f_2\\|\r\n\\end{aligned}\"/>\r\n\twhere\r\n<Latex math=\"\\begin{aligned}\r\n\t\\|f_i\\| \\equiv \\sqrt{\\int_\\mathcal{Z} f_i(z)^2dz}\r\n\\end{aligned}\"/>\r\n\tone find \r\n<Latex math=\"\\begin{aligned}\r\n\t\\int_{-\\infty}^{\\infty}\\int_{-\\infty}^{\\infty}\\left\\{(\\hat{x}(z)-x)\\sqrt{p(z,x)}\\right\\}\\left\\{\\frac{\\partial \\ln p(z,x)}{\\partial x}\\sqrt{p(z,x)}\\right\\}dzdx \\le \\\\\r\n\t\\left\\{\\int_{-\\infty}^{\\infty}\\int_{-\\infty}^\\infty (\\hat{x}(z)-x)^2p(z,x)dzdx\\right\\}^{1/2}\\left\\{\\int_{-\\infty}^{\\infty}\\int_{-\\infty}^\\infty\\left [\\frac{\\partial \\ln p(z,x)}{\\partial x}\\right]^2p(z,x)dz\\right\\}^{1/2}\r\n\\end{aligned}\"/>\r\n\tThereafter, \r\n<Latex math=\"\\begin{aligned}\r\n\t\\left\\{\\int_{-\\infty}^{\\infty}\\int_{-\\infty}^\\infty (\\hat{x}(z)-x)^2p(z,x)dzdx\\right\\}\\left\\{\\int_{-\\infty}^{\\infty}\\int_{-\\infty}^\\infty\\left [\\frac{\\partial \\ln p(z,x)}{\\partial x}\\right]^2p(z,x)dzdx\\right\\}\\ge 1\r\n\\end{aligned}\"/>\r\n\tThe above expression bring us to the definition of the Cram�r-Rao Low Bound\r\n<Latex math=\"\\begin{aligned}\r\n\t\\mathbb{E}\\{(\\hat{x}(z)-x)^2\\}\\ge \\mathbb{E}\\left\\{\\left[\\frac{\\partial \\ln p(x,z)}{\\partial x}\\right]^2\\right\\}^{-1}\r\n\\end{aligned}\"/>\r\n\twhere the partial derivative are averaged w.t.t all possible values of <Inline math=\"x\"/>. \r\n\t\r\n\tA second form to express the Fisher Information can be derived from the following identity\r\n<Latex math=\"\\begin{aligned}\r\n\t\\int_{-\\infty}^{\\infty}\\int_{-\\infty}^\\infty \\frac{\\partial p(z,x)}{\\partial x}dzdx = 0\r\n\\end{aligned}\"/>\r\n\twhich is a result from the fact that <Inline math=\"\\int_{-\\infty}^{\\infty}\\int_{-\\infty}^\\infty p(z,x)dzdx = 1\"/>. Applying the identity <a href=\"#eq:identity_der_joint\">eq:identity_der_joint</a> and taking again the partial derivative w.r.t <Inline math=\"x\"/>, one get\r\n<Latex math=\"\\begin{aligned}\r\n\t\\frac{\\partial}{\\partial x}\\int_{-\\infty}^\\infty \\frac{\\partial p(z,x)}{\\partial x}dzdx = \\frac{\\partial}{\\partial x}\\int_{-\\infty}^\\infty \\frac{\\partial\\ln p(z,x)}{\\partial x}p(z,x)dzdx \\\\\r\n\t=\\int_{-\\infty}^{\\infty}\\int_{-\\infty}^\\infty \\left[\\frac{\\partial^2\\ln p(z,x)}{\\partial x^2}p(z,x) + \\frac{\\partial\\ln p(z,x)}{\\partial x}\\frac{\\partial p(z,x)}{\\partial x}\\right]dzdx\\\\\r\n\t=\\int_{-\\infty}^{\\infty}\\int_{-\\infty}^\\infty\\frac{\\partial^2\\ln p(z,x)}{\\partial x^2}p(z,x)dzdx +\\int_{-\\infty}^{\\infty}\\int_{-\\infty}^\\infty   \\left[\\frac{\\partial\\ln p(z,x)}{\\partial x}\\right]^2p(z,x)dzdx\\\\\r\n\t=0\r\n\\end{aligned}\"/>\r\n\tThus,\r\n<Latex math=\"\\begin{aligned}\r\n\t\\mathbb{E}\\left\\{\\left[\\frac{\\partial\\ln p(z,x)}{\\partial x}\\right]^2\\right\\}=-\\mathbb{E}\\left\\{\\frac{\\partial^2\\ln p(z,x)}{\\partial x^2}\\right\\}\r\n\\end{aligned}\"/>\r\n<p align=\"right\"><Inline math=\"\\blacksquare\"/></p></div>\r\n<p></p>\r\n<h3>Biased case</h3>\r\n\r\nFor estimators that are <i>biased</i>, there is a modified version of the CRLB. Consider that an estimator <Inline math=\"\\hat{x}(Z)\"/> has <i>bias function</i> <Inline math=\"b(x)\"/>\r\n<Latex math=\"\\begin{aligned}\r\n\tb(x)=\\mathbb{E}\\{\\hat{x}(Z)-x\\}\r\n\\end{aligned}\"/>\r\nThus, assuming that <Inline math=\"b(x) \\in \\mathcal{C}^1\"/>, i.e., continuously differentiable then for the scalar case one has\r\n<Latex math=\"\\begin{aligned}\r\n\t\\mathbb{E}\\{(\\hat{x}(Z)-x)^2\\}\\ge \\frac{\\frac{\\partial b}{\\partial x}+1}{\\mathbb{E}\\left\\{\\left[\\frac{\\partial \\ln p(Z,x)}{\\partial x}\\right]^2\\right\\}}\r\n\\end{aligned}\"/>\r\n<h2>Consistency and Efficiency</h2>\r\n\r\n<h3>Consistency</h3>\r\n\r\nAn estimator is said to be a <i>consistent</i> if the estimate converges to the true value in some stochastic sense. For instance,\r\n<Latex math=\"\\begin{aligned}\r\n\\lim_{k\\rightarrow \\infty} \\mathbb{E}\\{(\\hat{x}(Z)-x_0)^2\\}=0\r\n\\end{aligned}\"/>\r\nis the condition for <i>consistency in the mean square sense</i> for a non-random parameter estimator. The expectation is taken over <Inline math=\"Z^k\"/>. For a random parameter, the convergence of its estimator in the mean square sense requires\r\n<Latex math=\"\\begin{aligned}\r\n\t\\lim_{k\\rightarrow \\infty} \\mathbb{E}\\{(\\hat{x}(Z)-x)^2\\}=0\r\n\\end{aligned}\"/>\r\nwhere the expectation is over <Inline math=\"Z^k\"/> and <Inline math=\"x\"/>. In general manner, the consistency can be expressed as the requirement that the estimation error converge to zero, that is,\r\n<Latex math=\"\\begin{aligned}\r\n\t\t\\lim_{k\\rightarrow \\infty} \\tilde{x}(k,Z^k)=0\r\n\\end{aligned}\"/>\r\nin some stochastic sense. Thus, the consistency is a asymptotic property, i.e. , it is defined for the case when the sample size tends to infinity and the object of estimation is static.\r\n<div class='remark'><b>Remark:</b><br/>\r\n\tA necessary condition for an estimator to be consistent in mean square sense is that there must be an increasing amount of information (in the sense of Fisher) about the parameter in the measurements. In other words, the Fisher information has to tend to infinity as <Inline math=\"k\\rightarrow \\infty\"/>. Then the CRLB converges to zero as <Inline math=\"k\\rightarrow \\infty\"/> and thus the variance can also converge to zero.\r\n</div>\r\nAnother consistency interpretation is regarding the estimated variance of an estimator that must satisfies\r\n<Latex math=\"\\begin{aligned}\r\n    \\hat{P}_k\\ge \\mathbb{E}\\{(x-\\hat{x}_k)^2\\},\\quad \\forall k\\ge 0\r\n\\end{aligned}\"/>\r\n<h3>Efficiency</h3>\r\n\r\nAccording to the <i>Cramer-Rao lower bound</i> (CRLB), the mean square error cannot be smaller than a certain quantity related to the likelihood function.\r\nIf an unbiased estimator's variance is <i>equal</i> to the CRLB then such estimator is called <i>Efficient</i>.\r\n<Latex math=\"\\begin{aligned}\r\n\t\\text{var}\\{\\hat{x}(Z)\\}=CRLB\r\n\\end{aligned}\"/>\r\n<p></p>\r\nEfficiency amounts to the extracted information being equal to the existing one, i.e., all the information has been taken from the set of observations.\r\n<p></p>\r\n<p></p>\r\n<p></p>\r\n<h2>Estimation of a Gaussian Random Vector</h2>\r\n\r\nConsider the vector <Inline math=\"x\\sim \\mathcal{N}(\\bar{x},P_{xx})\"/> the parameter to be estimated and <Inline math=\"z\\sim \\mathcal{N}(\\bar{z},P_{zz})\"/> the measurement available for the estimation process. Let's define the <i>stacked vector</i>\r\n<Latex math=\"\\begin{aligned}\r\n\ty\\equiv\\left[\r\n\t\\begin{matrix}\r\n\tx\\\\z\r\n\t\\end{matrix}\r\n\t\\right]\r\n\\end{aligned}\"/>\r\nThe notation <Inline math=\"y\\sim \\mathcal{N}(\\bar{y},P_{yy})\"/> indicates that the variable <Inline math=\"y\"/> is <i>normally distributed</i> with\r\n<Latex math=\"\\begin{aligned}\r\n\t\\bar{y}=\\left[\r\n\t\\begin{matrix}\r\n\t\\bar{x}\\\\\r\n\t\\bar{z}\r\n\t\\end{matrix}\r\n\t\\right],\\quad P_{yy}=\\left[\r\n\t\\begin{matrix}\r\n\tP_{xx} & P_{xz}\\\\\r\n\tP_{xz} & P_{zz}\r\n\t\\end{matrix}\r\n\t\\right]\r\n\\end{aligned}\"/>\r\nAccording to the mean square error criterion, the best estimator of <Inline math=\"x\"/> given <Inline math=\"z\"/> is the conditional mean\r\n<Latex math=\"\\begin{aligned}\r\n\t\\hat{x}(z)=\\mathbb{E}\\{x|z\\}=\\int x p(x|z)dx\r\n\\end{aligned}\"/>\r\nAssuming that <Inline math=\"x\"/> and <Inline math=\"z\"/> are jointly normal distributed, we find that\r\n<Latex math=\"\\begin{aligned}\r\n\tp(x|z)&=\\frac{p(x,z)}{p(z)}=\\frac{\\alpha_1\\exp(\\frac{1}{2}\\|y-\\bar{y}\\|_{P_{yy}^{-1}}^2)}{\\alpha_2\\exp(\\frac{1}{2}\\|z-\\bar{z}\\|_{P_{zz}^{-1}}^2)}\\\\\r\n\t&=\\alpha \\exp\\left(-\\frac{1}{2}(\\|y-\\bar{y}\\|_{P_{yy}^{-1}}^2-\\|z-\\bar{z}\\|_{P_{zz}^{-1}}^2)\\right)\r\n\\end{aligned}\"/>\r\nDefining <Inline math=\"\\xi_1=x-\\bar{x}\"/> and <Inline math=\"\\xi_2=z-\\bar{z}\"/>. One has\r\n<Latex math=\"\\begin{aligned}\r\n\t\\|y-\\bar{y}\\|_{P_{yy}^{-1}}^2-\\|z-\\bar{z}\\|_{P_{zz}^{-1}}^2=\\\\\\xi_1^T \\Sigma_{xx}\\xi_1+\\xi_1^T \\Sigma_{xz}\\xi_2+\\xi_2^T \\Sigma_{zx}\\xi_1+\\xi_2^T \\Sigma_{zz}\\xi_2-\\xi_2^T (\\Sigma_{zz}-\\Sigma_{zx}\\Sigma_{xx}^{-1}\\Sigma_{xz})\\xi_2\\\\\r\n\t=\\xi_1^T \\Sigma_{xx}\\xi_1+\\xi_1^T (\\Sigma_{xx}\\Sigma_{xx}^{-1})\\Sigma_{xz}\\xi_2+\\xi_2^T \\Sigma_{zx}(\\Sigma_{xx}^{-1}\\Sigma_{xx})\\xi_1+\\xi_2^T \\Sigma_{zx}\\Sigma_{xx}^{-1}\\Sigma_{xz}\\xi_2\\\\\r\n\t= \\|\\xi_1+\\Sigma_{xx}^{-1}\\Sigma_{xz}\\xi_2\\|_{\\Sigma_{xx}}^2= \\|x-(\\bar{x}+P_{xz}P_{zz}^{-1}(z-\\bar{z}))\\|_{\\Sigma_{xx}}^2\r\n\\end{aligned}\"/>\r\nwhere the following identity for the inverse of partitioned matrix is employed\r\n<Latex math=\"\\begin{aligned}\r\n\t\\left[\r\n\t\\begin{matrix}\r\n\tP_{xx} & P_{xz}\\\\\r\n\tP_{zx} & P_{zz}\r\n\t\\end{matrix}\r\n\t\\right]^{-1}&=\\left[\r\n\t\\begin{matrix}\r\n\t(P_{xx}-P_{xz}P_{zz}^{-1}P_{zx})^{-1} & -(P_{xx}-P_{xz}P_{zz}^{-1}P_{zx})^{-1}P_{xz}P_{zz}^{-1}\\\\\r\n\t-P_{zz}^{-1}P_{zx}(P_{xx}-P_{xz}P_{zz}^{-1}P_{zx})^{-1} & (P_{zz}-P_{zx}P_{xx}^{-1}P_{xz})^{-1}\r\n\t\\end{matrix}\r\n\t\\right]\\\\\r\n\t&=\\left[\r\n\t\\begin{matrix}\r\n\t\\Sigma_{xx} & \\Sigma_{xz}\\\\\r\n\t\\Sigma_{zx} & \\Sigma_{zz}\r\n\t\\end{matrix}\r\n\t\\right]\r\n\\end{aligned}\"/>\r\n<Latex math=\"\\begin{aligned}\r\n%\tP_{zz}^{-1}&=\\Sigma_{zz}-\\Sigma_{zx}\\Sigma_{xx}^{-1}\\Sigma_{xz}\\\\\r\n%\t\\Sigma_{xx}^{-1}\\Sigma_{xz}&=-P_{xz}P_{zz}^{-1}\r\n\\end{aligned}\"/>\r\n<p></p>\r\n<Latex math=\"\\begin{aligned}\r\n\t\t\\Sigma_{xz}&=-\\Sigma_{xx}P_{xz}P_{zz}^{-1}\\\\\r\n\t\t\\Rightarrow &\\Sigma_{xx}^{-1}\\Sigma_{xz}=-P_{xz}P_{zz}^{-1}\r\n\\end{aligned}\"/>\r\nand\r\n<Latex math=\"\\begin{aligned}\r\n\\Sigma_{zz}&=P_{zz}^{-1}+P_{zz}^{-1}P_{zx}\\Sigma_{xx}P_{xz}P_{zz}^{-1}\\\\\r\n&=P_{zz}^{-1}+\\Sigma_{zx}\\Sigma_{xx}^{-1}\\Sigma_{xz}\\\\\r\n\\Rightarrow & P_{zz}^{-1}=\\Sigma_{zz}-\\Sigma_{zx}\\Sigma_{xx}^{-1}\\Sigma_{xz}\r\n\\end{aligned}\"/>\r\nThereafter, one concludes that <Inline math=\"p(x|z)\"/> is Gaussian distributed. Which implies that\r\n<Latex math=\"\\begin{aligned}\r\n\t\\hat{x}(z)&=\\bar{x}+P_{xz}P_{zz}^{-1}(z-\\bar{z})\\\\\r\n\tP_{xx|z}&=\\Sigma_{xx}^{-1}=P_{xx}-P_{xz}P_{zz}^{-1}P_{xz}\r\n\\end{aligned}\"/>\r\n<p></p>\r\nThe pair <Inline math=\"\\{\\hat{x}(z),P_{xx|z}\\}\"/> is called <i>sufficient statistic</i> in the sense that\r\n<Latex math=\"\\begin{aligned}\r\np(x|z)=p(x|\\hat{x}(z),P_{xx|z}).\r\n\\end{aligned}\"/>\r\n<p></p>\r\nNote that the optimal estimator (in the MMSE sense) of <Inline math=\"x\"/> in terms of <Inline math=\"z\"/> is a linear function of <Inline math=\"z\"/> plus a constant. Another important property specific for this Gaussian case is that the conditional covariance <Inline math=\"P_{xx|z}\"/>, which measures the \"quality\" of the estimate, is independent of the observations <Inline math=\"z\"/>. However, these optimal properties only hold when Gaussian assumption is valid.\r\n<div class='remark'><b>Remark:</b><br/>\r\n\tIn order to the assumption of jointly Gaussianess of <Inline math=\"x\"/> and <Inline math=\"z\"/> be true, the likelihood function <Inline math=\"p(z|x)\"/> and <Inline math=\"p(x)\"/> must be Gaussian as <Inline math=\"p(x,z)=p(z|x)p(x)\"/>.\r\n</div>\r\n<h4>Linear Gaussian Estimation</h4>\r\n\r\nLet <Inline math=\"y=Hx+\\varepsilon\"/> with <Inline math=\"x\\sim \\mathcal{N}(\\bar{x},P)\"/> and <Inline math=\"\\varepsilon\\sim\\mathcal{N}(0,R)\"/>. Therefore, <Inline math=\"y|x\\sim\\mathcal{N}(Hx,R)\"/> and one conclude that the joint distribution is <Inline math=\"p(x,y)=\\mathcal{N}(z,\\Sigma)\"/> where\r\n<Latex math=\"\\begin{aligned}\r\n    z=\\begin{bmatrix}\r\n    \\bar{x}\\\\\r\n    H\\bar{x}\r\n    \\end{bmatrix},\\quad \\Sigma=\\begin{bmatrix}\r\n    P & PH^T \\\\\r\n    HP & R+H^T P H\r\n    \\end{bmatrix}\r\n\\end{aligned}\"/>\r\nThus,\r\n<Latex math=\"\\begin{aligned}\r\n    \\hat{x}&=\\bar{x}+PH^T[R+H^T P H]^{-1}(y-H\\bar{x})\\\\\r\n    P_e &= P-PH^T[R+H^T P H]^{-1}HP\r\n\\end{aligned}\"/>\r\nwhere <Inline math=\"P_e=\\mathbb{E}[(x-\\hat{x})(x-\\hat{x})^T]=\\mathbb{E}[(x-\\mathbb{E}[x])(x-\\mathbb{E}[x])^T]\"/>.\r\n<p></p>\r\n<h2>Best Linear Unbiased Estimator of random vectors</h2>\r\n\r\nThe best estimate (in MMSE sense) of any random variable <Inline math=\"x\"/> in terms of another random variable <Inline math=\"z\"/> is the conditional mean <Inline math=\"\\mathbb{E}\\{x|z\\}\"/>. But, in many problems the distribution <Inline math=\"p(x|z)\"/> needed for the evaluation of this expectation is not available or could be prohibitively complicated. \r\n<p></p>\r\nTo overcome this difficult and to provide a simple tool for estimation in real scenarios one might consider an approximation given by the <i>Best Linear Unbiased Estimator</i> (BLUE) even when the random variables are no longer Gaussian.\r\n<p></p>\r\nFor this case, the following conditions needs to be satisfied\r\n<div class='itemize'><lu>\r\n\t<li> The estimate must be unbiased;</li>\r\n\t\r\n\t<li> The estimation error must be uncorrelated from the observations;</li>\r\n</lu></div>\r\n<p></p>\r\n<h3>Orthogonality Principle</h3>\r\n\r\nThe second requirement of uncorrelatedness between the estimation error and observations is equivalent to ask for the estimation error be orthogonal to the space spanned by all observations.\r\nIn order to understand this idea, let's define the space of all zero-mean real-valued random variables. \r\n<Latex math=\"\\begin{aligned}\r\n\t\\mathcal{Z}=\\{z\\sim p(z) , z\\in \\mathbb{R} ~|~ \\mathbb{E}\\{z\\}=0\\}\r\n\\end{aligned}\"/>\r\n<Inline math=\"\\mathcal{Z}\"/> is a <i>vector space</i>, that is, it is closed under addition and multiplication by scalars.\r\n<Latex math=\"\\begin{aligned}\r\n\t\\forall z_1,z_2 \\in \\mathcal{Z}, \\alpha \\in \\mathbb{R} \\left\\{\r\n\t\\begin{matrix}\r\n\t z_1+z_2 \\in \\mathcal{Z}\\\\\r\n\t \\alpha z_1 \\in \\mathcal{Z}\r\n\t\\end{matrix}\r\n\t\\right.\r\n\\end{aligned}\"/>\r\nOne also can define the <i>Inner Product</i> by \r\n<Latex math=\"\\begin{aligned}\r\n\t\\langle z_1, z_2 \\rangle  \\equiv \\mathbb{E}\\{z_1 z_2\\}\r\n\\end{aligned}\"/>\r\nThereafter, a <i>norm</i> can be established\r\n<Latex math=\"\\begin{aligned}\r\n\t\\|z\\|^2 = \\langle z, z \\rangle = \\mathbb{E}\\{z^2\\}\r\n\\end{aligned}\"/>\r\nTwo random vector are said to be orthogonal, denoted by <Inline math=\"z_1\\perp z_2\"/>, if\r\n<Latex math=\"\\begin{aligned}\r\n\t\\langle z_1, z_2 \\rangle = \\mathbb{E}\\{z_1 z_2\\}=0 \r\n\\end{aligned}\"/>\r\nwhich is equivalent to these zero-mean random vectors being uncorrelated.\r\n<p></p>\r\nThe best linear unbiased estimator of a scalar zero-mean random variable <Inline math=\"x\"/> in terms of scalar measurements <Inline math=\"z_i\"/>, <Inline math=\"i=1,\\ldots, n\"/>, is assumed to be a linear combination\r\n<Latex math=\"\\begin{aligned}\r\n\t\\hat{x}(z)=\\sum_{i=1}^n \\beta_i z_i\r\n\\end{aligned}\"/>\r\nwhere the parameters <Inline math=\"\\beta_i \\in \\mathbb{R}, i=1,\\ldots, n\"/> are chosen in order to minimize the norm of the estimation error \r\n<Latex math=\"\\begin{aligned}\r\n\t\\min_{\\beta_1,\\ldots,\\beta_n} \\|x-\\hat{x}(z)\\|^2 = \\min_{\\beta_1,\\ldots,\\beta_n} \\mathbb{E}\\left\\{\\left(x-\\sum_{i=1}^n \\beta_i z_i\\right)^2\\right\\}\r\n\\end{aligned}\"/>\r\n<p></p>\r\nTaking the derivative with respect to <Inline math=\"\\beta_k\"/> and setting to zero, we find that\r\n<Latex math=\"\\begin{aligned}\r\n\t\\frac{\\partial }{\\partial \\beta_k}\\|x-\\hat{x}(z)\\|^2&=\\mathbb{E}\\left\\{2 \\left(x-\\sum_{i=1}^n \\beta_i z_i\\right) z_k\\right\\}\\\\\r\n\t&\\Rightarrow \\langle \\tilde{x}, z_k\\rangle =0\r\n\\end{aligned}\"/>\r\nwhere <Inline math=\"\\tilde{x}=x-\\hat{x}(z)\"/>. thus, it seems equivalent to requiring the following orthogonality property\r\n<Latex math=\"\\begin{aligned}\r\n\t\\tilde{x}\\perp z_k,\\quad \\forall k=1,\\ldots,n\r\n\\end{aligned}\"/>\r\nThis is the principle of orthogonality, in order to the error to have minimum norm, it has to be orthogonal to all the observations. \r\n<p></p>\r\nThis is equivalent to stating that the estimate <Inline math=\"\\hat{x}\"/> has to be the orthogonal projection of <Inline math=\"x\"/> into the space spanned by the observations. To illustrate this idea, let's consider only two measurements, thus, the space spanned by this measurements will be a \"plane\". As consequence, the best estimator <Inline math=\"\\hat{x}\"/> must be the projection of <Inline math=\"x\"/> into this plane, as depicted in the following Figure.\r\n<Image src=\"/images/orthogonality.svg\" label=\"fig:orthogonality\" legend=\"Orthogonality principle.\" width=\"50%\"/>\r\n<p></p>\r\nFor the case (more realistic) with non-zero mean random-values. The same approach can be made with the subtraction of the mean value. The estimator becomes \r\n<Latex math=\"\\begin{aligned}\r\n\t\\hat{x}(z)=\\bar{x}+\\sum_{i=1}^n \\beta_i(z_i-\\bar{z}_i)\r\n\\end{aligned}\"/>\r\nand the orthogonality principle requires that\r\n<Latex math=\"\\begin{aligned}\r\n\t \\tilde{x}\\perp (z_k-\\bar{z}_k),\\quad \\forall k=1,\\ldots,n\r\n\\end{aligned}\"/>\r\nwhere <Inline math=\"z_i-\\bar{z}_i\"/> is the measurement residual. Thus, we find that\r\n<Latex math=\"\\begin{aligned}\r\n\t\\mathbb{E}\\left\\{\\left(x-\\bar{x}-\\sum_{i=1}^n\\beta_i (z_i-\\bar{z_i})\\right)(z_k-\\bar{z}_k)\\right\\}=\\text{cov}(x,z_k)-\\sum_{i=1}^n\\beta_i\\mbox{cov}(z_i,z_k)=0\r\n\\end{aligned}\"/>\r\nif <Inline math=\"\\text{cov}(z_i,z_k)=\\delta_{ik}\"/> then\r\n<Latex math=\"\\begin{aligned}\r\n\t\\beta_k = \\frac{\\text{cov}(x,z_k)}{\\mbox{var}(z_k)}\r\n\\end{aligned}\"/>\r\n<h3>Multidimensional Orthogonality Principle</h3>\r\n\r\nConsider the vector-valued random variables <Inline math=\"x\\in \\mathbb{R}^n\"/> and <Inline math=\"z\\in \\mathbb{R}^m\"/>, which are not necessarily Gaussian or zero-mean. The BLUE of <Inline math=\"x\"/> in terms of <Inline math=\"z\"/> is obtained as follows. Find the estimator\r\n<Latex math=\"\\begin{aligned}\r\n\t\\hat{x}(z)=Az+b\r\n\\end{aligned}\"/>\r\nthat minimizes the scalar MSE criterion\r\n<Latex math=\"\\begin{aligned}\r\n\tJ\\equiv \\|(x-\\hat{x})^T (x-\\hat{x})\\|^2=\\mathbb{E}\\{(x-\\hat{x})^T (x-\\hat{x})\\}\r\n\\end{aligned}\"/>\r\nAccording to the orthogonality principle, the estimator is such that the estimation error <Inline math=\"\\tilde{x}=x-\\hat{x}\"/> is zero-mean and <Inline math=\"\\hat{x}\"/> is the orthogonal projection of the vector <Inline math=\"x\"/> into the space spanned by all components of the residual vector <Inline math=\"z-\\bar{z}\"/>. Therefore,\r\n<Latex math=\"\\begin{aligned}\r\n\t\\mathbb{E}\\{\\tilde{x}\\}=\\bar{x}-(A\\bar{z}+b)=0, \\quad \\Rightarrow b=\\bar{x}-A\\bar{z}\r\n\\end{aligned}\"/>\r\nThe estimation error now becomes <Inline math=\"\\tilde{x}=x-\\bar{x}-A(z-\\bar{x})\"/>. and from the orthogonality principle\r\n<Latex math=\"\\begin{aligned}\r\n\t\\mathbb{E}\\{(x-\\bar{x}-A(z-\\bar{x})) (z-\\bar{z})^T \\} = P_{xz}-AP_{zz}=0 \\\\\r\n\t\\Rightarrow A=P_{zx}P_{zz}^{-1}\r\n\\end{aligned}\"/>\r\nCombining all results, we have\r\n<Latex math=\"\\begin{aligned}\r\n\\hat{x}(z)=\\bar{x}+P_{xz}P_{zz}^{-1}(z-\\bar{z})\r\n\\end{aligned}\"/>\r\nthat is the best estimator within the linear class of estimators.  The existence of <Inline math=\"P_{zz}^{-1}\"/> depends on the no existence of linear dependencies between measurements (no redundant information). Notice that the BLUE is identical to the conditional mean from the Gaussian case. The MSE matrix, that assess the quality of this estimator, is\r\n<Latex math=\"\\begin{aligned}\r\n\tMSE &=\\mathbb{E}\\{\\tilde{x}\\tilde{x}^T \\}\\\\\r\n\t& = \\mathbb{E}\\{(x-\\bar{x}+P_{xz}P_{zz}^{-1}(z-\\bar{z}))(x-\\bar{x}+P_{xz}P_{zz}^{-1}(z-\\bar{z}))^T \\}\\\\\r\n\t&=P_{xx}-P_{xz}P_{zz}^{-1}P_{zx}\r\n\\end{aligned}\"/>\r\nwhich also is identical to the conditional covariance <Inline math=\"P_{xx|z}\"/> from Gaussian case. Notice, however, as the vector are not necessarily Gaussian, <Inline math=\"\\hat{x}(z)\"/> and <Inline math=\"MSE\"/> are not the conditional mean and covariance of this estimator.\r\n<div class='remark'><b>Remark:</b><br/>\r\n\tIt is worth point out the difference between the inner product utilized in the scalar MSE and the outer product in the matrix MSE. Also, notice that the best estimator for Gaussian problem is identical do the best linear estimator of arbitrarily distributed random variable with the same first and second moments. \r\n\t\r\n\tOne can state that the BLUE yields the worst performance for a non-Gaussian problem. As we might find a better estimator if the conditional mean could be computed. This estimator is also referred in the literature as the Least Mean Square Estimator (LMSE) or Minimum Variance Estimator (MVE).\r\n</div>\r\n<h2>The Linear Least Square Estimation</h2>\r\n\r\nConsider a set of linear measurements <Inline math=\"z_k \\in \\mathbb{R}^m\"/> of a variable of interest <Inline math=\"x\\in \\mathbb{R}^n\"/> with additive noise\r\n<Latex math=\"\\begin{aligned}\r\n\tz_k=H_kx+\\varepsilon_k\r\n\\end{aligned}\"/>\r\n<h3>Batch Case</h3>\r\n\r\nThe estimator <Inline math=\"\\hat{x}\"/> is obtained through the minimization of the following quadratic cost\r\n<Latex math=\"\\begin{aligned}\r\n\tJ(k)=\\sum_{i=1}^k (z_k-H_kx)^T R_k^{-1}(z_k-H_kx)\r\n\\end{aligned}\"/>\r\nThe above criterion can be rewritten in matrix form as\r\n<Latex math=\"\\begin{aligned}\r\n\tJ(k)=\\|z^k-H^kx\\|_{(R^k)^{-1}}\r\n\\end{aligned}\"/>\r\nwhere\r\n<Latex math=\"\\begin{aligned}\r\n\tz^k=\\left[\r\n\t\\begin{matrix}\r\n\tz_1\\\\\r\n\tz_2\\\\\r\n\t\\vdots\\\\\r\n\tz_k\r\n\t\\end{matrix}\r\n\t\\right],\\quad H^k=\\left[\r\n\t\\begin{matrix}\r\n\tH_1\\\\\r\n\tH_2\\\\\r\n\t\\vdots\\\\\r\n\tH_k\r\n\t\\end{matrix}\r\n\t\\right],\\quad R^k=\\diag(R_1,R_2,\\ldots,R_k)\r\n\\end{aligned}\"/>\r\nThe optimal estimator (regarding the quadratic cost) is obtained by setting its cost gradient w.r.t x to zero.\r\n<Latex math=\"\\begin{aligned}\r\n\t\\nabla_x J(k)=0\\quad \\Rightarrow -2H^k(R^k)^{-1}(z^k-H^kx)=0\r\n\\end{aligned}\"/>\r\nThus, \r\n<Latex math=\"\\begin{aligned}\r\n\t\\hat{x}(k)=[(H^k)^T (R^k)^{-1}H^k]^{-1}(H^k)^T (R^k)^{-1}z^k\r\n\\end{aligned}\"/>\r\nassuming that the required inverse exists. Notice that the batch estimator uses the entire data set simultaneously for each <Inline math=\"k\"/>. This means that every time a new measurement <Inline math=\"z^{k+1}\"/> is made, all the data must be reprocessed. \r\n<h4>Properties</h4>\r\n\r\nWith the assumption that <Inline math=\"\\varepsilon_k\"/> is uncorrelated and zero-mean random variables with variance <Inline math=\"R_k\"/>, then <Inline math=\"\\hat{x}(k)\"/> is unbiased.\r\n<Latex math=\"\\begin{aligned}\r\n\t\\mathbb{E}\\{\\hat{x}(k)\\}&=\\mathbb{E}\\{[(H^k)^T (R^k)^{-1}H^k]^{-1}(H^k)^T (R^k)^{-1}(H^kx+\\varepsilon^k)\\}\\\\\r\n\t&=[(H^k)^T (R^k)^{-1}H^k]^{-1}[(H^k)^T (R^k)^{-1}(H^k)]\\mathbb{E}\\{x\\}\\\\\r\n\t&=\\mathbb{E}\\{x\\}\r\n\\end{aligned}\"/>\r\nThe error estimation is\r\n<Latex math=\"\\begin{aligned}\r\n\t\\tilde{x}&=x-\\hat{x}(k)\\\\\r\n\t&=x-[(H^k)^T (R^k)^{-1}H^k]^{-1}(H^k)^T (R^k)^{-1}(H^kx+\\varepsilon^k)\\\\\r\n\t&=-[(H^k)^T (R^k)^{-1}H^k]^{-1}(H^k)^T (R^k)^{-1}\\varepsilon^k\r\n\\end{aligned}\"/>\r\nTherefore, the covariance error matrix of <Inline math=\"\\hat{x}(k)\"/> is\r\n<Latex math=\"\\begin{aligned}\r\n\tP(k)&=\\mathbb{E}\\{(\\tilde{x}-\\mathbb{E}\\{\\tilde{x}\\})(\\tilde{x}-\\mathbb{E}\\{\\tilde{x}\\})^T\\}\\\\\r\n\t&=\\mathbb{E}\\{(x-\\hat{x}(k))(x-\\hat{x}(k))^T\\}\\\\\r\n\t&=\\mathbb{E}\\{[(H^k)^T (R^k)^{-1}H^k]^{-1}(H^k)^T (R^k)^{-1}\\varepsilon^k(\\varepsilon^k)^T (R^k)^{-1} H^k [(H^k)^T (R^k)^{-1}H^k]^{-1}\\}\\\\\r\n\t&=[(H^k)^T (R^k)^{-1}H^k]^{-1}\r\n\\end{aligned}\"/>\r\nIn summary, the LS batch estimator is\r\n<Latex math=\"\\begin{aligned}\r\n\t\\hat{x}(k)&=P(k)(H^k)^T (R^k)^{-1}z^k\\\\\r\n\tP(k)&=[(H^k)^T (R^k)^{-1}H^k]^{-1}\r\n\\end{aligned}\"/>\r\n<div class='remark'><b>Remark:</b><br/>\r\n\tThe existence of <Inline math=\"[(H^k)^T (R^k)^{-1}H^k]^{-1}\"/> depends on the observability of the problem. which is equivalent to require that the noise covariance of measurements be finite, that is, it can be estimated from observations.\r\n\t\r\n\tSmall eigenvalues of <Inline math=\"[(H^k)^T (R^k)^{-1}H^k]\"/> will lead to large eigenvalues on its inverse and provide an indication of poor observability. The corresponding eigenvectors give the direction in the parameter space where one has poor observability. \r\n</div>\r\n<h3>The Recursive form</h3>\r\n\r\nA useful feature of the LS estimator is that it can be rewritten in recursive form (suitable for sequential rather than batch processing). In this case, k is interpreted as \"discrete time\". When <Inline math=\"z_{k+1}\"/> is obtained, one can write the following partitioned form\r\n<Latex math=\"\\begin{aligned}\r\n\tz^{k+1}=\\left[\r\n\t\\begin{matrix}\r\n\tz^k\\\\\r\n\tz_{k+1}\r\n\t\\end{matrix}\r\n\t\\right],\\quad H^{k+1}=\\left[\r\n\t\\begin{matrix}\r\n\tH^k\\\\\r\n\tH_{k+1}\r\n\t\\end{matrix}\r\n\t\\right],\\quad R^{k+1}=\\diag(R^k,R_{k+1})\r\n\\end{aligned}\"/>\r\nFrom the batch case, one has\r\n<Latex math=\"\\begin{aligned}\r\n\tP(k+1)^{-1}&=(H^{k+1})^T(R^{k+1})^{-1}H^{k+1}\\\\\r\n\t&=\\left[\r\n\t\\begin{matrix}\r\n\tH^k\\\\\r\n\tH_{k+1}\r\n\t\\end{matrix}\r\n\t\\right]\\left[\r\n\t\\begin{matrix}\r\n\tR^k & 0\\\\\r\n\t0 & R_{k+1}\r\n\t\\end{matrix}\r\n\t\\right]^{-1}\\left[\r\n\t\\begin{matrix}\r\n\tH^k\\\\\r\n\tH_{k+1}\r\n\t\\end{matrix}\r\n\t\\right]\\\\\r\n\t&=(H^k)^T (R^k)^{-1} H^k + H_{k+1}^T R_{k+1}^{-1}H_{k+1}\\\\\r\n\t&=P(k)^{-1}+ H_{k+1}^T R_{k+1}^{-1}H_{k+1}\r\n\\end{aligned}\"/>\r\nIn terms of information, this can be interpreted as follows: The information at time <Inline math=\"k+1\"/> equals the sum of the information up to time <Inline math=\"k\"/> and the new information about <Inline math=\"x\"/> obtained from <Inline math=\"z_{k+1}\"/>.\r\n<p></p>\r\nThe information is additive because the problem is static (i.e, the parameter is constant) and the observations are uncorrelated, i.e. <Inline math=\"\\text{cov}(z_j,z_i)=R_{ji}\\delta_{ji}\"/>.\r\n<p></p>\r\nUsing the <i>matrix inversion lemma</i>, one has\r\n<Latex math=\"\\begin{aligned}\r\n\tP(k+1)&=[P(k)^{-1}+H_{k+1}^T R_{k+1}^{-1}H_{k+1}]^{-1}\\\\\r\n\t&=P(k)-P(k)H_{k+1}^T [R_{k+1}+H_{k+1}P(k)H_{k+1}^T ]^{-1}H_{k+1}P(k)\\\\\r\n\t&=[I-P(k)H^T_{k+1}[R_{k+1}+H_{k+1}P(k)H_{k+1}^T ]^{-1}H_{k+1}]P(k)\\\\\r\n\t&=[I-K_kH_{k+1}]P(k)\r\n\\end{aligned}\"/>\r\nwhere <Inline math=\"K_k=P(k)H^T_{k+1}[R_{k+1}+H_{k+1}P(k)H_{k+1}^T ]^{-1}\"/> is the <i>estimator gain</i>. Notice that this also can be written as\r\n<Latex math=\"\\begin{aligned}\r\n\tK_k=P(k+1)H_{k+1}^T R_{k+1}^{-1}\r\n\\end{aligned}\"/>\r\nThereafter, following the same vein as before, the estimator is\r\n<Latex math=\"\\begin{aligned}\r\n\t\\hat{x}(k+1)&=P(k+1)(H^{k+1})^T (R^{k+1})^{-1}z^{k+1}\\\\\r\n\t&=P(k+1)\\left[\r\n\t\\begin{matrix}\r\n\t(H^k)^T & H_{k+1}^T \r\n\t\\end{matrix}\r\n\t\\right]\\left[\r\n\t\\begin{matrix}\r\n\tR^k & 0 \\\\\r\n\t0 & R_{k+1}\r\n\t\\end{matrix}\r\n\t\\right]^{-1}\\left[\r\n\t\\begin{matrix}\r\n\tz^k\\\\\r\n\tz_{k+1} \r\n\t\\end{matrix}\r\n\t\\right]\\\\\r\n\t&=P(k+1)[(H^k)^T (R^k)^{-1}z^k+H_{k+1}^T R_{k+1}^{-1}z_{k+1}]\\\\\r\n\t&=[I-K_kH_{k+1}]P(k)(H^k)^T (R^k)^{-1}z^k+P(k+1)H_{k+1}^T R_{k+1}^{-1}z_{k+1}\\\\\r\n\t&=[I-K_kH_{k+1}]\\hat{x}(k)+K_kz_{k+1}\\\\\r\n\t&=\\hat{x}(k)+K_k\\left(z_{k+1}-H_{k+1}\\hat{x}(k)\\right)\r\n\\end{aligned}\"/>\r\nThe new (updated) estimate is equal to the previous one plus a correction term, which consists of the gain multiplying the residual from the previous k measurements.\r\nIn summary, the recursive form of the LS estimator is\r\n<Latex math=\"\\begin{aligned}\r\n\tK_k&=P(k)H^T_{k+1}[R_{k+1}+H_{k+1}P(k)H_{k+1}^T ]^{-1}\\\\\r\n\t\\hat{x}(k+1)&=\\hat{x}(k)+K_k\\left(z_{k+1}-H_{k+1}\\hat{x}(k)\\right)\\\\\r\n\tP(k+1)&=[I-K_kH_{k+1}]P(k)\\\\\r\n\\end{aligned}\"/>\r\n<div class='remark'><b>Remark:</b><br/>\r\n\tSince this is a recursive scheme, initialization is required. This can be done by using a batch step with small number of measurements or by using some priori initial guess and associated covariance.\r\n</div>\r\n<h2>Regularized Least Square</h2>\r\n\r\nConsider the following cost function\r\n<Latex math=\"\\begin{aligned}\r\n\tJ=\\|x-x_0\\|_{P_0^{-1}}^2+\\sum_{i=1}^N\\|z_{i}-H_ix\\|_{R_{i}^{-1}}^2\r\n\\end{aligned}\"/>\r\nTo facilitate the solution let <Inline math=\"v=x-x_0\"/> and <Inline math=\"y=z-Hx_0\"/>. Thus,\r\n<Latex math=\"\\begin{aligned}\r\nJ=\\|v\\|_{P_0^{-1}}+\\|y-Hv\\|_{R^{-1}}\r\n\\end{aligned}\"/>\r\nThe solution is\r\n<Latex math=\"\\begin{aligned}\r\n\t\\hat{x}=x_0+[P_0^{-1}+H^T WH]^{-1}H^T W(z-Hx_0)\r\n\\end{aligned}\"/>\r\nThis recursive form of LS also can be interpret as <i>The Regularized Least Square</i> (RLS). Note that the original cost function is <Inline math=\"J_k=\\sum_{i=1}^k \\|z_i-H_ix\\|_{R_i^{-1}}^2\"/>. Therefore,  <Inline math=\"J_{k+1}=J_k+\\|z_{k+1}-H_{k+1}x\\|^2_{R_{k+1}^{-1}}\"/> and <Inline math=\"J_k=\\|\\hat{x}_{k+1}-\\hat{x}_k\\|^2_{P_k^{-1}}\"/>.\r\n<h3>Recursive form</h3>\r\n\r\nLet <Inline math=\"\\hat{x}_k = x_0+[P_0^{-1}+H_k^T W_k H_k]^{-1}H^T_k W_k(z_k-H_kx_0)\"/> be the RLS estimator given <Inline math=\"\\{y_1,\\ldots,y_k\\}\"/> measurements. Thereafter, with a new measurement is obtained, then\r\n<Latex math=\"\\begin{aligned}\r\n\\hat{x}_{k+1} = x_0+[P_0^{-1}+H_{k+1}^T W_{k+1} H_{k+1}]^{-1}H^T_{k+1} W_{k+1}(z_{k+1}-H_{k+1}x_0)\r\n\\end{aligned}\"/>\r\nUsing the <i>matrix inversion lemma</i>, one has\r\n<Latex math=\"\\begin{aligned}\r\n\t\tP(k+1)&=[P(k)^{-1}+H_{k+1}^T R_{k+1}^{-1}H_{k+1}]^{-1}\\\\\r\n\t\t&=P(k)-P(k)H_{k+1}^T [R_{k+1}+H_{k+1}P(k)H_{k+1}^T ]^{-1}H_{k+1}P(k)\\\\\r\n\t\t&=[I-P(k)H^T_{k+1}[R_{k+1}+H_{k+1}P(k)H_{k+1}^T ]^{-1}H_{k+1}]P(k)\\\\\r\n\t\t&=[I-K_kH_{k+1}]P(k)\r\n\\end{aligned}\"/>\r\nwhere <Inline math=\"K_k=P(k)H^T_{k+1}[R_{k+1}+H_{k+1}P(k)H_{k+1}^T ]^{-1}\"/> is the <i>estimator gain</i>. Notice that this also can be written as\r\n<Latex math=\"\\begin{aligned}\r\n\tK_k=P(k+1)H_{k+1}^T R_{k+1}^{-1}\r\n\\end{aligned}\"/>\r\nThereafter, following the same vein as before, the estimator is\r\n<Latex math=\"\\begin{aligned}\r\n\t\t\\hat{x}(k+1)&=x_0+P(k+1)(H_{k+1})^T W_{k+1}(z^{k+1}-H_{k+1}x_0)\\\\\r\n\t\t&=x_0+P(k+1)\\left[\r\n\t\t\\begin{matrix}\r\n\t\t\tH_k^T & H^T \r\n\t\t\\end{matrix}\r\n\t\t\\right]\\left[\r\n\t\t\\begin{matrix}\r\n\t\t\tW_k & 0 \\\\\r\n\t\t\t0 & R_{k+1}^{-1}\r\n\t\t\\end{matrix}\r\n\t\t\\right]\\left[\r\n\t\t\\begin{matrix}\r\n\t\t\ty_k\\\\\r\n\t\t\ty\r\n\t\t\\end{matrix}\r\n\t\t\\right]\\\\\r\n\t\t&=x_0+P(k+1)[H_k^T W_ky_k+H^T R^{-1}y]\\\\\r\n\t\t&=[I-K_kH]P(k)H_k^T W_ky_k+P(k+1)H^T R^{-1}y\\\\\r\n\t\t&=x_0+[I-K_kH](\\hat{x}(k)-x_0)+K_ky\\\\\r\n\t\t&=\\hat{x}(k)+K_k\\left(y-H(\\hat{x}(k)-x_0)\\right)\\\\\r\n\t\t&=\\hat{x}(k)+K_k\\left(z-H\\hat{x}(k)\\right)\r\n\\end{aligned}\"/>\r\nThe new (updated) estimate is equal to the previous one plus a correction term, which consists of the gain multiplying the residual from the previous k measurements.\r\nIn summary, the recursive form of the RLS estimator coincides with the recursive form of the LS with the initialization <Inline math=\"\\hat{x}_0=x_0\"/> and <Inline math=\"P(0)=P_0\"/>.\r\n<Latex math=\"\\begin{aligned}\r\n\t\tK_k&=P(k)H^T_{k+1}[R_{k+1}+H_{k+1}P(k)H_{k+1}^T ]^{-1}\\\\\r\n\t\t\\hat{x}(k+1)&=\\hat{x}(k)+K_k\\left(z_{k+1}-H_{k+1}\\hat{x}(k)\\right)\\\\\r\n\t\tP(k+1)&=[I-K_kH_{k+1}]P(k)\\\\\r\n\\end{aligned}\"/>\r\n<h2>Nonlinear LS</h2>\r\n\r\nConsider the case where measurements are available through a non-linear map <Inline math=\"h: \\mathbb{R}^n \\rightarrow \\mathbb{R}^m\"/> plus additive noise\r\n<Latex math=\"\\begin{aligned}\r\n\ty_i=h(x)+\\varepsilon_i\r\n\\end{aligned}\"/>\r\n<h3>Batch case</h3>\r\n\r\nAssuming that <Inline math=\"h\"/> is differentiable, then one can employ the first-order approximation\r\n<Latex math=\"\\begin{aligned}\r\n\ty_k=h(\\hat{x}^0)+H^0(x-\\hat{x}^0)+\\mathcal{O}(\\|x-\\hat{x}^0\\|^2) + \\varepsilon\r\n\\end{aligned}\"/>\r\nwhere\r\n<Inline math=\"H^0=\\left.\\frac{\\partial h(x)}{\\partial x}\\right|_{x=\\hat{x}^0}\"/> and <Inline math=\"\\hat{x}^0\"/> is some initial guess or <i>priori</i> estimate of <Inline math=\"x\"/>. If the second order terms are neglected then a linear approximation based on <Inline math=\"\\hat{x}^0\"/> is obtained,\r\n<Latex math=\"\\begin{aligned}\r\n\t(y_i-h(\\hat{x}^0))=H^0(x-\\hat{x}^0)\r\n\\end{aligned}\"/>\r\nwhere the measurement is replaced by the residual <Inline math=\"y_i-h(\\hat{x}^j)\"/> and the variable of interest by <Inline math=\"x-\\hat{x}^0\"/>. \r\n<p></p>\r\nMoreover, given a set of measurements <Inline math=\"y_1,y_2,\\ldots,y_k\"/>, the classic linear LS estimator can be applied. However, as the problem is nonlinear, might be necessary to apply them more then once, replacing the \"initial guess\" by the last result until convergence or some criterion been satisfied. This yields the so-called <i>Iterated Least Square</i> (ILS) estimator\r\n<Latex math=\"\\begin{aligned}\r\n\tP(k)^{j}&=[(H^{j}_k)^T (R^k)^{-1}H^{j}_k]^{-1},\\\\\r\n\t\\hat{x}(k)^{j+1}&=\\hat{x}(k)^j+P(k)^j(H_k^j)^T(R^k)^{-1} z^j_k\r\n\\end{aligned}\"/>\r\nwith\r\n<Latex math=\"\\begin{aligned}\r\nz^j_k&=\\left[\r\n\\begin{matrix}\r\ny_1-h(\\hat{x}^j(k))\\\\\r\ny_2-h(\\hat{x}^j(k))\\\\\r\n\\vdots\\\\\r\ny_k-h(\\hat{x}^j(k))\r\n\\end{matrix}\r\n\\right],\\quad H^j_k=\\left[\r\n\\begin{matrix}\r\nH^j\\\\\r\nH^j\\\\\r\n\\vdots\\\\\r\nH^j\r\n\\end{matrix}\r\n\\right],\\\\ R^k &= \\diag(R_1,R_2,\\ldots,R_k),\\quad H^j=\\left.\\frac{\\partial h(x)}{\\partial x}\\right|_{x=\\hat{x}^j}\r\n\\end{aligned}\"/>\r\n<div class='remark'><b>Remark:</b><br/>\r\n\tIt is important to point out that for nonlinear scenarios one cannot claim that the ILS estimator will be unbiased as the linear case. Besides, the <Inline math=\"P(k)\"/> is only an approximation to the real MSE matrix.\r\n</div>\r\n<h3>The Recursive form</h3>\r\n\r\nAs described for the linear case, a useful feature of the LS estimator is that it can be rewritten in recursive form. The same might be applied for the ILS estimator. When <Inline math=\"y_{k+1}\"/> is obtained, one can write the following partitioned form\r\n<Latex math=\"\\begin{aligned}\r\nz^j_{k+1}=\\left[\r\n\\begin{matrix}\r\nz_k^j\\\\\r\ny_{k+1}-h(\\hat{x}^j(k+1))\r\n\\end{matrix}\r\n\\right],\\quad H^j_{k+1}=\\left[\r\n\\begin{matrix}\r\nH^j_{k}\\\\\r\nH^j\r\n\\end{matrix}\r\n\\right],\\quad R^{k+1}=\\diag(R^k,R_{k+1})\r\n\\end{aligned}\"/>\r\nAccordingly, one has\r\n<Latex math=\"\\begin{aligned}\r\nP(k+1)^j=[I-K_kH^j]P(k)^j\r\n\\end{aligned}\"/>\r\nThereafter, following the same vein as before and defining <Inline math=\"v(k+1)=\\hat{x}(k+1)^{j+1}-\\hat{x}(k+1)^j\"/>, the recursive form of the ILS estimator is\r\n<Latex math=\"\\begin{aligned}\r\nv(k+1)&=P(k+1)^j(H^j_{k+1})^T (R^{k+1})^{-1}z^j_{k+1}\\\\\r\n&=P(k+1)^j\\left[\r\n\\begin{matrix}\r\n(H^j_k)^T & (H^j)^T \r\n\\end{matrix}\r\n\\right]\\left[\r\n\\begin{matrix}\r\nR^k & 0 \\\\\r\n0 & R_{k+1}\r\n\\end{matrix}\r\n\\right]^{-1}\\left[\r\n\\begin{matrix}\r\nz^j_k\\\\\r\ny_{k+1}-h(\\hat{x}(k+1)^j) \r\n\\end{matrix}\r\n\\right]\\\\\r\n&=P(k+1)[(H^j_k)^T (R^k)^{-1}z^j_k+(H^j)^T R_{k+1}^{-1}(y_{k+1}-h(\\hat{x}(k+1)^j))]\\\\\r\n&=[I-K_kH^j]P(k)^j[(H^j_{k})^T (R^k)^{-1}z^j_k+(H^j)^T R_{k+1}^{-1}(y_{k+1}-h(\\hat{x}(k+1)^j)]\\\\\r\n&=[I-K_kH^j]v(k)+P(k+1)^j(H^j)^T R_{k+1}^{-1}\\left(y_{k+1}-h(\\hat{x}(k+1)^j)\\right)\\\\\r\n&=K_k\\left(y_{k+1}-h(\\hat{x}(k+1)^j)\\right)\r\n\\end{aligned}\"/>\r\nNotice that <Inline math=\"v(k)=\\hat{x}(k)^{j+1}-\\hat{x}(k)^j=0\"/> assuming that based on <Inline math=\"k\"/> measurements the previous iteration converged successfully for the best value <Inline math=\"\\hat{x}(k)^*\"/> and <Inline math=\"P(k)^*\"/>. Thus, the new (updated with new observation) estimate will be the result of the following iteration with initialization <Inline math=\"\\hat{x}(k+1)^0=\\hat{x}(k)^*\"/>.\r\n<Latex math=\"\\begin{aligned}\r\n\t\\hat{x}(k+1)^{j+1}=\\hat{x}(k+1)^j+K_k(y_{k+1}-h(\\hat{x}(k+1)^j))\r\n\\end{aligned}\"/>\r\nTherefore, the updated estimate consists of the previous one plus a correction term given by a gain multiplying the residual from the previous iteration.\r\n<p></p>\r\nIn summary, the recursive form of the ILS estimator is\r\n<Latex math=\"\\begin{aligned}\r\n\\hat{x}^{j+1}&=\\hat{x}^j+K^j\\left(y_{k+1}-h(\\hat{x}^j)\\right)\\\\\r\nK^{j+1}&=P(k)^*(H^{j+1})^T[R_{k+1}+H^{j+1}P(k)^*(H^{j+1})^T ]^{-1}\\\\\r\nP(k+1)^{j+1}&=[I-K^{j+1}(H^{j+1})^T ]P(k)^*\\\\\r\n\\end{aligned}\"/>\r\n<div class='remark'><b>Remark:</b><br/>\r\nThe recursive form of ILS result in a nested loop for each measurement. Which can become a computational burden depend on the application. \r\n</div>\r\n<h2>Taylor Approximation</h2>\r\n\r\nConsider <Inline math=\"x=x_0+\\delta x\"/> where <Inline math=\"\\delta x \\sim \\mathcal{N}(0,P_x)\"/>, thus\r\n<Latex math=\"\\begin{aligned}\r\n\tg(x) = g(x_0)+ G_x\\delta x + \\sum_i \\frac{1}{2}\\delta x^T G_{xx}^i \\delta x e_i +\\cdots\r\n\\end{aligned}\"/>\r\nTaking only the first order approximation, one has\r\n<Latex math=\"\\begin{aligned}\r\n\t\\mathbb{E}\\{g(x)\\}&\\simeq g(x_0)\\\\\r\n\t\\text{cov}(g(x)) &\\simeq G_xP_xG_x^T\r\n\\end{aligned}\"/>\r\nWe often are interest in the covariance between <Inline math=\"x\"/> and <Inline math=\"g(x)\"/>. For this purpose, let us consider the augmented r.v. <Inline math=\"z=[x~g(x)]^T\"/>. Notice that\r\n<Latex math=\"\\begin{aligned}\r\n\tz \\simeq \\left[\r\n\t\\begin{matrix}\r\n\tx_0+\\delta x\\\\\r\n\tg(x_0)+G_x\\delta x\r\n\t\\end{matrix}\r\n\t\\right]\r\n\\end{aligned}\"/>\r\nThus,\r\n<Latex math=\"\\begin{aligned}\r\n\\mathbb{E}\\{z\\}=\\left[\r\n\\begin{matrix}\r\nx_0\\\\\r\ng(x_0)\r\n\\end{matrix}\r\n\\right]\r\n\\end{aligned}\"/>\r\nand\r\n<Latex math=\"\\begin{aligned}\r\n\\text{cov}(z)\\simeq \\mathbb{E}\\left\\{\\left(\\left[\r\n\\begin{matrix}\r\nx_0+\\delta x\\\\\r\ng(x_0)+G_x\\delta x\r\n\\end{matrix}\r\n\\right]-\\left[\r\n\\begin{matrix}\r\nx_0\\\\\r\ng(x_0)\r\n\\end{matrix}\r\n\\right]\\right)(\\cdot)^T \\right\\}\\\\\r\n= \\mathbb{E}\\left\\{\r\n\\left[\r\n\\begin{matrix}\r\nI\\\\\r\nG_x\r\n\\end{matrix}\r\n\\right]\\delta x \\delta x^T \\left[\r\n\\begin{matrix}\r\nI & G_x\r\n\\end{matrix}\r\n\\right]\r\n\\right\\}\\\\\r\n= \\left[\r\n\\begin{matrix}\r\nP_x & P_x G_x^T\\\\\r\nG_xP_x & G_xP_xG_x^T \r\n\\end{matrix}\r\n\\right]\r\n\\end{aligned}\"/>\r\n<h1 id=\"appendix\">Appendix</h1>\r\n \r\n<h3>Woodbury matrix Identity</h3>\r\n\r\n<Latex math=\"\\begin{aligned}\r\n    [A+UCV]^{-1}=A^{-1}-A^{-1}U[C^{-1}+VA^{-1}U]^{-1}VA^{-1}\r\n\\end{aligned}\"/>\r\n\r\n                    </div>\r\n                    <Disqus.DiscussionEmbed shortname={disqusShortname} config={disqusConfig} />\r\n                    </article>\r\n                    }\r\n                    export default ClassicEstimation;","import React from 'react';\r\nimport './Notes.css';\r\nimport Helmet from 'react-helmet';\r\nimport EkfLie from '../../Content/Notes/Kalman/ekf_lie';\r\nimport RiccatiEq from '../../Content/Notes/Riccati/RiccatiEq';\r\nimport ParticleFilter from '../../Content/Notes/particleFilter';\r\nimport Lasso from '../../Content/Notes/LASSO/lasso';\r\nimport BayesianFiltering from '../../Content/Notes/Kalman/BayesianFiltering';\r\nimport IntroKalmanFilter from '../../Content/Notes/Kalman/IntroKalmanFilter';\r\nimport KalmanSmoothing from '../../Content/Notes/Kalman/kalmanSmoothing';\r\nimport ClassicEstimation from '../../Content/Notes/Kalman/classicEstimation';\r\n\r\nconst NotePage = (props) => {\r\n    let content;\r\n    switch (props.note.class) {\r\n        case 'EkfLie':\r\n            content = <EkfLie note={props.note}/>;\r\n            break\r\n        case 'RiccatiEq':\r\n            content = <RiccatiEq note={props.note}/>;\r\n            break\r\n        case 'particleFilter':\r\n            content = <ParticleFilter note={props.note}/>;\r\n            break\r\n        case 'Lasso':\r\n            content = <Lasso note={props.note}/>;\r\n            break    \r\n        case 'BayesianFiltering':\r\n            content = <BayesianFiltering note={props.note}/>;\r\n            break    \r\n\r\n        case 'IntroKalmanFilter':\r\n            content = <IntroKalmanFilter note={props.note}/>;\r\n            break  \r\n        case 'KalmanSmoothing':\r\n                content = <KalmanSmoothing note={props.note}/>;\r\n            break               \r\n        case 'ClassicEstimation':\r\n                content = <ClassicEstimation note={props.note}/>;\r\n            break                \r\n    }\r\n    return <div className=\"divNote\">\r\n<div className=\"top\">\r\n   <h1>{props.note.title}</h1>\r\n   <p>{props.note.desc}</p>\r\n</div>\r\n{content}\r\n</div>\r\n}\r\nexport default NotePage;","import React, { Component } from 'react';\r\nimport './Notes.css';\r\n\r\nimport NoteList from './NotesList'\r\nimport NotePage from './NotePage'\r\nimport {Route} from 'react-router-dom';\r\nclass Notes extends Component {\r\n    states = {\r\n        notes: [\r\n        {\r\n            id:1,\r\n            title:'Introduction to the Kalman Filter',\r\n            desc:'Brief introduction to the famous Kalman Filter from a Bayesian pespective.',\r\n            link: 'intro-kalman-filter',\r\n            class: 'IntroKalmanFilter'\r\n        },\r\n        {\r\n            id:6,\r\n            title:'Kalman Smoother',\r\n            desc:'Brief introduction to the Kalman Smoother from a Bayesian pespective.',\r\n            link: 'kalman-smoother',\r\n            class: 'KalmanSmoothing'\r\n        },\r\n        {\r\n            id:7,\r\n            title:'Classic Estimation',\r\n            desc:'Introduction to the classic estimation tools such as least-squares, Maximum Likelihood, Maximum A Posteriori, MMSE, etc.',\r\n            link: 'classic-estimation',\r\n            class: 'ClassicEstimation'\r\n        },\r\n        {\r\n            id:0,\r\n            title:'Extend Kalman Filter on Lie Groups',\r\n            desc:'Here I provide the main equations for implementation of Extend Kalman Filter on Lie Groups.',\r\n            link: 'ekf-lie-groups',\r\n            class: 'EkfLie'\r\n        },\r\n        {\r\n            id:5,\r\n            title:'Analytical Solution of Riccati Equations',\r\n            desc:'The Differential Riccati Equations are essential to solving many problems in optimal control and filtering. In this note, the analytical solution is discussed for both finite and infinite horizons.',\r\n            link: 'riccati-equation',\r\n            class: 'RiccatiEq'\r\n        },\r\n        {\r\n            id:2,\r\n            title:'Particle Filter and Monte Carlo Integration',\r\n            desc:'Particle Filter perform Sequential Monte Carlo (SMC) Estimation based on point mass \"particles\" representation of probabilities densities. The basic SMC ideas in the form of Sequential Importance Sampling had been introduced in statistics back in the 1950s. In this note, an overview of this method is provided.',\r\n            link: 'particle-filter',\r\n            class: 'particleFilter'\r\n        },\r\n        {\r\n            id:3,\r\n            title:'LASSO Regression',\r\n            desc:'This note is dedicated to summarize the main fundamentals of the lasso estimator. This method combines the usual least-square loss with a l1-constraint, or bound in the sum of the absolute values of the model parameters. Compared to the classical least-square, the lasso estimator has the effect of shrinking the regression coefficients or even setting some to zero. In this way, the lasso provides an automatic way to feature selection, and unlike another methods, the resulting optimization problem is convex, and can be solved efficiently for large problems. The lasso was proposed by Robert Tibshirani in 1996.',\r\n            link: 'lasso',\r\n            class: 'Lasso'\r\n        },\r\n        {\r\n            id:4,\r\n            title:'Bayesian Filtering',\r\n            desc:'Bayesian Filtering methods are used to produce an accurate estimate of the state of a time-varying system based on multiple observational inputs (data). Interest in these methods has exploded in recent years, with numerous applications emerging in fields such as navigation, aerospace engineering, telecommunications, and medicine. The Bayesian approach to the estimation and filtering problem is far from new. It was pioneered by Stratonovich in the 1950s and 1960s - even before Kalman\\'s seminal article in 1960.',\r\n            link: 'bayesian-filtering',\r\n            class: 'BayesianFiltering'\r\n        }\r\n    ]\r\n    };\r\n    routes=this.states.notes.map((note)=>{\r\n        return <Route path={'/notes/'+note.link} render={(props) => <NotePage note={note}/>}/>\r\n    });\r\n    render(){\r\n    return <div className=\"divPage\">\r\n     <Route path=\"/notes\" exact render={(props) => <NoteList notes={this.states.notes}/>}/>\r\n    {this.routes}\r\n    </div>\r\n    }\r\n}\r\nexport default Notes;","import React from 'react';\r\nconst Header = (props) => {\r\n    return <header className=\"fix\">\r\n        {props.children}\r\n    </header>\r\n}\r\nexport default Header;","import React from 'react';\r\nconst Navigation = () => {\r\n    return <div className=\"divnav\">\r\n    <nav>\r\n          <ul>\r\n            <li><a href=\"/\">Home</a></li>\r\n            <li><a href=\"/tutorials\">Tutorials</a></li>\r\n            <li><a href=\"/notes\">Notes</a></li>\r\n            <li><a href=\"/publications\">Publications</a></li>\r\n            <li><img className=\"brazilFlag\" src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/0/05/Flag_of_Brazil.svg/2000px-Flag_of_Brazil.svg.png\" alt=\"Brazil's flag\"/></li>\r\n          </ul>\r\n        </nav>\r\n        </div>\r\n}\r\nexport default Navigation;","import React from 'react';\r\nconst Bottom = (props) => {\r\n    let d=new Date();\r\n    let year=d.getFullYear();\r\nreturn <div className=\"bottom\">\r\n     {year} - &copy; Copyright - All rights reserved.\r\n</div>\r\n}\r\nexport default Bottom;","import React from 'react';\nimport './App.css';\nimport Layout from './Components/Layout/Layout';\nimport {Route, BrowserRouter as Router} from 'react-router-dom';\nimport HomePage from './Components/Pages/HomePage';\nimport Publications from './Components/Pages/Publications';\nimport Tutorials from './Components/Pages/Tutorials';\nimport Notes from './Components/Pages/Notes';\nimport Header from './Components/Header/Header';\nimport Navigation from './Components/Header/Navigation';\nimport Bottom from './Components/Bottom/Bottom';\nfunction App() {\n  //console.log(process.env.PUBLIC_URL);\n  return (\n    <Layout>\n      <Header>\n        <div className=\"divHeader\"><h2>Marcos R. Fernandes</h2></div>\n       <Navigation/>\n      </Header>\n      <Router basename={process.env.PUBLIC_URL}>      \n      <Route path=\"/\" exact component={HomePage}/>\n      <Route path=\"/publications\" component={Publications}/>\n      <Route path=\"/tutorials\" component={Tutorials}/>\n      <Route path=\"/notes\" component={Notes}/>\n      </Router>\n      <Bottom/>\n    </Layout> \n  )\n}\n\nexport default App;\n","// This optional code is used to register a service worker.\n// register() is not called by default.\n\n// This lets the app load faster on subsequent visits in production, and gives\n// it offline capabilities. However, it also means that developers (and users)\n// will only see deployed updates on subsequent visits to a page, after all the\n// existing tabs open on the page have been closed, since previously cached\n// resources are updated in the background.\n\n// To learn more about the benefits of this model and instructions on how to\n// opt-in, read https://bit.ly/CRA-PWA\n\nconst isLocalhost = Boolean(\n  window.location.hostname === 'localhost' ||\n    // [::1] is the IPv6 localhost address.\n    window.location.hostname === '[::1]' ||\n    // 127.0.0.1/8 is considered localhost for IPv4.\n    window.location.hostname.match(\n      /^127(?:\\.(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)){3}$/\n    )\n);\n\nexport function register(config) {\n  if (process.env.NODE_ENV === 'production' && 'serviceWorker' in navigator) {\n    // The URL constructor is available in all browsers that support SW.\n    const publicUrl = new URL(process.env.PUBLIC_URL, window.location.href);\n    if (publicUrl.origin !== window.location.origin) {\n      // Our service worker won't work if PUBLIC_URL is on a different origin\n      // from what our page is served on. This might happen if a CDN is used to\n      // serve assets; see https://github.com/facebook/create-react-app/issues/2374\n      return;\n    }\n\n    window.addEventListener('load', () => {\n      const swUrl = `${process.env.PUBLIC_URL}/service-worker.js`;\n\n      if (isLocalhost) {\n        // This is running on localhost. Let's check if a service worker still exists or not.\n        checkValidServiceWorker(swUrl, config);\n\n        // Add some additional logging to localhost, pointing developers to the\n        // service worker/PWA documentation.\n        navigator.serviceWorker.ready.then(() => {\n          console.log(\n            'This web app is being served cache-first by a service ' +\n              'worker. To learn more, visit https://bit.ly/CRA-PWA'\n          );\n        });\n      } else {\n        // Is not localhost. Just register service worker\n        registerValidSW(swUrl, config);\n      }\n    });\n  }\n}\n\nfunction registerValidSW(swUrl, config) {\n  navigator.serviceWorker\n    .register(swUrl)\n    .then(registration => {\n      registration.onupdatefound = () => {\n        const installingWorker = registration.installing;\n        if (installingWorker == null) {\n          return;\n        }\n        installingWorker.onstatechange = () => {\n          if (installingWorker.state === 'installed') {\n            if (navigator.serviceWorker.controller) {\n              // At this point, the updated precached content has been fetched,\n              // but the previous service worker will still serve the older\n              // content until all client tabs are closed.\n              console.log(\n                'New content is available and will be used when all ' +\n                  'tabs for this page are closed. See https://bit.ly/CRA-PWA.'\n              );\n\n              // Execute callback\n              if (config && config.onUpdate) {\n                config.onUpdate(registration);\n              }\n            } else {\n              // At this point, everything has been precached.\n              // It's the perfect time to display a\n              // \"Content is cached for offline use.\" message.\n              console.log('Content is cached for offline use.');\n\n              // Execute callback\n              if (config && config.onSuccess) {\n                config.onSuccess(registration);\n              }\n            }\n          }\n        };\n      };\n    })\n    .catch(error => {\n      console.error('Error during service worker registration:', error);\n    });\n}\n\nfunction checkValidServiceWorker(swUrl, config) {\n  // Check if the service worker can be found. If it can't reload the page.\n  fetch(swUrl)\n    .then(response => {\n      // Ensure service worker exists, and that we really are getting a JS file.\n      const contentType = response.headers.get('content-type');\n      if (\n        response.status === 404 ||\n        (contentType != null && contentType.indexOf('javascript') === -1)\n      ) {\n        // No service worker found. Probably a different app. Reload the page.\n        navigator.serviceWorker.ready.then(registration => {\n          registration.unregister().then(() => {\n            window.location.reload();\n          });\n        });\n      } else {\n        // Service worker found. Proceed as normal.\n        registerValidSW(swUrl, config);\n      }\n    })\n    .catch(() => {\n      console.log(\n        'No internet connection found. App is running in offline mode.'\n      );\n    });\n}\n\nexport function unregister() {\n  if ('serviceWorker' in navigator) {\n    navigator.serviceWorker.ready.then(registration => {\n      registration.unregister();\n    });\n  }\n}\n","import React from 'react';\nimport ReactDOM from 'react-dom';\nimport './index.css';\nimport App from './App';\nimport * as serviceWorker from './serviceWorker';\n\nReactDOM.render(<App />, document.getElementById('root'));\n\n// If you want your app to work offline and load faster, you can change\n// unregister() to register() below. Note this comes with some pitfalls.\n// Learn more about service workers: https://bit.ly/CRA-PWA\nserviceWorker.unregister();\n"],"sourceRoot":""}